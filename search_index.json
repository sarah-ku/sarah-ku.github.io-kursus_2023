[["index.html", "Analyse og visualisering af biologiske datasæt - 2023 Chapter 1 Grundlæggende R 1.1 Inledning til kapitel 1.2 RStudio 1.3 Working directory 1.4 R pakker 1.5 Hvor kommer vores data fra? 1.6 Beregninger i R 1.7 Dataframes 1.8 If/else 1.9 Loops 1.10 Descriptive statistics 1.11 Statistike tester 1.12 Problemstillinger", " Analyse og visualisering af biologiske datasæt - 2023 Sarah Rennie Last updated: 2023-05-28 Chapter 1 Grundlæggende R “Det er ikke, fordi noget er svært, at vi ikke tør, det er, fordi vi ikke tør, at noget er svært” - Seneca 1.1 Inledning til kapitel Først og fremmest, velkommen til kurset! Det her dokument er kursusnotaterne, som indeholder bla. videoer, forklaringer og problemstillinger, og jeg opdaterer dem løbende gennem hele forløbet. Vær opmærksom på, at der også vil være flere dokumenter på Absalon vedrørende forelæsninger, workshops og løsningerne til øvelserne. I dette kapitel opsummerer jeg nogle grundlæggende elementer inden for R og statistik, der betragtes som forudsætninger i dette kursus. Selvom vi i kurset skifter hurtigt over til tidyverse-pakken, som erstatter en stor del af funktionaliteten fra base-R, er det stadig vigtigt at have et grundlæggende kendskab til hvordan tingene fungerer i base-R. Hvis du har begrænset erfaring med base-R, anbefaler jeg, at du bruger ekstra tid ud over de første mødegange for at nå det nødvendige niveau. For at bestå kurset forventes det ikke, at du kender til alle detaljer og teorier bag de statistiske metoder, men at du kan anvende dem hensigtsmæssigt i praksis i R og fortolke resultaterne korrekte. Der vil være masser af muligheder for at øve dig I at anvende statistik hele vejen gennem kurset, og under eksamen vil jeg ikke stille spørgsmål om metoder, der ikke er dækket i de forskellige øvelser (herunder workshop-opgaver). Lineær regression vil også blive gennemgået i forelæsningerne så vær ikke bekymret hvis du ikke har set det hele før. Se gerne også “Quiz - grundlæggende” på Absalon for at tjekke din forståelse og udfylde eventuelle huller i din viden (OBS: Quizzen er tilgængelig kort tid inden kursets start). 1.2 RStudio Vi kommer fremadrettet til at være afhængig af RStudio til at arbejde med bl.a. R Markdown dokumenter. Kendskab til R Markdown er emnet i vores næste lektion og jeg går ud fra, at du ikke har benyttet det før. Det allerførste du bør gør, hvis du ikke har installeret RStudio på din computer, er at downloade det gratis på nettet: https://www.rstudio.com/products/rstudio/download/#download Følg venligst RStudios egne anvisninger til at få det installeret. Bemærk, at installering af RStudio er ikke den samme som at have R installeret på din computer - man skal installere dem begge to (man kan bruge R uden RStudio men ikke omvendt. 1.2.1 De forskellige vinduer i RStudio Du kan læse følgende for at lære de fire forskellige vinduer i RStudio at kende: https://bookdown.org/ndphillips/YaRrr/the-four-rstudio-windows.html Her er et kort oversigt: Man skriver kode i Source (øverst til venstre) Man kører kode ved at tryk CMD+ENTER (eller WIN-KEY+ENTER) Koder køres ind i Console (som plejer at være nederst til venstre, selvom det er øverst til højere i billedet). Man kan også skrive koder direkte i Console, men det ikke anbefales generelt, når koden ikke bliver gemt. Environment - her kan man se blandt andet, alle objekter i Workspace. 1.3 Working directory Når man arbejder på et projekt, er det ofte nyttigt at vide, den working directory som R arbejder fra - det er den mappe, hvor R forsøger at åbne eller gemme filer fra, medmindre man angiver et andet sted. getwd() #se nuværende working directory list.dirs(path = &quot;.&quot;, recursive = FALSE) #se mappe indenfor working directory setwd(&quot;~/Documents/&quot;) #sætte en ny working directory (C:/Users/myname/Documents hvis man bruger Windows) Hvis man bruger Windows, husk at man kan skrive en path på følgende måde: #notrun setwd(&quot;C:/Users/myname/Documents&quot;) #enten med / setwd(&quot;C:\\\\Users\\\\myname\\\\Documents&quot;) #eller med \\\\ OBS: jeg bruger Mac, så hvis der er et vigtigt ting at man skal huske hvis man bruger en Windows computer, kan jeg også tilføje det her. Bemærk dog, at de allerfleste ting ved R programmering og tidyverse er ens uanset om man bruger Windows eller Mac. 1.4 R pakker R pakker er simpelthen en samling af funktioner (eller datasæt i nogle tilfælde), der udvider, hvad er tilgængelige i base-R (den R man få, uden at indlæse en pakke). I R er der mange tusind R pakker (op mod 100,000), der er tilgængelige på CRAN (https://cran.r-project.org/). Indenfor det biologiske fag er der også mange flere pakker på Bioconductor (https://www.bioconductor.org/), og i nogle tilfælde kan R pakker også installeres direkte fra Github. I dette kursus arbejder vi rigtig meget med en pakke der hedder tidyverse. tidyverse er faktisk en samling af otte R pakker, som indlæses på en gang. Inden du indlæse pakken, skal du først sikre dig, at pakken er installeret på systemet ved følgende kommando: install.packages(&quot;tidyverse&quot;) Alle pakker på CRAN er installeret på samme måde. Når du faktisk gerne vil bruge en R pakke, skal du først indlæse den ved at bruge library(): library(tidyverse) ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.2 ✔ readr 2.1.4 ## ✔ forcats 1.0.0 ✔ stringr 1.5.0 ## ✔ ggplot2 3.4.2 ✔ tibble 3.2.1 ## ✔ lubridate 1.9.2 ✔ tidyr 1.3.0 ## ✔ purrr 1.0.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors Vi kommer til at arbejde med tidyverse pakker fra kapitel tre (vi starter med ggplot2 og så nogle af de andre pakke fra tidyverse fra kapitel fire), så det er en god idé at har tidyverse installeret allerede nu, når det nogle gange kan tage lidt tid til at installere eller opdatere de mange andre mulige pakker, der tidyverse er afhængig af. Vær opmærksom på, at der nogle gange opstår konflikter når det samme funktionnavn findes i flere pakker - for eksempel, funktionen filter() findes indenfor to forskellige pakker, nemlig dplyr og stats. Når du skriver filter() så ved R ikke, hvilke pakker du mener. I dette tilfælde kan du være gennemskueligt overfor den pakke, du gerne vil bruge ved at skrive dplyr::filter() eller stats:filter() i stedet for bare filter(). Som sidste kommentar, er det god praksis at indlæse alle pakker, der du benytter sig af, på toppen af din script, så at du hurtigt kan få overblik over, hvilke pakker, der skal indlæses til at få dine koder til at fungere. 1.5 Hvor kommer vores data fra? De forskellige datasæt, vi kommer til at arbejde med i kurset stammer fra mange forskellige steder. 1.5.1 Indbyggede datasæt I R er der mange indbygget datasæt som er meget brugbart for at vise koncepter, hvilket gøre dem især populært i undervisningsmateriale. Indbyggede datasæt er ofte tilgængligt indenfor mange pakker, men library(datasets) er den mest brugt (der er også mange indenfor library(ggplot2). For eksempel, for at indlæse datasættet, der hedder ‘iris’, kan man bruge data(): library(datasets) data(iris) Så er en dataframe, der hedder ‘iris’ tilgængelige som en objekt i workspacen - se den “Environment” fane på højere side i RStudio, eller indtaste ls(), så bør du kunne se et objekt med navnet ‘iris’. Man kan kun arbejde med objekter som er en del af workspacen. 1.5.2 Importering af data fra .txt fil Det er meget hyppigt, at man har sin data i formen af en .txt fil eller .xlsx fil på sin computer. Den nemmeste måde at få åbnet en .txt fil er ved at bruge read.table(), som i nedenstående: data &lt;- read.table(&quot;mydata.txt&quot;) #indlæse data filen mydata.txt som er i working directory head(data) Hvis datasættet har kolonner navne, der er skrevet ind i filen, så skal man huske at bruge header=T for at undgå, at den første række i datasættet bliver disse tekste i stedet for virkelige observationer. data &lt;- read.table(&quot;mydata.txt&quot;,header=T) #indlæse data filen mydata.txt som er i working directory head(data) 1.5.3 Importering af data fra Excel Der findes også en hjælpsom pakke, som hedder readxl, der kan indlæse Excel-ark direkte ind i R: library(readxl) data &lt;- read_excel(&quot;data.xlsx&quot;) data 1.5.4 Kaggle Hvis du gerne vil øve dig med statistike analyser (udover nuværende kursus), er Kaggle en fantastisk ressource til at finde forskellige datasæt. I rigtige mange tilfælde kan man også finde analyser some andre har lavet I R (også Python), hvilket kan inspirere jeres egen læring. Link hvis interesseret: https://www.kaggle.com/ 1.6 Beregninger i R Her er nogle helt grundlæggende koncepter når man arbejder med R. Du må selvfølgelige gerne springe sektionen over, hvis du allerede har meget erfaring med base R, men det kan være værd at tjekke, om der noget ting, der lige skal gennemgås. En god tilgang er bare at arbejde gennem problemstillingerne nedenfor, og bruger følgende notater som en reference. 1.6.1 Vectorer I R laver man en vector med c(), hvor man adskiller de forskellige elementer med en komma, som i nedenstående eksempel: a &lt;- c(1,2,3,4,5) #sæt objektet &#39;a&#39; til at være en vector af tal a ## [1] 1 2 3 4 5 Man er ikke begrænset til tal: c &lt;- c(&quot;cat&quot;,&quot;mouse&quot;,&quot;horse&quot;,&quot;sheep&quot;,&quot;dog&quot;) c ## [1] &quot;cat&quot; &quot;mouse&quot; &quot;horse&quot; &quot;sheep&quot; &quot;dog&quot; 1.6.2 datatyper Nar vi kommer til at arbejde med visualiseringer og data beardejdning er det vigtigt at have styr på datatyper i datasættet. For eksempel har vectoren c ovenpå typen character (forkortet chr) og ikke numeric (forkortet num): is.numeric(c) ## [1] FALSE is.character(c) ## [1] TRUE Her er en list overfor nogle af de vigtigste datatyper: Datatype Navn Beskrivelse int integer kun hel tal c(-1,0,1,2,3) lgl logical TRUE TRUE FALSE TRUE FALSE chr character c(\"Bob\",\"Sally\",\"Brian\",...) fct factor bestemte niveauer e.g. Species: c(\"setosa\",\"versicola\") dbl double Tal fk. c(4.3902, 3.12, 4.5) lst list blande forskellige data typer og specificere elementer med [[i]] [[1]] [1] c(\"red\",\"blue\") [[2]] [1] TRUE [[3]] [1] c(3,2.3,1.459) En datatype, der bør få særlig opmærksomhed er fct (factor). I følgende vector tea_coffee har vi tekst, men blandt de fem elementer er der kun to bestemte niveauer (nemlig “tea” og “coffee”). tea_coffee &lt;- c(&quot;tea&quot;,&quot;tea&quot;,&quot;coffee&quot;,&quot;coffee&quot;,&quot;tea&quot;) is.factor(tea_coffee) ## [1] FALSE tea_coffee ## [1] &quot;tea&quot; &quot;tea&quot; &quot;coffee&quot; &quot;coffee&quot; &quot;tea&quot; Vi vil derfor gerne fortælle R, at tea_coffee er ikke bare nogle tilfældig tekst men at der er en struktur med, så vi bruger funktionen as.factor for at lave den om til datatypen fct. tea_coffee &lt;- as.factor(tea_coffee) is.factor(tea_coffee) ## [1] TRUE tea_coffee ## [1] tea tea coffee coffee tea ## Levels: coffee tea Den ‘ekstra’ oplysninger man har ved at sige, at en variabel betragtes som factor bliver vigtigt når man arbejder med visualiseringer - for eksempel, hvis vi gerne vil lave et barplot hvor man gerne vil adskille søjlerne efter de to niveauer “tea” og “coffee” (visualiseringer er emnet fra kapitel 3). 1.7 Dataframes http://www.r-tutor.com/r-introduction/data-frame Mange af de ting, som vi laver i R tager udgangspunkten i dataframes (eller datarammer). mydf &lt;- data.frame(&quot;personID&quot;=1:5, &quot;height&quot;=c(140,187,154,132,165), &quot;age&quot;=c(34,31,25,43,29)) mydf ## personID height age ## 1 1 140 34 ## 2 2 187 31 ## 3 3 154 25 ## 4 4 132 43 ## 5 5 165 29 Man kan fa adgang til variabler i en dataframe ved at bruge det dollar tegn $. For eksempel giver følgende variablen personID fra dataframen mydf: mydf$personID ## [1] 1 2 3 4 5 Husk, at vores dataframe, ligesom et matrix (i R: matrix()) har to dimensioner - række og kolonner Forskellen mellem en matrix og en dataramme er, at datarammer kan indeholde mange forskellige data typer (herunder numeriske, faktorer, karakterer osv.), men matrix indeholder kun numeriske data. For eksempel i tilfældet af ovenstående dataframen er alle variabler numeriske, men vi kan godt tilføje en variabel som er ikke-numeriske: mydf$colour &lt;- c(&quot;red&quot;,&quot;blue&quot;,&quot;green&quot;,&quot;orange&quot;,&quot;purple&quot;) #make new variable which is non-numeric mydf ## personID height age colour ## 1 1 140 34 red ## 2 2 187 31 blue ## 3 3 154 25 green ## 4 4 132 43 orange ## 5 5 165 29 purple Nu er mydf er en dataframe, der blander forskellige datatyper, men følgende er en matrix matrix(c(1, 2, 3, 4, 5, 6), nrow=3, ncol=2) ## [,1] [,2] ## [1,] 1 4 ## [2,] 2 5 ## [3,] 3 6 og kan kun indeholde numeriske data, som kan bruges til at lave matematik operationer (matrix multiplikation osv.). I dette kursus beskæftiger os primært med dataframes (som bliver kaldt for tibbles i tidyverse). 1.7.1 Delmængder af dataframes Selvom vi kommer til at redefinere hvordan man laver delmængde når vi kommer til at arbejde med pakken tidyverse, er det alligevel vigtigt at forstå, hvordan man laver en delmængde i base-R, og det er et område, der ofte skaber forvirring blandt de uerfarne. Når man vil gerne har en bestemt delmængde af en vector, bruger man firkantet paranteser [ ]. Følgende kode giver mig de første to værdier fra vectoren a: a[1:2] ## [1] 1 2 Bemærk, at mens vectorer har kun en dimension, har dataframes to dimensioner. Når man skal lave en delmægde af en dataframe, skal man derfor fortælle R, hvilke række og hvilke kolonner skal være med. mydf[række indekser, kolonner indekser] #not run For eksempel, hvis vi gerne vil have de første to observationer med, samt kun den anden variabel, skriver man følgende: mydf[1:2, 2] #first two rows (observations), second column (variable) only ## [1] 140 187 Hvis vi vil beholde den første to observationer og samtlige variabler, kan den anden plads være tom: mydf[1:2, ] #first two rows, all columns ## personID height age colour ## 1 1 140 34 red ## 2 2 187 31 blue Jeg kan også angive et variabelnavn direkte: mydf[1:2,&quot;height&quot;] ## [1] 140 187 Man kan kigge på en subset af rækkerne i de data ved at mydf[mydf$height&gt;=165,] #alle rækker i datarammen med height = 165 eller over ## personID height age colour ## 2 2 187 31 blue ## 5 5 165 29 purple Her er en tabel af comparitiver, og jeg gengiver samme tabel når I kommer til at lave delmængde i tidyverse: comparitiv beskrivelse &lt; less than &gt; greater than &lt;= less than or equal to &gt;= greater than or equal to == equal to != not equal to &amp; and %in% in | or ! not Jeg mener, at %in% er særlig brugbart og er værd at lære: mydf[mydf$personID %in% c(1,3,5),] #alle personer med personID 1,3 eller 5 ## personID height age colour ## 1 1 140 34 red ## 3 3 154 25 green ## 5 5 165 29 purple Her er et eksempel på, hvordan man bruger udråbstegnet: personer med personID, der ikke er 1,3 eller 5: mydf[!(mydf$personID %in% c(1,3,5)),] #alle personer med personID 2 eller 4 ## personID height age colour ## 2 2 187 31 blue ## 4 4 132 43 orange 1.8 If/else If/else kodekonstruktioner giver mulighed for at udføre forskellige handlinger baseret på, om en bestemt betingelse er opfyldt. Her er et eksempel med if med betingelsen number &gt; 0: number &lt;- 42 if (number &gt; 0) { print(&quot;Number is positive&quot;) } ## [1] &quot;Number is positive&quot; Hvis betingelse er sand udføres den handling indenfor { }, dvs. “Number is positive” printes. If/else konstruktioner gør det samme, men hvis betingelsen er falsk, udføres en alternativ handling: number &lt;- -5 if (number &gt; 0) { print(&quot;Number is positive&quot;) } else { print(&quot;Number is not positive&quot;) } ## [1] &quot;Number is not positive&quot; Man kan også opnå samme resultat med at bruge ifelse: number &lt;- 3 numbers_of_interest &lt;- c(1,3,5,7) ifelse(test = number %in% numbers_of_interest, yes = &quot;Number is interesting&quot;, no = &quot;Number is uninteresting&quot;) ## [1] &quot;Number is interesting&quot; Man behøver ikke at skrive ordene “test”, “yes” og “no” hver gang, såfremt at du bruger samme rækkefølgen som funktionen forventer: ifelse(number %in% numbers_of_interest, &quot;Number is interesting&quot;, &quot;Number is uninteresting&quot;) ## [1] &quot;Number is interesting&quot; 1.9 Loops I base-R kan man laver simpel loops med følgende konstruktion: for (i in 1:5) { print(i) } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 Loops bliver et stort emne senere i kurset (emne 8/9). 1.10 Descriptive statistics 1.10.1 Simulere data fra den normale fordeling Hvis du har bruge for at vide mere om den normale fordeling: http://www.r-tutor.com/elementary-statistics/probability-distributions/normal-distribution Man kan nemt lave sin egne ‘fake’ data ved at simulere det fra en fordeling, der typisk er normalfordelingen, da den er den mest almindelige fordeling i den virkelige verden (husk den klassiske klokkeform). I R kan funktionen rnorm bruges til at simulere data. Først angiver man antallet af observationer, og derefter den gennemsnitlige værdi og standardafvigelsen (sd), som er de to nødvendige parametre for at beskrive en normalfordeling. x &lt;- rnorm(25,mean=0,sd=1) #standard normal distribution x #så har vi 25 værdier fra en normal distribution med mean=0 og standard deviation=1. ## [1] -0.3076682 1.5747765 -0.1768637 -0.6272138 -1.1885154 1.4926498 ## [7] 1.4926068 0.6416757 -0.3573947 0.4212948 0.9241376 -0.2485553 ## [13] -1.3591219 0.8172188 1.4836074 -0.2377516 1.0627462 -0.8786571 ## [19] 0.2156636 -0.3389847 4.1615417 -1.0163683 -0.6963343 -2.0001262 ## [25] 0.3364288 I stedet for at kigge på alle værdier på én gang, vil vi måske hellere kigge kun på de første (eller sidste) værdier: head(x) #første 6 ## [1] -0.3076682 1.5747765 -0.1768637 -0.6272138 -1.1885154 1.4926498 tail(x) #sidste 6 ## [1] -0.3389847 4.1615417 -1.0163683 -0.6963343 -2.0001262 0.3364288 x[1] #første værdi ## [1] -0.3076682 x[length(x)] #sidste data point ## [1] 0.3364288 Bemærk, at i modsætning til Python og mange andre programmeringssprog, bruger R en 1-baseret indeksering. Det betyder, at den første værdi er x[1] og ikke x[0] som i Python. 1.10.2 Measures of central tendency function Description mean() mean \\(\\bar{x}_{i} = \\frac{1}{n}\\sum_{i=1}^{n} x_{i}\\) median() median value max() maximum value min() minimum value var() variance \\(s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n} (x_{i} - \\bar{x}_{i})^2\\) sd() standard deviation \\(s\\) Lad os afprøve dem på vores simulerede data: my_mean &lt;- mean(x) my_median &lt;- median(x) my_max &lt;- max(x) my_min &lt;- min(x) my_var &lt;- var(x) my_sd &lt;- sd(x) c(my_mean,my_median,my_max,my_min,my_var,my_sd) #print results ## [1] 0.2076317 -0.1768637 4.1615417 -2.0001262 1.6336783 1.2781543 Man kan også lave et summary af dataen, som består af mange af de statistiker navnt ovenpå: summary(x) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -2.0001 -0.6272 -0.1769 0.2076 0.9241 4.1615 1.10.3 tapply() tapply() er en meget nyttig funktion i R, som kan bruges til at anvende en funktion på en gruppe af data baseret på værdier i en anden vektor. Funktionen tager tre hovedargumenter: den vektor, som vi ønsker at anvende funktionen på, den vektor, som bruges til at gruppere dataene, og funktionen, som vi ønsker at anvende på hver gruppe. tapply() vil derefter opdele dataene i grupper baseret på den anden vektor og anvende funktionen på hver gruppe. Resultatet af tapply() vil være en vektor, som indeholder resultaterne af funktionen anvendt på hver gruppe af data. For eksempel: data(iris) tapply(iris$Sepal.Length,iris$Species,mean) # ovenstående i kun en linje ## setosa versicolor virginica ## 5.006 5.936 6.588 Her tager vi en vektor ved navn Sepal.Length, opdeler den efter Species og beregner gennemsnittet ved hjælp af funktionen mean for hver af de tre arter i Species (setosa, versicolor og virginica). Alternativt kunne man have beregnet gennemsnittet for hver af de tre Species separat (en tilgang, der ikke skalerer godt!): # gennemsnit Sepal Length for Species setosa mean_setosa &lt;- mean(iris$Sepal.Length[iris$Species==&quot;setosa&quot;]) # gennemsnit Sepal Length for Species versicolor mean_versi &lt;- mean(iris$Sepal.Length[iris$Species==&quot;versicolor&quot;]) # gennemsnit Sepal Length for Species virginica mean_virgin &lt;- mean(iris$Sepal.Length[iris$Species==&quot;virginica&quot;]) c(mean_setosa,mean_versi,mean_virgin) ## [1] 5.006 5.936 6.588 Det er også værd at ved koncepten, fordi vi kommer til lære en lignende koncept i tidyverse (med group_by og summarise). 1.11 Statistike tester Her er en oversigt over nogle af de mest grundlæggende tests, som man kan udføre på data i R. Det kan være nyttigt som en reference senere hen, hvis det er nødvendigt. Jeg vil ikke gå i dybden med teorien bag disse tests (da det antages, at du har lært det tidligere), men jeg forventer, at du er i stand til at anvende dem korrekt i R og fortolke resultaterne. Hvis du ikke er bekendt med nogle af disse tests, vil der være masser af muligheder for at øve dig i statistik gennem kurset. t-test: Bruges til at sammenligne to grupper og afgøre, om forskellen mellem deres gennemsnitlige værdier er statistisk signifikant. ANOVA: Bruges til at sammenligne mere end to grupper og afgøre, om der er statistisk signifikant forskel mellem mindst to af grupperne. Korrelationsanalyse: Bruges til at afgøre, om der er en statistisk signifikant sammenhæng mellem to variabler. Regressionsanalyse: Bruges til at afgøre, om der er en statistisk signifikant sammenhæng mellem en uafhængig variabel og en afhængig variabel og at forudsige værdien af den afhængige variabel baseret på værdien af den uafhængige variabel. Chi-square test: Bruges til at afgøre, om der er en statistisk signifikant forskel mellem observerede og forventede værdier for kategoriske variabler. 1.11.1 P-værdien Først og fremmest er det vigtigt at kunne huske p-værdi både i forhold til definitionen og i forhold til hvordan det fortolkes. P-værdien er sandsynligheden for at observere et resultat lige så ekstremt eller mere ekstremt end det observerede, givet at null-hypotesen er sand. Null-hypotesen er en antagelse om, at der ikke er nogen signifikant forskel mellem grupper eller variabler i det dataset, som der arbejdes med. Hvis p-værdien er mindre end det valgte signifikansniveau (typisk 0,05), så betyder det, at det observerede resultat er usandsynligt at opstå ved ren tilfældighed, og null-hypotesen forkastes til fordel for den alternative hypotese om, at der er en signifikant forskel mellem grupper eller variabler i datasættet. 1.11.2 Korrelation Korrelation måler styrken og retningen af den lineære sammenhæng mellem to kontinuerte variabler, som begge er normalfordelte: \\(&gt;0\\) betyder, at der er en positiv sammenhæng \\(&lt;0\\) betyder, at der er en negativ sammenhæng \\(=0\\) betyder, at der er ingen sammenhængen mellem de to variabler data(cars) cor(cars$speed, cars$dist) ## [1] 0.8068949 Husk dog, at “Correlation does not equal causation” - dvs. at korrelation er bare en sammenhæng og ikke nødvendigvis angiver en årsagssammenhæng mellem de to variable. Funktionen cor.test() kan bruges til at teste, om korrelationen mellem to variable er statistisk signifikant. Null-hypotesen antager, at der ikke er nogen korrelation mellem de to variable i den population, som datasættet repræsenterer. cor.test(cars$speed, cars$dist) ## ## Pearson&#39;s product-moment correlation ## ## data: cars$speed and cars$dist ## t = 9.464, df = 48, p-value = 1.49e-12 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.6816422 0.8862036 ## sample estimates: ## cor ## 0.8068949 Så kan man se, at p-værdien er 0, der er under 0.05. Derfor konkluderer man, at der er en signifikant sammenhæng mellem de to variabler. 1.11.3 Test for uafhængighed (chi-sq test) En chi-squared test kan bruges til at undersøge, om der er en statistisk signifikant sammenhæng mellem antallet af observationer i to eller flere forskellige kategorier. For eksempel kan man teste for sammenhængen mellem antallet af kopier af en genvariant og to forskellige farver på blomster i en bestemt planteart. 0 1 2 red 29 31 16 pink 11 16 24 Vi vil gerne vide, om phenotype er afhængig af genotype: \\(H_{0}:\\) antal gen copi og phenotype er uafhængie af hinanden VS \\(H_{1}:\\) antal gen copi og phenotype er afhængie af hinanden Testen går ud på, at man beregner forventede værdier under nulhypotesen om, at der ikke er nogen sammenhæng mellem de to kategorier, og sammenligner disse forventede værdier med observerede værdier. Man laver testen i R ved at benytte funktionen chisq.test(): chisq.test(dat) ## ## Pearson&#39;s Chi-squared test ## ## data: dat ## X-squared = 9.9516, df = 2, p-value = 0.006903 Her er p-værdien = 0.006903 &lt; 0.05, så vi forkaster nulhypotesen og konkluderer, at der er en signifikant sammenhæng mellem de to variabler. Ud fra rådatasættet kan man også observere, at der er flere røde blomster uden nogen kopi af genet sammenlignet med røde blomster med to kopier af genet, mens det modsatte er tilfældet for de lyserøde blomster. 1.11.4 1 sample t-test For at vise en 1-sample t-test, simulerer jeg nogle data fra en normalfordeling med middelværdi på 3 ved hjælp af rnorm()-funktionen: set.seed(290223) # bare for at få den samme resultat hver gang x &lt;- rnorm(10,mean = 3,sd = 1) Forestil dig, at du ikke helt stoler på funktionen rnorm() og ønsker at teste, om x stammer fra en normalfordeling med en middelværdi på 3. Nulhypotesen og den alternative hypotese (to-sidet test) er derfor: \\(H_{0}: \\mu = 3\\), VS \\(H_{1}: \\mu \\neq 3\\) For at lave testen i R, bruger man funktionen t.test() og angiver mu = 3 for at reflektere vores hypoteser: t.test(x,mu = 3) ## ## One Sample t-test ## ## data: x ## t = -1.1448, df = 9, p-value = 0.2818 ## alternative hypothesis: true mean is not equal to 3 ## 95 percent confidence interval: ## 2.169968 3.272231 ## sample estimates: ## mean of x ## 2.721099 Fra resultatet kan man se, at p-værdien er estimeret til 0.2818, og da den er &gt; 0.05 kan vi ikke forkaste nulhypotesen, og vi konkluderer derfor, at middelværdien af x ikke adskiller sig signifikant fra 3. Bemærkning: da vi simulerede vores data fra en normal fordeling med et gennemsnit på tre, vidste vi i forvejen at det korrekte svar er, at beholde nullhypotesen. Havde vi forkastet nullhypotesen, havde vi lavet en type I fejl - det vil sige, at vi forkaster nullhypotesen når det faktisk er sandt. 1.11.5 2-sample t-test Undersøger om der er en forskel i de gennemsnitlige værdier mellem to grupper - kan de to grupper betragtes til at stammer fra den samme normale fordeling? Hypoteserne er således (to-sidet): \\(H_{0}: \\mu_{1} = \\mu_{2}\\), VS \\(H_{1}: \\mu_{1} \\neq \\mu_{2}\\) I følgende kode simulere jeg to stikprøver, der kommer fra en normal fordeling med forskellige gennemsnitte og bruger funktionen t.test. Man kan angive at de to stikprøver har samme variance ved at skrive var.equal = T indenfor funktionen t.test: x &lt;- rnorm(10,3,1) y &lt;- rnorm(10,5,1) t.test(x,y,var.equal = T) ## ## Two Sample t-test ## ## data: x and y ## t = -5.4258, df = 18, p-value = 3.729e-05 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -2.700858 -1.193081 ## sample estimates: ## mean of x mean of y ## 2.783056 4.730025 Hvis man til gengæld ikke kan antage, at variansen er den samme i de to grupper: x &lt;- rnorm(10,3,1) y &lt;- rnorm(10,5,3) #større variance t.test(x,y,var.equal = F) #var.equal=F er &#39;default&#39; så man behøver ikke at specifere ## ## Welch Two Sample t-test ## ## data: x and y ## t = -2.0238, df = 11.77, p-value = 0.0663 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -3.9077927 0.1483728 ## sample estimates: ## mean of x mean of y ## 2.757436 4.637146 Bemærk at hvis man kan antage at variancen er den samme, så har man mere power (kræft) til at kalde en virkelig forskel for signifikant. 1.11.6 Paired t-test En paired t-test bruges når man for eksempel har målinger for den samme sæt personer i hver stikprøve, og man gerne vil teste om forskellen i værdier mellem de to stikprøver er signifikant. For eksempel hvis vi har “before” og “after” målinger for den samme 10 individer: set.seed(320) before &lt;- rnorm(10,3,1) after &lt;- rnorm(10,6,2) t.test(before,after,paired=T) #specificy paired data ## ## Paired t-test ## ## data: before and after ## t = -9.3296, df = 9, p-value = 6.356e-06 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## -5.415186 -3.301613 ## sample estimates: ## mean difference ## -4.358399 t.test(before-after,mu=0) #exactly the same result ## ## One Sample t-test ## ## data: before - after ## t = -9.3296, df = 9, p-value = 6.356e-06 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## -5.415186 -3.301613 ## sample estimates: ## mean of x ## -4.358399 1.11.7 ANOVA (variansanalyse) Har man flere grupper i stedet for to, kan man bruge ANOVA (analysis of variance eller variansanalyse). For en kategorisk variabel med \\(k\\) grupper, er nul/alternativhypotesen: \\(H_{0}: \\mu_{1} = \\mu_{2} = \\ldots = \\mu_{k}\\) \\(H_{1}:\\) ikke alle middelværdier er enes #simulere data til 3 forskellige grupper fra den normale fordeling med standard afvigelse af 3 group1 &lt;- rnorm(50,10,3) group2 &lt;- rnorm(55,10,3) group3 &lt;- rnorm(48,5,3) #data må være i en dataramme, med den ene kolon = vores værdier, og den anden kolon = grupper y &lt;- c(group1,group2,group3) x &lt;- c(rep(&quot;G1&quot;,50),rep(&quot;G2&quot;,55),rep(&quot;G3&quot;,48)) mydf &lt;- data.frame(&quot;group&quot;=x,&quot;value&quot;=y) For at udføre testen kan man bruge funktionen lm(), som står for “linear model” og kan bruges til at opbygge forskellige modeller. Her angiver vi en model, hvor hver gruppe (G1, G2 og G3 fra variablen x) har sin egen middelværdi (variablen value), hvilket er modellen under alternativhypotesen: mylm &lt;- lm(value~group,data=mydf) #H1 model Under nulhypotesen har alle grupper den samme middelværdi, og derfor behøver vi ikke at inkludere variablen group i modellen. Vi angiver situationen i modellen ved at skrive 1, som betyder, at forventede værdier for den afhængige variabel value blot er dens middelværdi: mylm_null &lt;- lm(value~1,data=mydf) #H0 model For at sammenligne de to modeller benytter vi funktionen anova() (efter analysis of variance): anova(mylm_null,mylm) ## Analysis of Variance Table ## ## Model 1: value ~ 1 ## Model 2: value ~ group ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 152 2215.4 ## 2 150 1509.9 2 705.55 35.047 3.245e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 P-værdien er (&lt;0.05), så nulhypotesen er forkastet til fordel af alternativhypotesen, altså modellen, hvor hver gruppe har sin egen middelværdi. Bemærk at det er til trods af, at to af de tre grupper kommer fra en normal fordeling med præcis de samme middelværdier (det er nok, at den trejde gruppe har en ænderledes middelværdi). 1.11.8 Lineær regression OBS: se også video i forbindelse med Rmarkdown (næste emne), hvor jeg gennemgå lineær regression med R Formål: måler (en retningsbestemt) relation mellem to kontinuerte variabler. I simpel lineær regression svarer det til, at man gerne vil finde den rette linje gennem punkterne, der bedste beskriver relationen. Eksempel - datasættet mtcars, response (afgængig) variabel er mpg og predictor (uafhængig) variabel er wt. Man skriver relationen i R som mpg ~ wt og benytter lm()(lm(mpg~wt,data=mtcars)): mylm &lt;- lm(mpg ~ wt, data=mtcars) # build linear regression model mylm ## ## Call: ## lm(formula = mpg ~ wt, data = mtcars) ## ## Coefficients: ## (Intercept) wt ## 37.285 -5.344 Vores “Coefficients” beskriver den bedste rette linje: Skæringen (intercept): 37.285 Hældningskoefficient (slope): -5.344 Det betyder, at hvis vægten wt af en bil stiger med 1, så stiger mpg ved -5.344 (det vil sige at mpg reduceres med 5.344). 1.11.9 R-squared coefficient of determination Den \\(R^2\\) eller “forklaringsgraden” (coefficeint of determination) har til formål at forklare, hvor godt vores lineær model passer til de data. For eksempel hvor meget af variansen i mpg forklares af variablen wt? Hvis det er tæt på 1 - så er der en meget tæt relation (hvis man kender vægten, så vide man også mpg med stor sikkerhed) Hvis det er tæt på 0 - så er relationen svag - høj sandsynlighed for, at der er andre variabler der bedre kan forklare variansen i mpg. I ovenstående model, kan man se den \\(R^2\\) værdi med summary(mylm). summary(mylm) ## ## Call: ## lm(formula = mpg ~ wt, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.5432 -2.3647 -0.1252 1.4096 6.8727 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 37.2851 1.8776 19.858 &lt; 2e-16 *** ## wt -5.3445 0.5591 -9.559 1.29e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.046 on 30 degrees of freedom ## Multiple R-squared: 0.7528, Adjusted R-squared: 0.7446 ## F-statistic: 91.38 on 1 and 30 DF, p-value: 1.294e-10 Det fortæller os, at \\(R^2\\) = 0.7528. 1.11.10 Antagelser - lineær regression Normalfordelte residualer Residualer har samme spredning (varianshomogenitet) Uafhængighed Fit er linæer Koden plot(mylm,which=c(1)) angiver residualer vs predikterede (fitted) værdier - de skal være tilfældigt fordelt over plottet og prikkernes varians skal være nogenlunde konstant langt x-aksen (det giver, at den røde linje er flade). plot(mylm,which=c(1)) Med koden plot(mylm,which=c(2)) kan man tjekke antagelsen på en normal fordeling. Punkterne skal være nogenlunde tæt på den diagonale linje. plot(mylm,which=c(2)) 1.11.11 Multiple lineær regression Her kan man tilføje flere variabler i vores model formel. mylm_disp &lt;- lm(mpg ~ wt + disp, data=mtcars) # build linear regression model summary(mylm_disp) ## ## Call: ## lm(formula = mpg ~ wt + disp, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.4087 -2.3243 -0.7683 1.7721 6.3484 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 34.96055 2.16454 16.151 4.91e-16 *** ## wt -3.35082 1.16413 -2.878 0.00743 ** ## disp -0.01773 0.00919 -1.929 0.06362 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.917 on 29 degrees of freedom ## Multiple R-squared: 0.7809, Adjusted R-squared: 0.7658 ## F-statistic: 51.69 on 2 and 29 DF, p-value: 2.744e-10 Her kan man se, at med tilføjelsen af variablen disp, er \\(R^2\\) steget til 0.7809. Bemærk, at jo flere variabler man tilføjer til modellen, jo større bliver \\(R^2\\)-værdien. Den adjusted \\(R^2\\) værdi er lavere fordi den prøver at tage højde for kompleksiteten af modellen (hvor mange parametre der er). Variablen disp er faktisk ikke selv signifikant når der er taget højde for variablen wt (p-værdien 0.0636 - tjek, at du selv kan finde værdien i resultatet). Hvis en af de uafhængige variabler er kategorisk bruger man funktionen anova til at teste den overordnet effekt af den variabel. For eksempel har variablen cyl 3 mulige værdier (niveauer) - 4, 6 og 8. Vi kan inddrage variablen i vores model: –&gt; mylm_cyl &lt;- lm(mpg ~ wt + factor(cyl), data=mtcars) # build linear regression model summary(mylm_cyl) ## ## Call: ## lm(formula = mpg ~ wt + factor(cyl), data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.5890 -1.2357 -0.5159 1.3845 5.7915 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 33.9908 1.8878 18.006 &lt; 2e-16 *** ## wt -3.2056 0.7539 -4.252 0.000213 *** ## factor(cyl)6 -4.2556 1.3861 -3.070 0.004718 ** ## factor(cyl)8 -6.0709 1.6523 -3.674 0.000999 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.557 on 28 degrees of freedom ## Multiple R-squared: 0.8374, Adjusted R-squared: 0.82 ## F-statistic: 48.08 on 3 and 28 DF, p-value: 3.594e-11 Man kan ikke se den overordnet effekt af cyl fra den ovenstående summary men man kan teste den med anova: anova(mylm,mylm_cyl) ## Analysis of Variance Table ## ## Model 1: mpg ~ wt ## Model 2: mpg ~ wt + factor(cyl) ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 30 278.32 ## 2 28 183.06 2 95.263 7.2856 0.002835 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Så kan man se, at cyl er signifikant. 1.12 Problemstillinger Husk quizzen på Absalon, og lav gerne nogle øvelser for at øve dine færdigheder i R: Øvelse 2-8 er meget grundlæggende og i godt kan springes over, hvis man er nogenlunde fortrolig med base-R. Jeg vil anbefale øvelse 9-15 til alle som en god måde at teste deres viden på. Øvelse 16-20 fokuserer på andre statistiske test i R. Vi vil komme tilbage til regression flere gange i kurset, så det vil være en god idé at have kendskab til funktionen lm() til at opbygge modeller i ANOVA / simpel lineær regression (se også videoen og problemstillingerne til det næste emne R Markdown). 1.12.1 Quiz - Basics 1) Lav quiz i Absalon, der hedder “Quiz - Basics”. 1.12.2 Grundlæggende R 2) (helt baserende viden) Åbn en ny fil i RStudio ved at klikke på “File” &gt; “New File” &gt; “R Script”. Kør følgende kode en linje ad gangen og tjek, om du forstår outputtet. Husk, at den nemmeste måde at køre kode på er ved at trykke på CMD+ENTER (Mac) eller WIN-KEY+ENTER (Windows). 2+2 2*2 x &lt;- 4 x &lt;- x+2 sqrt(x) sqrt(x)^2 rnorm(10,2,2) log10(100) y &lt;- c(1,4,6,4,3) class(y) class(c(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;)) mean(y) sd(y) seq(1,13,by=3) 3) (helt baserende viden) Kør følgende kode til at åbne nogle af de indbygget datasæt, som vi bruger i kurset. * Prøve head(), nrow(), summary() osv. * Prøve også fk. ?cars for at se en beskrivelse. data(iris) data(cars) data(ToothGrowth) data(sleep) head(chickwts) data(trees) #se her for andre: library(help = &quot;datasets&quot;) 4) (baserende plots) Jeg giver nogle muligheder for datasættet “iris”. Prøv også at bruge nogle af de andre indbyggede datasæt, som du har indlæst. plot(iris$Sepal.Length,iris$Sepal.Width) hist(iris$Sepal.Width) boxplot(iris$Sepal.Length~iris$Species) Du kan også gøre plottene lidt pænere ved at give dem en titel og navne på akserne. Prøv at kigge på dokumentationen for plot() ved at skrive ?plot i R-konsollen. Du kan tilføje ylab, xlab og main (titel) i én af plottene. Prøv også at eksperimentere med farver ved at bruge col. Bemærk dog, at vi vil ændre måden at lave plottene på, når vi begynder at bruge ggplot2. 5) (dataframes) Brug datasættet cars (data(cars)) til at: Lav et scatter plot med speed på x-aksen og dist på y-aksen Tilføj en ny kolon med følgende kode: cars$fast &lt;- cars$speed&gt;15 Brug mean på den nye kolon fast for at finde ud af proportionen af biler, der er hurtige Beregn gennemsnitsværdien af variablen dist for hurtige biler og ikke-hurtige biler hver for sig (brug funktionen tapply). Gem resultatet med &lt;-. Brug barplot til at lave et plot af den gennemsnitlige dist for hurtige og ikke-hurtige biler. 6) (dataframes) En dataframe kan indeholde forskellige datatype (i modsætning til en matrix). Lav en ny dataframe (funktionen data.frame()) med tre kolonner, som hedder “navn”, “alder” og “yndlings_farve” (du kan finde på værdierne selv). Sørg for, at din dataframe har 4 rækker. mydf &lt;- data.frame(&quot;navn&quot;= c(&quot;alice&quot;,&quot;freddy&quot;, ... ), &quot;alder&quot; = c(...), ...) #not run, slette &quot;...&quot; og skrive videre dim(mydf) # fire række og tre kolonner mydf 7) (dataframes) Tilføj en ny kolon random til din oprettede dataframe - hvor værdierne kommer fra en normalfordeling med et gennemsnit på 5 og standardafvigelse på 1 (bruge funktionen rnorm()). mydf$random &lt;- #?? 8) (delmængder af dataframes) Åbn datasættet “ToothGrowth” med følgende kode: data(&quot;ToothGrowth&quot;) ?ToothGrowth Find delmængden af datasættet således at diet (variablen supp) er “OJ” og længden (variablen len) er større end 15. newdf &lt;- ToothGrowth[#skrive her til at lave subset af observationerne,] Hvor mange rækker er der i den nye data frame newdf? Hvor mange unikke værdier er der i variablen dose (brug funktionen unique) ? Find delmængden af datasættet ToothGrowth, hvor variablen dose er 0.5 eller 2.0 (hint: brug %in% eller |) og supp er “VC”. Beregn den gennemsnitlige længde for observationerne i delmængden. 1.12.3 Kort analyse med reaktionstider 9) (indlæse data) Åbn en fil på Absalon ved navn “reactions.txt” ved at bruge funktionen read.table() og gem resultatet i variablen data. Husk at tjekke, om filen indeholder variabelnavne og brug header=T hvis nødvendigt. data &lt;- ... #replace ... 10) (factor variabler) Variablerne subject og time blev indlæst som henholdsvis int (heltal) og chr (character) datatyper, men de skal i stedet være factor variabler. Brug funktionen as.factor() til at konvertere dem til factor variabler. #gør subject til en faktor data$subject &lt;- as.factor(data$subject) ## gør den samme her for time: Hvor mange niveauer er der i hver af de to variabler efter konvertering til faktorvariabler? Prøv funktionerne levels() eller nlevels(). 11) (delmængder af dataframes) Lav to delmængder af det ovenstående datasæt ved at: oprette en delmængde til alle observationer fra tidspunktet “before” ved at vælge rækkerne i dataframen hvor data$time == “before” oprette en delmængde til alle observationer fra tidspunktet “after”. RT_before &lt;- data[#skrive her , ] RT_after &lt;- #skrive her Opret en yderligere delmængde, som viser alle observationer fra tidspunktet “before” med en reaktionstid på mindst 800. Hvor mange personer er der i denne delmængde? RT_before_mindst800 &lt;- #skrive her 12) (mean og tapply) Benyt funktionen mean() til at beregne den gennemsnitlige reaktionstid (variablen RT) for “before” og “after” delmængderne. Brug funktionen tapply() på det oprindelige datasæt data for at beregne den samme middelværdi med mindre kode. tapply(#skrive her,#skrive her,#skrive her) Er reaktionstiderne blevet hurtigere eller langsommere i gennemsnit? 13) (beregn forskellen og mean) Bemærk, at datasættet er ‘paired’ - målingerne er lavet på de samme personer både “before” og “after”. Opret en vector diff, der indeholder forskellene i reaktionstiderne mellem “before” og “after” for hver person. Beregn den gennemsnitlige forskel i rekationstiderne. diff &lt;- #change in reaction time between before and after mean(diff) Tjek, om tegnet på middelværdien stemmer overens med din konklusion fra 11) - hvis den er positiv, betyder det, at reaktionstiderne er blevet langsommere. 14) (lav t-test i R) Lav en t-test (funktionen t.test()) for at teste hypotesen om, at den gennemsnitslige forskel i reaktionstiderne mellem “before” og “after” er forskellig fra 0. t.test(#skrive her..) Find følgende i outputtet fra R: Hvor er test-statistik t? Hvor er p-værdien? Hvad er alternativhypotesen? Husk at skrive en kort sætning med din endelige konklusioner. 1.12.4 Øvelse med CO2 15) (t-test med CO2) Indlæs datasættet med kommandoen data(CO2) Opret en delmængde med kun observationer for planten “Qn1” Beregn den gennemsnitlige optagelse (variablen uptake) for hvert behandlingstype (variablen Treatment) i din delmængde ved hjælp af tapply()-funktionen. Udfør en t-test ved hjælp af t.test()-funktionen for at sammenligne optagelsen mellem de to behandlinger i din delmængde. Skriv en kort sætning med din konklusion. 1.12.5 Ekstra øvelser med statistik tests 16) (Chi-sq) Kør følgende kode til at få en tabel (selve koden er ikke vigtigt): mytable &lt;- structure(c(80L, 97L, 372L, 136L, 87L, 119L), .Dim = 3:2, .Dimnames = structure(list( c(&quot;First&quot;, &quot;Second&quot;, &quot;Third&quot;), c(&quot;Died&quot;, &quot;Survived&quot;)), .Names = c(&quot;Class&quot;, &quot;Survival&quot;)), class = &quot;table&quot;) mytable ## Survival ## Class Died Survived ## First 80 136 ## Second 97 87 ## Third 372 119 Tabellen angiver antallet af passagerer ombord skibet ‘Titanic’, som sank den 15. april 1912 efter et sammenstød med et isbjerg 600 km sydøst for Halifax, Nova Scotia i Canada. Tabellen er opdelt i tre klasser (førsteklasse, andenklasse, tredjeklasse) og viser antallet af passagerer, som overlevede tragedien og antallet af passagerer, som døde. Benyt funktionen chisq.test() på tabellen. Hvad er nulhypotesen til testen? Er testen signifikant? Er passagerenes klasse og deres chance for at overleve tragedien uafhængige af hinanden? Hvilken af de tre klasse havde den bedste chance for at overleve? OBS: Vi kommer til at arbejde meget mere med datasættet Titanic i emnet Tidyverse - dag 1! 17) (Korrelation analyse) Åbn datasættet trees og lav et scatter plot med variablen Girth på x-aksen og variablen Volume på y-aksen. data(trees) summary(trees) Anvend funktionen cor.test for at teste, om der er en signifikant korrelation mellem de to variabler. Brug method = \"pearson\" (det er dog faktisk default) cor.test(???, ???,method=&quot;pearson&quot;) Hvad er korrelationen mellem Girth og Volume? Hvad er p-værdien? Er den signifikant? 18) (ANOVA) OBS: hvis du føler dig utryg med funktionen lm() - der kommer en video om det i morgen (i forbindelse med emnet Rmarkdown). Kør følgende kode til at lave variansanalyse, der tester hulhypotesen hvor den gennemsnitlige værdi af variablen Sepal.Width er ens for hver af de tre arter (variablen Species) fra datasættet iris: data(iris) #model under H0: no difference according to group variable Species (1 just means &quot;fit overall mean&quot;) model_h0 &lt;- lm(Sepal.Width ~ 1, data=iris) #model under H1: each level of group variable Species has its own mean model_h1 &lt;- lm(Sepal.Width ~ Species, data=iris) #compare two models - significant p-value equates to choosing H1 model anova(model_h0,model_h1) ## Analysis of Variance Table ## ## Model 1: Sepal.Width ~ 1 ## Model 2: Sepal.Width ~ Species ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 149 28.307 ## 2 147 16.962 2 11.345 49.16 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Kig på outputtet: Hvilken model reflekterer nulhypotesen? Hvilken model reflekterer alternativhypotesen? Hvor er p-værdien? Er der en signifikant forskel i den gennemsnitlige Sepal.Width efter de forskellige Species? Brug funktionen tapply for at finde ud af, hvad er den middelværdi Sepal.Width til hver af de tre arter. 19) (ANOVA) Lav en lignende analyse på datasættet chickwts for at svare på spørgsmålet: Er der en forskel i den gennemsnitlige vægt (variablen weight) efter fodertypen (variablen feed)? Med andre ord er vægt afhængig af fodertypen? data(chickwts) OBS - hvis du er usikker med linær regression gennemgå gerne videoerne til emnet R Markdown og kom tilbage til følgende spørgsmål 20) (Lineær regression) Brug lm til at lave en simpel lineær regression, således at respons variablen Volume er afhængig af variablen Girth (datasæstet trees). mylm &lt;- lm(???, data=trees) Brug summary på din model for at finde følgende værdier: Hvad er r.squared? (multiple) Er variablen Girth signifikant? Hvad er ligningen på den bedste rette linje (husk formen y = ax + b)? 21) (Kort intro til multiple lineær regression) Tag ovenstående model og tilføj variablen Height som en ekstra prediktær (uafhængig) variabel i modellen med en “+” tegn: mylm_height &lt;- lm(??? ~ ??? + ???, data=trees) summary(mylm_height) Bemærk at det ikke betyder, at de to variabler skal lægges sammen, men at vi gerne vil have både variablerne i modellen som uafhængig variabler (med andre ord er Volume afhængig af både Girth og Height). Benyt summary på modellen og prøv at finde følgende: Hvad er den den (multiple) r.squared værdi? Hvor meget ændre den (multiple) r.squared værdi i forhold til modellen med kun variablen Girth? Er Volume signifikant afhængig af Height (efter at man har taget højde for Girth)? Brug funktionen anova til at sammenligne modellen uden Height med modellen med Height anova(#model without height,#model with height) Bemærk, at i dette tilfælde er p-værdien fra ANOVA samme p-værdi fra summary(mylm_height). "],["rmarkdown.html", "Chapter 2 Introduktion til R Markdown 2.1 Hvad er R Markdown? 2.2 Installere R Markdown 2.3 Videodemonstrationer 2.4 Oprette et nyt dokument i R Markdown 2.5 Skrive baseret tekst 2.6 Knitte kode 2.7 Kode chunks 2.8 R beregninger inden for teksten i dokumentet (‘inline code’) 2.9 Working directory 2.10 Matematik 2.11 Problemstillinger 2.12 Færdig for i dag og næste gang 2.13 Ekstra links", " Chapter 2 Introduktion til R Markdown I dag starter vi med at arbejde med R Markdown. Emnet er kort og er designet til at hjælpe dig med at komme i gang med at bruge R Markdown i praksis. Notaterne inkluderer også nogle ekstra muligheder, så du kan indrette dit dokument efter eget ønske. Der er to videoer tilgængelige - den ene er en “quick-start guide” til at komme i gang, og den anden viser en simpel lineær regression i R Markdown. Hvis du ikke har brug for en genopfriskning, kan du stadig udforske mere af funktionaliteten i R Markdown. Efter quizzerne og problemstillingerne er der en worksheet, hvor du kan øve dig yderligere med de typer opgaver, vi vil se i workshopperne. Fra næste gang (fredag) skifter vi emnet til visualiseringer i ggplot2, og vi vil fortsætte med at bruge R Markdown fremadrettet. 2.1 Hvad er R Markdown? R Markdown er en nem og fleksibel måde at arbejde med R i projekter på. Her kan du kombinere din R-kode, output og tekst i samme dokument og generere et pænt HTML-dokument, som potentielt kan deles med andre. Jeg anbefaler, at du bruger R Markdown til alle opgaver i kurset. OBS: Ved eksamen forventer jeg, at du afleverer et HTML-dokument til mig med din “knittede” kode fra din analyse. 2.2 Installere R Markdown R Markdown er, ligesom R, gratis og ‘open source’. Den fungerer indenfor RStudio and kan installeres ved at bruge den følgende kommando: install.packages(&quot;rmarkdown&quot;) 2.3 Videodemonstrationer Jeg har lavet to videoer, som du kan se nedenfor: Video 1: I denne video viser jeg, hvordan du: opretter et nyt dokument i R Markdown skriver tekst i dokumentet bruger “knit” til at lave et HTML-dokument opretter og kører kodechunks. Link her hvis det ikke virker nedenunder: https://vimeo.com/702416505 ## ## Vedhæfter pakke: &#39;vembedr&#39; ## Det følgende objekt er maskeret fra &#39;package:lubridate&#39;: ## ## hms Video 2: I denne video viser jeg en kort lineær regression analyse: Hvordan man indlæser et datasæt og laver et plot af datasættet En lynhurtig gennemgang af ligningen for en ret linje Hvordan man anvender funktionen lm() til at fitte en lineær model Fortolkning af resultaterne af modellen og deres statistiske betydning. Link her hvis det ikke virker nedenunder: https://vimeo.com/701240044 2.4 Oprette et nyt dokument i R Markdown Man åbner et nyt R Markdown dokument i RStudio ved at klikke på “File” &gt; “New File” &gt; “R Markdown…”. Alternativt kan man klikke på “+” knappen i øverste venstre hjørne af RStudio vinduet og vælge “R Markdown”. Hvordan man åbner et nyt R Markdown dokument Dernæst angiver man en titel (som kan ændres senere hvis nødvendigt) og specificerer, at outputtet skal være i HTML-format. I dette kursus arbejder vi kun med HTML-dokumenter, men der er også andre muligheder, som du er velkommen til at prøve (PDF/Word/Shiny osv.). Hvordan man åbne et nyt R Markdown dokument 2.4.1 YAML Den første sektion af dokument skrives i hvad der kaldes for ‘YAML’. (Dette står for ‘YAML Ain’t Markup Language’). YAML-sektionen bruges til at definere en række indstillinger og metadata for dokumentet, såsom titel, forfatter, dato og outputformat. Denne sektion indrammes typisk af tre bindestreger (—) øverst og nederst: YAML eksempel I dette eksempel angiver vi titlen på rapporten som “test”, forfatterens navn, datoen og outputformatet (HTML-dokument). Du kan tilføje yderligere indstillinger og tilpasse outputformatet ved at ændre eller udvide YAML-headeren. I de fleste tilfælde nøjes vi dog med at bruge standard indstillinger. Hvis man gerne vil lære mere om de forskellige muligheder med YAML, kan man læse her: https://bookdown.org/yihui/rmarkdown/html-document.html Man kan også se en liste af muligheder her på dette cheatsheet: https://www.rstudio.com/wp-content/uploads/2016/03/rmarkdown-cheatsheet-2.0.pdf 2.4.2 Globale options Der er også tekst som ser ud som følgende: Globale muligheder Ved at bruge funktionen opts_chunk$set() kan du angive globale indstillinger, der styrer udseendet af det endelige dokument. I dette tilfælde er de fleste parametre sat til deres ‘default’ eller standardværdier (da de ikke nævnes eksplicit), og echo er den eneste parameter, der har en værdi angivet. Når echo er sat til TRUE, betyder det, at når du “knitter” din kode (processen der omdanner R Markdown-filen til et HTML-dokument, som beskrevet nedenfor), vil både den udførte kode og dens output blive vist i det genererede HTML-dokument. Funktionen opts_chunk$set() giver dig mulighed for at kontrollere adskillige aspekter af dit dokument på en global måde, såsom visning af advarsler og beskeder, cacheindstillinger og grafikindstillinger. For eksempel, advarsler og beskeder undertrykkes ved at sætte warning = FALSE og message = FALSE (du kan selv afprøve dette). Bemærk, at disse globale indstillinger kan overstyres for individuelle kodeblokke, hvis det er nødvendigt. 2.5 Skrive baseret tekst Her er nogle brugbare muligheder for at skrive tekst i opgaverne eller rapporter: *italic* **bold** _italic_ __bold__ italic bold italic bold 2.5.1 Headers Man kan også lave sektioner: # Header 1 ## Header 2 ### Header 3 Caption for the picture. 2.5.2 liste * Item 1 * Item 2 + Item 2a + Item 2b Item 1 Item 2 Item 2a Item 2b 2.6 Knitte kode Du bruger Knit til at omdanne R Markdown-filen til HTML-format. Når du trykker på Knit-knappen, bliver alle kodeblokke i filen udført, og et HTML-dokument genereres og vises. Bemærk, at koden udføres på ny hver gang du knitter, uafhængigt af indholdet i dit aktuelle RStudio-workspace. Det betyder, at hvis du for eksempel har indlæst pakken tidyverse i dit RStudio-arbejdsområde, men har glemt at inkludere library(tidyverse) eksplicit i begyndelsen af dit R Markdown-dokument, vil du modtage en fejlmeddelelse, hvis du bruger funktioner fra tidyverse andre steder i dokumentet. 2.7 Kode chunks Du skriver R-kode inden for såkaldte “chunks” i R Markdown-dokumenter. Du kan oprette en ny kodeblok på flere måder - enten ved at klikke på knappen Insert a new code chunk øverst i RStudio, eller ved at trykke på Cmd+Option+I på tastaturet (hvis du bruger en Mac) eller Ctrl+Alt+I (hvis du bruger Windows). Det er værd at huske denne shortcut/genvej, da det kan spare dig meget tid i det lange løb! Her er et eksempel af en kodechunk: # This is a chunk, let&#39;s write som R code x &lt;- 1 x + 1 ## [1] 2 For at køre en chunk skal du trykke på den grønne pil øverst i højre hjørne af selve chunk’en (der hedder Run Current Chunk når du holder musen over den). Resultatet kan ses lige nedenunder, som vist ovenfor. Bemærk, at når du arbejder med dit R Markdown dokument, er det generelt hurtigere at bruge den grønne pil / Run Current Chunk i stedet for at knitte hele dokumentet hver gang man vil køre kode. Det skyldes, at du her kun kører den enkelte chunk i stedet for hele dokumentet på ny (herunder indlæsning af pakker og eventuelle store filer), som er tilfældet med Knit. 2.7.1 Et godt råd når man arbejder med chunks For længere opgaver er det god praksis løbende at sikre, at du kan generere et HTML-dokument ved at knitte, selvom du kører din chunks lokalt, mens du udvikler din kode. Med andre ord skal du sørge for, at du ikke få alvorlige fejlmeddelelser, der forhindrer din kode i at blive knittet. Det er dit ansvar at sikre, at din kode fungerer som helhed, og at du dermed kan producere et HTML-dokument med din løsninger. 2.7.2 Chunk indstillinger I R Markdown er der mange muligheder for at styre hver enkelt chunk i dit dokument - hvordan skal R håndtere koden med hensyn til evaluering og præsentation (især med hensyn til tabeller og plots) af en bestemt chunk i dit dokument? Det afhænger meget af, hvem du gerne vil viser dit dokument til. For eksempel, i de nuværende kursusnotater vil jeg gerne have generelt, at du ser al min kode (en global indstilling), men nogle gange vil jeg foretrække noget andet - en chunk, der viser noget, jeg ikke vil have kørt, eller ændre på størrelsen på et plotte i en bestemt chunk. For eksempel ser en chunk med indstillingen eval=FALSE sådan ud (fjern # symbolet) #```{r,eval=FALSE} # #``` Her er nogle muligheder (sektionen “Embed code with knitr syntax”): https://www.rstudio.com/wp-content/uploads/2016/03/rmarkdown-cheatsheet-2.0.pdf Her er seks populære muligheder: include = FALSE forhindrer både kode og resultater i at blive vist i den færdige fil. R Markdown kører stadig koden i kodeblokken, og resultaterne kan bruges af andre kodeblokke. echo = FALSE forhindrer koden, men ikke resultaterne, i at blive vist i den færdige fil. Dette er en nyttig måde at integrere figurer på. message = FALSE forhindrer beskeder, der genereres af koden, i at blive vist i den færdige fil. warning = FALSE forhindrer advarsler, der genereres af koden, i at blive vist i den færdige fil. fig.cap = \"...\" tilføjer en billedtekst til grafiske resultater. eval = FALSE evaluerer ikke koden 2.8 R beregninger inden for teksten i dokumentet (‘inline code’) I nogle tilfælde ønsker man køre R kode “inline”, det vil sige, direkte inden for teksten, for eksempel inden for en sætning. Dette gøres ved at skrive på følgende måde: Her er min `kode` Ovenstående ser sådan ud, når det er skrevet direkte inden for teksten: Her er min kode I dette tilfælde, er der ikke noget R kode, der er blevet kørt. Hvis man vil køre R kode inden for teksten, skriver man (for eksempel): Det gennemsnitlige antal af observationer er `r mean(c(5,7,4,6,3,3))` Ovenstående ser sådan ud, når det er skrevet direkte inden for teksten: Det gennemsnitlige antal observationer er 4.6666667 Bemærk, at hvis man glemmer ‘r’, bliver koden ikke kørt: Det gennemsnitlige antal af observationer er `mean(c(5,7,4,6,3,3))` giver: Det gennemsnitlige antal af observationer er mean(c(5,7,4,6,3,3)) At bruge kode inline kan være en stor fordel, når man gerne vil skrive noget om an analyse, hvor man referere til forskellige statistike beregninger, som man har udført i R (eksempelvis en middelværdi eller p-værdi). Hvis man skriver eller kopierer et tal direkte, og datasættet eller analysemetoden ændre sig af en eller anden grund, bliver beregningerne inden for teksten ikke opdateret, og så risikerer man at have en fejl i den endelige rapport. Ved at bruge inline code, så opdateres beregningerne automatisk, uden at man behøver at tænke over det. 2.9 Working directory Bemærk at måden man sætter en working directory er ændleredes i R Markdown i forhold til base-R. Hvis man bruger setwd() i en chunk, sætter man kun den working directory i den pågældende chunk og ikke i de efterfølgende chunks. I R Markdown er standarden (default), at din working directory er mappen, hvor du gemmer din .Rmd fil. Hvis du genre vil bruge andet, kan du tilføje knitr::opts_knit$set(root.dir = '/tmp') til din globale indstillinger chunk øverst i din fil, hvor '/tmp' skal ændres til din ønskede mappe. ```{r, setup, include=FALSE} knitr::opts_knit$set(root.dir = &#39;/tmp&#39;) ``` 2.10 Matematik Man kan også skrive matematik (LaTeX) i R Markdown - for eksempel vil $\\int_0^5 x^2 dx$ se ud som \\(\\int_0^5 x^2 dx\\) i dit HTML-dokument. Jeg forventer ikke, at du lærer LaTeX, men det er af og til brugbart - for eksempel en retlinjet ligning er $y = 3.4x + 2.1$ giver \\(y = 3.4x + 2.1\\) eller en hypotese: $H0: \\mu = 0$ giver \\(H0: \\mu = 0\\). Det er op til dig, hvor meget du bruger matematik i dine egne dokumenter. 2.11 Problemstillinger Der er en kort quiz i Absalon, som hedder “Quiz - R Markdown”. Opret et nyt R Markdown-dokument i RStudio. Prøv at lave en liste og nogle overskrifter i forskellige størrelser. Klik nu på Knit-knappen og kontroller, at et HTML-dokument vises på din skærm. Rediger titlen (som er en del af din YAML-header øverst i din fil) - kald dit dokument “My first R Markdown document” og klik på Knit igen for at se ændringen i dit HTML-dokument. Opret en ny R-kodeblok og tilføj noget kode, for eksempel: x &lt;- rnorm(20,1,2) #make a sample of normally distributed data plot(x) Husk genvejen CMD+OPT+I eller CTRL+WIN+I når man oprette en chunk (det sparer tid) Klik på den grønne pil Prøv også at køre en linje ad gangen med CMD+Enter/CTRL+Enter Lav flere chunks med forskellig kode efter eget valg Klik på “knit” og bemærk, at det tager længere tid at “knit” hver gang du ændrer noget, end når du bare kører chunks individuelt indenfor dit dokument Klik på “hjul”-knappen i øverste højre hjørne af en af dine chunks og prøv at ændre de forskellige chunk-indstillinger. Klik på “knit” for at se, hvad der sker. Hver gang du knitter, laver du et HTML-dokument. Prøv nu at lave en anden type dokument i stedet for - erstat html_document med word_document i YAML (toppen af din .Rmd fil) Se her for endnu flere muligheder: https://bookdown.org/yihui/rmarkdown/output-formats.html Tilføj følgende chunk til dit dokument og klik på “knit”. Få du en fejlmeddelelse? data(mtcars) mtcars %&gt;% filter(cyl==6) Bemærk, at du får en fejlmeddelelse, fordi du endnu ikke har indlæst den nødvendige pakke for at få koden til at virke. Det kan ske, selvom du måske har indlæst pakken i “Console” eller i fanebladet “Packages”. Prøv først at køre “library(tidyverse)” i Console og derfeter prøve at knitte dit dokument igen - du får stadig en fejlmeddelelse. Tilføj library(tidyverse) øverst i din chunk. Nu skulle dit dokument kunne knitte. Erstat linjen output: html_document med følgende i din YAML metadata øverst i din .Rmd fil: output: html_document: code_folding: hide Knit og se hvad, der sker. Erstat hide med show og se forskellen. Brug $ $ til at skrive en ligning ind i teksten i din .Rmd fil. Prøv for eksempel $\\bar{x}_{i} = \\frac{1}{n}\\sum_{i=1}^{n} x_{i}$ og knitte dit dokument for at tjekke, om du får formlen til middelværdien. (Worksheet) På Absalon har jeg lagt en R Markdown (.Rmd) fil kaldet “R Markdown opgave”, som du kan bruge til at starte med at arbejde med R Markdown-baserede opgaver. Det kombinerer koncepter fra det forudgående kapitel om grundlæggende ting i R og statistik. 2.12 Færdig for i dag og næste gang Husk at sende mig eventuelle spørgsmål, som jeg kan svare på enten direkte eller i forelæsning næste gang. Næste gang begynder vi at arbejde vi med R-pakken ggplot2, der bruges til at lave høj kvalitet visualiseringer fra datasæt. 2.13 Ekstra links Her er en ‘quick tour’ https://rmarkdown.rstudio.com/authoring_quick_tour.html Handy R Markdown Cheatsheet: RStudio has published numerous cheatsheets for working with R, including a detailed cheatsheet on using R Markdown! The R Markdown cheatsheet can be accessed from within RStudio by selecting Help &gt; Cheatsheets &gt; R Markdown Cheat Sheet. "],["visual1.html", "Chapter 3 Visualisering - ggplot2 dag 1 3.1 Inledning og videoer 3.2 Transition fra base R til ggplot2 3.3 Vores første ggplot 3.4 Lidt om ggplot2 3.5 Specificere etiketter og titel 3.6 Ændre farver 3.7 Ændre tema 3.8 Forskellige geoms 3.9 Troubleshooting 3.10 Problemstillinger 3.11 Næste gang", " Chapter 3 Visualisering - ggplot2 dag 1 3.1 Inledning og videoer Dette kapitel giver en introduktion til, hvordan man visualiserer data med R-pakken ggplot2. 3.1.1 Læringsmålene for dag 1 I skal være i stand til at: Forstå hvad “Grammar of Graphics” betyder og sammenhængen med den ggplot2-pakke Lære at bruge funktionen ggplot og den relevante geoms (geom_point(), geom_bar(), geom_histogram(), geom_boxplot(), geom_density()) Lave en ‘færdig’ figur med en titel og korrekte etiketter på akserne Begynde at arbejde med farver og temaer 3.1.2 Hvad er ggplot2? De fleste i kurset har brugt funktionen plot(), som er den standard base-R funktion til at lave et plot. Man kan fortsætte med at bruge plotfunktioner fra base-pakken, men det kan være meget tidskrævende, især når man vil lave mere komplekse og pænere plots. En alternativ løsning er pakken ggplot2, som står for “Grammar of Graphics” (se nærmere forklaring nedenfor). ggplot2 er den mest populær pakke fra tidyverse. Som vi vil se i dette kapitel, har den en ret logisk tilgang, hvor man opbygger et plot i forskellige komponenter. Det kan virke uoverskueligt i starten, men når man først har lært det, er det faktisk meget intuitivt. Det nyttige i at lære ggplot2 kan også ses når man begynder at integrere de andre tidyverse-pakker fra kapitel 4. 3.1.3 Brugen af materialerne Jeg har optaget videoer, hvor jeg viser nogle ‘quick-start’ type eksempler i min RStudio. Videoerne er ikke designet til at indeholde alle detaljer, men til at fungere som udgangspunkt for at komme i gang med øvelserne. Vær opmærksom på, at al kode, der vises i videoerne, også kan findes i kursusnotaterne, hvis du selv vil afprøve den. Jeg anbefaler, at du bruger kursusnotaterne som en reference gennem kurset, når man arbejder på opgaverne. Vær også opmærksom på, at jeg nogle gange introducerer nye ting i selve øvelserne. 3.1.4 Video ressourcer I video 1 demonstrerer jeg, hvordan man lave sit første plot med ggplot2. Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/701245598 I video 2 dækker vi boxplots. Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/701245695 I video 3 demonstrerer jeg barplots. Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/704025240 Video 4: Histogram og density plots Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/703699213 3.2 Transition fra base R til ggplot2 Vi starter som udgangspunkt med base-R og viser, hvordan man laver et lignende plot med ggplot2. Til dette formål bruger vi det indbyggede datasæt, der hedder iris. Datasættet er meget berømt, og det er næsten sikkert, at du allerede er stødt på det uden for dette kurus, enten på nettet eller i forbindelse med andre kurser, som handler om R. Datasættet var oprindeligt samlet af statistikeren og biologen Ronald Fisher i 1936 og indeholder 50 stikprøver, der dækker forskellige målinger for hver af tre arter af planten iris (Iris setosa, Iris virginica og Iris Versicolor). Som vi også så i grundlæggende R, kan man indlæse et indbyggede datasæt med hjælp af funktionen data(). data(iris) Først vil vi have et overblik over datasættet. Til at gøre dette bruger vi summary(): summary(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species ## setosa :50 ## versicolor:50 ## virginica :50 ## ## ## Forestil, at vi gerne vil lave et plot, som viser sammenhængen mellem længden og bredden af sepal (bægerblad), eller specifikt er vi interesseret i kolonnerne iris$Sepal.Length og iris$Sepal.Width. Lad os starte med at visualisere variablerne i base-R, ved at bruge plot: plot(iris$Sepal.Length, iris$Sepal.Width) Man kan gøre det meget pænere eksempelvis ved at bruge forskellige farver til at betegne de forskellige arter, eller ved at give en hensigtsmæssig overskrift eller aksenavne. 3.3 Vores første ggplot Vi vil imidlertid fokusere på at lave et lignende plot med pakken ggplot2. Hvis man ikke allerede har gjort det, så husk at indlæse pakken i R for at få nedenstående koder til at virke. #install.packages(&quot;ggplot2&quot;) #hvis ikke allerede installeret library(ggplot2) For at lave et plot med ggplot2 tager man altid udgangspunkt i funktionen ggplot(). Først specificerer vi vores data - altså at vi gerne vil bruge dataframe iris. Dernæst angiver vi indenfor funktionen aes() (som sidder indenfor ggplot()), at x-aksen skal være Sepal.Length og y-aksen Sepal.Width. Det ser sådan ud: ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width)) Koden fungerer, men bemærk, at plottet er helt tomt og derfor ikke særligt brugbart. Men der er skabt et grundlag (se aksenavne osv.). Det er tomt fordi vi endnu ikke har specificeret, hvilken plottype det skal være - for eksempel søljediagram/barplot, histogram, punktplot/scatter plot (jeg vælge de engelske begreber herfra for at skabe den bedste sammenhæng med koden). Vi vil gerne bruge et scatter plot, som i ggplot2 er angivet med funktionen geom_point(). Vi tilslutter derfor funktionen geom_point() til den ggplot() funktion, som vi allerede har specificeret. Husk altid, at man bruger + til at forbinde de to “komponenter” (altså ggplot() og geom_point()) af plottet (ellers få vi fortsat et tomt plot). Koden er således: ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width)) + geom_point() Bemærk, at vi ikke har skrevet noget indeni de runde parenteser i funktionen geom_point(). Det betyder, at vi accepterer alle standard- eller ‘default’ parametre, som funktionen tager. Hvis vi vil have noget andet end de standard parametre, kan vi godt specificere det. For eksempel kan vi gøre punkterne lidt større end ved standarden (prøve at tjekke ?geom_point() for at se en list overfor de mulige parametre, som man kan justere): ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width)) + geom_point(size=3) Vi har nu et plot, som vi kan sammenligne med det ovenstående plot, vi lavet i base-pakken. Ligesom i base-pakken vil vi gerne tilføje nogle ting for at gøre vores plot til vores færdige figur.. Her i ggplot2 gøres det ved at tilføje flere komponenter ovenpå, med brugen af +, ligesom vi gjorde da vi tilføjede geom_point() til ggplot(). Første vil jeg gerne skrive nogle orde om ggplot2 generelt, og filosofien bag. 3.4 Lidt om ggplot2 3.4.1 Syntax Som vi har lige set, ggplot() tager altid udgangspunkt i en dataframe, som vi specificerer først. I ggplot() indeholder den dataframe variablerne vi skal bruge til at få lavet figuren. Til at gøre det til noget mere konkret, lad os sammenligne koden mellem base-pakken og ggplot() til vores iris data. I base-R angav vi direkte vektorer iris$Sepal.Length og iris$Sepal.Width som parametre x og y, der tager henholdsvis først og anden-plads i funktionen plot(). Til gengæld i ggplot(), specificerer man først den hele dataramme i den første plads, og så bagefter med brugen af aes() angav vi hvordan x-aksen og y-aksen ser ud. #baseplot solution plot(iris$Sepal.Length, iris$Sepal.Width) #ggplot2 solution ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width)) + geom_point() En anden fordel af ggplot2() er, at man kan fortsætte med at forbedre plottet ved at tilføje ting ovenpå det eksisterende plot, i hvilket kan beskrives som en lagbaseret tilgang. Dette gøres intuitivt ved at bruge “+”. Man kan derfor starte med noget simpelt, og gradvist opbygge det noget mere kompleks. Dette er uafhængigt af den type plot, vi laver. 3.4.2 Hvad betyder egentlig grammar of graphics? Den gg i ggplot2 står for grammar of graphics, og filosofien er, at man skal definere en sætningsstruktur til de figurer, man laver. Med andre ord består vores figur af forskellige komponenter, som man forbinder med “+”.. Her er en beskrivelse af de forskellige komponenter, som bruges til at opbygge et plot: Data: Datarammer tages altid som udgangspunkt. Aesthetics: Variabler til x-aksen eller y-aksen, farve, form eller størrelse Scale: Skalering af værdier eller repræsentation af flere værdier Geometries: Også kaldet geoms - bestemmer hvilken type plot, der skal laves, som f.eks. søjler, punkter, linjer osv. Statistics: Tilføjer f.eks. mean, median eller kvartiler, som beskriver dataene. Facets: Opretter subplots baseret på flere dimensioner. Coordinate system: Transformerer akser og ændrer afstanden for de viste data. 3.4.3 Globale versus lokale æstetik I de fleste tilfælde bruger man funktionen aes() indenfor ggplot(), hvilket betyder, at variablerne, der er specificeret inden for aes(), gælder globalt over alle komponenter i plottet. Man kan faktisk også skrive en lokal aes() inden for selve geom-funktionen, som i følgende eksempel: ggplot(iris) + geom_point(aes(x=Sepal.Length, y=Sepal.Width)) Vi får det samme plot som før, men det er kun geom_point(), der er påvirket af specificeringen inden for aes(). I simple situationer som dette er der ingen forskel, men når man har mange forskellige komponenter i spil, kan det nogle gange give mening at bruge lokale æstetik. 3.5 Specificere etiketter og titel Vi tager udgangspunkt i plottet, som vi har lavet i ovenstående, og prøver at gøre det bedre ved at tilføje nye etiketter og en titel. I ggplot kan man opdatere y-akse og x-akse etiketter ved at bruge henholdsvis ylab og xlab: ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width)) + geom_point(size=3) + xlab(&quot;Sepal Length&quot;) + ylab(&quot;Sepal Width&quot;) Vi tilføjer en titel med funktionen ggtitle(): ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width)) + geom_point(size=3) + xlab(&quot;Sepal Length&quot;) + ylab(&quot;Sepal Width&quot;) + ggtitle(&quot;Scatter plot of Sepal Width vs Sepal Length&quot;) 3.6 Ændre farver I ggplot2 kan man bruge “automatisk” farver for at skelne mellem de tre forskellige Species i datasættet iris. I den næste lektion vil vi dække, hvordan man kan være mere fleksibel ved at sætte farver manuelt, men ofte vil vi bare bruge den nemme løsning som udgangspunkt og eventuelt rette op på det senere med en ny komponent, hvis der er behov for det. Vi skriver color=Species indenfor aes(), som i følgende eksempel. Bemærk, at der kommer en ‘legend’ med, der fortæller os, hvilken art, der får hvilken farve. ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width,color=Species)) + geom_point(size=3) + xlab(&quot;Sepal Length&quot;) + ylab(&quot;Sepal Width&quot;) + ggtitle(&quot;Scatter plot of Sepal Width vs Sepal Length&quot;) 3.7 Ændre tema Det standard tema har en grå baggrund og “grid” linjer, men man kan godt vælge noget andet. For eksempel kan man tilføje theme_minimal() som i nedenstående eksempel. Her får vi en hvid baggrund i stedet, mens man stadig får grid linjer. Man kan afprøve forskellige temaer (for eksempel theme_classic(), theme_bw()), og se, hvilket tema, der fungerer bedst i det enkelte plot. ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width,color=Species)) + geom_point(size=3) + xlab(&quot;Sepal Length&quot;) + ylab(&quot;Sepal Width&quot;) + ggtitle(&quot;Scatter plot of Sepal Width vs Sepal Length&quot;) + theme_minimal() Her er nogle eksempler på mulige temaer, som du kan bruge i dine plotter (det er dog generelt op til dig). tema theme_grey() theme_classic() theme_bw() theme_dark() theme_minimal() theme_light() Se også her, hvis du er interesseret i flere temaer: https://r-charts.com/ggplot2/themes/ 3.8 Forskellige geoms Indtil videre har vi kun arbejdet med geom_point() for at lave et scatter plot, men der er også andre “geoms”, som kan bruges til forskellige typer af plots. Her er en liste over nogle af de mest almindelige geoms: geom plot geom_point() scatter plot geom_bar() barplot geom_boxplot() boxplot geom_histogram() histogram geom_density() density For at lave disse geoms, skal man tilføje dem til ggplot()-kommandoen ved at bruge +, på samme måde som vi gjorde med geom_point(). Der kan dog være specifikke overvejelser, der er værd at have i tankerne for nogle plot-typer, før man bruger dem. 3.8.1 Boxplot (geom_box) For at lave et boxplot af Sepal.Length opdelt efter Species, angiver vi Species på x-aksen og Sepal.Length på y-aksen. Vi vil også have, at hver art få sin egen farve, så bruger vi fill=Species. ggplot(data=iris, aes(x=Species, y=Sepal.Length,fill=Species)) + geom_boxplot() + ylab(&quot;Sepal Length&quot;) + ggtitle(&quot;Boxplot&quot;) + theme_minimal() Lave punkter ovenpå Det kan ofte være nyttigt at plotte de faktiske datapunkter oven på et boxplot, så man kan se både fordelingen i dataene samt de rå data. En løsning er at benytte geom_point() ved at tilføje det som komponent over vores eksisterende kode. ggplot(data=iris, aes(x=Species, y=Sepal.Length,fill=Species)) + geom_boxplot() + geom_point() + ylab(&quot;Sepal Length&quot;) + ggtitle(&quot;Boxplot with points overlayed&quot;) + theme_minimal() Man kan dog se, at det ikke er særlig informativt, da alle punkter er på den samme lodrette linje. Hvis der er mange punkter med samme eller næsten samme værdier, kan man ikke se de fleste af dem i plottet. En bedre løsning er at indføre noget tilfældighed i punkterne langs x-aksen, så at man tydeligere kan se dem. Dette kaldes “jitter”, og man specificere jitter ved at bruge geom_jitter() i stedet for geom_point(). ggplot(data=iris, aes(x=Species, y=Sepal.Length,fill=Species)) + geom_boxplot() + geom_jitter() + ylab(&quot;Sepal Length&quot;) + ggtitle(&quot;Boxplot with jitter&quot;) + theme_minimal() Man kan også specificere alpha, som gøre punkterne mere gennemsigtige og mindre markante. Man kan også ændre på width, som kontrollerer deres spredning langs x-axsen. ggplot(data=iris, aes(x=Species, y=Sepal.Length,fill=Species)) + geom_boxplot() + geom_jitter(alpha=0.5,width=0.2) + ylab(&quot;Sepal Length&quot;) + ggtitle(&quot;Boxplot with jitter and transparency&quot;) + theme_minimal() Fjerne legend hvis unødvendige Man kan se, at når man specificerer farver, får man en legende på højre side af plottet. I dette tilfælde er det faktisk ikke nødvendigt, da man kan se uden legende, hvad de tre boxplots refererer til. Derfor fjerner vi legenden fra plottet ved at bruge theme(legend.position=\"none\"). ggplot(data=iris, aes(x=Species, y=Sepal.Length,fill=Species)) + geom_boxplot() + geom_jitter() + ylab(&quot;Sepal Length&quot;) + ggtitle(&quot;Boxplot with jitter and no legend&quot;) + theme(legend.position=&quot;none&quot;) 3.8.2 Barplot (geom_bar) Med ggplot() kan man repræsentere data i et barplot ved at bruge geom_bar(). Her vil vi gerne tælle antallet af observationer for hver art (variablen Species) og visualisere dem som søjler. Indenfor geom_bar() specificerer vi derfor stat=\"count\". Vi bruger også fill=Species for at lave en forskellig farve automatisk for hver af de tre arter. Bemærk, at det var color=Species i det forudgående plot, når vi anvendte geom_point(). Det skyldes, at color bruges til punkter og linjer, mens fill er til større områder, der bliver udfyldt, såsom søjler og histogrammer. ggplot(iris, aes(x=Species,fill=Species)) + geom_bar(stat = &quot;count&quot;) + ggtitle(&quot;Number of observations by species&quot;) + theme_minimal() Barplot: stack vs dodge Hvis man har flere katagoriske variabler, kan man lave barplots på forskellige måder. Da der er en ekstra katagorisk variabel i datasættet, laver jeg én, der hedder Sepal.Group, der skelne imellem Long og Short værdier af variablen Sepal.Length. Her specificerer jeg bare (med funktionen ifelse()), at hvis Sepal.Length er længere end den gennemsnitlige Sepal.Length, så er det betragtet Long, ellers er det Short, som i følgende: iris$Sepal.Group &lt;- ifelse(iris$Sepal.Length&gt;mean(iris$Sepal.Length), #test &quot;Long&quot;, #if TRUE &quot;Short&quot;) #if FALSE Når jeg laver en barplot med de to variabler, tilføjer jeg Sepal.Group med fill, og ggplot splitter antal observationer efter Sepal.Group med farver som repræsenterer Sepal.Group, og tilføjer en tilsvarende legende. ggplot(iris, aes(x=Species, fill=Sepal.Group)) + geom_bar(stat = &quot;count&quot;) + ggtitle(&quot;Number of observations by species&quot;) + theme_minimal() Mange gange foretrækker man at få søjlerne stående ved siden af hinanden i stedet for at overlappe. Dette kan opnås ved blot at tilføje position=\"dodge\" ind i geom_bar(). ggplot(iris, aes(x=Species, fill=Sepal.Group)) + geom_bar(stat = &quot;count&quot;, position = &quot;dodge&quot;) + ggtitle(&quot;Number of observations by species&quot;) + theme_minimal() Som et eksempel på fleksibiliteten i pakken ggplot2, kan jeg nævne, at det kan være irriterende, når bredden af søjlen for arten setosa i et barplot er dobbelt så bred som de andre søjler, fordi der ikke er nogen observationer i setosa-gruppen med en “Long” værdi i variablen Sepal.Group. En løsning på dette kan findes ved at tilføje position=position_dodge2(preserve = \"single\") i geom_bar(). Denne parameter gør bredden på alle søjler ens, uanset om der er data i alle kategorier eller ej. ggplot(iris, aes(x=Species, fill=Sepal.Group)) + geom_bar(stat = &quot;count&quot;, position = position_dodge2(preserve = &quot;single&quot;)) + ggtitle(&quot;Number of observations by species&quot;) + theme_minimal() 3.8.3 Histogram (geom_histogram) Et histogram bruges til at give et overblik over, hvordan dataene fordeler sig. Med ggplot2 kan man lave et histogram med geom_histogram(). Den x-akse variabel skal være en kontinuerlig variabel. Her specificerer vi, at vi gerne vil have et histogram for hver art (Species). ggplot(data=iris, aes(x=Sepal.Length, fill=Species)) + geom_histogram() + xlab(&quot;Sepal Length&quot;) + ggtitle(&quot;Iris histogram&quot;) + theme_minimal() Man kan også gøre det nemmere at skelne mellem de tre arter ved at sætte alpha=0.5 inden for geom_histogram og ved at angive en linje farve som mulighed ind i geom_histogram(). ggplot(data=iris, aes(x=Sepal.Length, fill=Species)) + geom_histogram(alpha=0.5,color=&quot;black&quot;) + xlab(&quot;Sepal Length&quot;) + ggtitle(&quot;Iris histogram&quot;) + theme_minimal() 3.8.4 Density (geom_density) Med et density plot kan man, ligesom med et histogram, se fordelingen af dataene i form af en glat eller “smooth” kurve. ggplot(data=iris, aes(x=Sepal.Length, color=Species)) + geom_density() + xlab(&quot;Sepal Length&quot;) + ggtitle(&quot;Density plot&quot;) + theme_minimal() Density plot med fill og gennemsigtig farver Vi kan angive en værdi for alpha indenfor geom_density(). Den parameter alpha specificerer gennemsigtigheden af de density kurver i plottet. ggplot(data=iris, aes(x=Sepal.Length, fill=Species)) + geom_density(alpha=0.5) + xlab(&quot;Sepal Length&quot;) + ggtitle(&quot;Density plot with alpha=0.5&quot;) + theme_minimal() Tilføje middelværdi linjer Vi bruger funktionen tapply() til at beregne middelværdierne af Sepal.Length for hver af de tre Species. Vi kan derefter tilføje dem som lodrette linjer til vores plot. Her bruger vi geom_vline() (OBS det er geom_hline(), hvis man vil have en vandret linje) og fortæller, at xintercept skal være lig med de middelværdier, som vi har beregnet. Parameteren lty=2 betyder, at vi gerne vil have en stiplede (“dashed”) linje. means &lt;- tapply(iris$Sepal.Length,iris$Species,median) ggplot(data=iris, aes(x=Sepal.Length, color=Species)) + geom_density(alpha=0.5) + xlab(&quot;Sepal Length&quot;) + ggtitle(&quot;Density plot with alpha=0.5&quot;) + geom_vline(xintercept = means,lty=2) + theme_minimal() 3.8.5 Line plot (geom_line()) geom_line() kan bruges til at lave linjediagrammer. Her indlæser jeg datasættet population og laver en delmængde til landene i Skandinavien. library(tidyr) data(population) population_scand &lt;- population[population$country %in% c(&quot;Denmark&quot;,&quot;Sweden&quot;,&quot;Norway&quot;,&quot;Finland&quot;),] head(population_scand) ## # A tibble: 6 × 3 ## country year population ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Denmark 1995 5232582 ## 2 Denmark 1996 5254383 ## 3 Denmark 1997 5276683 ## 4 Denmark 1998 5298680 ## 5 Denmark 1999 5319410 ## 6 Denmark 2000 5338283 Når tallene i variablen population er ret store, kan det være en god idé at normalisere, så de betegner befolkningsstørrelser i millioner. population_scand$population &lt;- population_scand$population/1e06 Her laver jeg et plot med geom_line(), så vi kan se udviklingen i befolkningsstørrelserne over tid. For at få det til at virke, skal man huske at angive group inden for aes(), udover at man specificerer farven med colour: ggplot(data = population_scand, aes(x = year, y = population, group = country, colour = country)) + geom_line() + labs(title = &quot;Populations in Scandinavia over time&quot;, x = &quot;År&quot;, y = &quot;Befolkningsstørrelse i millioner&quot;) + theme_minimal() 3.9 Troubleshooting Her er blot en lille liste over nogle ting, der kan forårsage fejl, når man kører kode med ggplot2. Jeg tilføjer også andre ting, som kan opstå i vores lektion :). ggplot(data=iris, aes(....)): Husk her, at data=iris er korrekt og ikke Data=iris (R skelner mellem store og små bogstaver). Man kan også undlade at bruge data= og skrive bare iris i stedet for. Forkert stavning: Dobbelttjek, at du har stavet variabel- eller funktionsnavne korrekt. Glemt +-symbol: For at forbinde komponenterne i plottet skal man huske at tilføje + i slutningen af en linje og skrive de næste komponenter bagefter (man behøver ikke at skrive hver komponent på en ny linje, men det gør det nemmere at læse koden). Skrev %&gt;%-symbolet i stedet for +: De øvrige pakker fra tidyverse bruger %&gt;%. Glemt parentes: Her har man glemt den sidste parentes, der skal være fill=Species)) og ikke fill=Species). Man får bare en +, fordi R forventer, at man fortsætter med at skrive mere kode. &gt; ggplot(data=iris, aes(x=Sepal.Length, fill=Species) + fill og colour - indenfor aes() refererer fill til at man fylder fk. bars eller regioner med farver, og colour referere til farven af linjer eller punkter. 3.10 Problemstillinger 1) Quiz på Absalon - den hedder Quiz - ggplot2 part 1. OBS: Husk at lave følgende øvelser i R Markdown. Det er god praksis at sikre, at jeres dokument kan knitte - i selve eksamen afleverer du et html dokument. Lav et nyt R Markdown-dokument og fjern eksempelkoden. Husk at oprette en ny chunk ved at trykke på “Insert” ny chunk” eller bruge genvejstastene CMD+ALT+I eller CTRL+ALT+I. Jeg anbefaler at oprette en ny chunk for hver plot, I laver. Vi bruger datasættet diamonds. Husk at først indlæse dataene: data(diamonds) Her er beskrivelsen af diamonds: Prices of over 50,000 round cut diamonds: a dataset containing the prices and other attributes of almost 54,000 diamonds. Se også ?diamonds for en beskrivelse af variablerne. 2) Brug datasættet diamonds til at lave et scatter plot (geom_point()): caret på x-aksen price på y-aksen Så at du har noget at sammenligne med, skal dit plot se sådan ud: 3) Tilføj følgende komponenter til dit plot fra 2): En x-akse label (xlab()) og en y-akse label (ylab()) En titel (ggtitle()) Et tema som hedder theme_bw() Husk at forbinde komponenterne med + og skriv de nye komponenter på deres egen linje. Det skal se sådan ud: 4) Ændr temaet på dit plot til theme_classic() eller theme_minimal() i stedet for theme_bw() og se på resultatet. Hvis man (måske ved et uheld) skriver to temaer på samme tid (f.eks. + theme_bw() + theme_classic()), hvilket tema vil så blive anvendt i plottet? Valgfri ekstra: her er nogle flere temaer, du kan prøve: https://ggplot2.tidyverse.org/reference/ggtheme.html 5) Lav det samme plot som i 3), og skriv color=color ind i aes(). Den første color refererer til punkt farver og den anden til variablen color i dataframen. Det skal se sådan ud: Nu fjern color=color fra funktionen aes() og i stedet tilføj aes(color=color) i funktionen geom_point(). Får du samme resultat? Bemærk at det er lige meget om man bruger britisk eller amerikansk stavning i ggplot2 - fk. colour eller color ind i aes() giver samme resultat. 6) Brug stadig diamonds, til at lave et boxplot: cut på x-aksen (giv x-aksen label Cut) price på y-aksen (giv y-aksen label Price of diamond) bruge fill til at give forskellige farver til de mulige værdier af cut. bruge temaet theme_bw() Det skal se sådan ud: Hvordan ser det ud, hvis man bruger colour i stedet for fill? Eller hvis man specificerer begge to? 7) Lav følgende ekstra ændringer til din boxplot fra ovenstående: Tilføj geom_jitter() til din boxplot fjern legend ved at tilføj theme(legend.position=\"none\") Man kan også tilføj show.legend=FALSE til både geom_boxplot() og geom_jitter() i stedet for - prøv det i stedet for at bruge theme(legend.position=\"none\"). Er det nok at tilføje show.legend=FALSE til kun én af de to geoms? Det skal se sådan ud: Man kan også prøve at forbedre plottet ved at give nogle indstillinger ind i geom_jitter(), for eksempel kan man prøve geom_jitter(size=.2,color=\"grey\",alpha=0.5) for at gøre punkter mindre overbelastende i plottet (eller kan man overvejer at fjerne dem). Leg med de tre indstillinger size, color og alpha og se på forskellen. Her er en note om alpha: Alpha refers to the opacity of a geom. Values of alpha range from 0 to 1, with lower values corresponding to more transparent colors. https://ggplot2.tidyverse.org/reference/aes_colour_fill_alpha.html Prøv at skifte rækkefølgerne af geom_jitter() og geom_boxplot() i dit plot kommando og se - gøre det en forskel til, hvordan plottet ser ud? 8) Lav en barplot med indstillingen stat=\"count\": Variablen clarity på x-aksen Forskellige farver til gruppevariablen cut Specificer position=\"dodge\" for at få bars ved siden af hinanden Brug også indstillingen color=\"black\" og noter effekten Tilføj et tema. 9) Lav en histogram Variablen depth på x-aksen Forskellige farver til gruppevariablen cut Brug indstilling alpha til at ændre gennemsigtigheden af søljerne Giv søjlerne en sort ramme Tilføj et tema osv. Det ser sådan ud: Nu får du en advarsel - gør hvad advarselen siger og ændre på parameteren bins ind i geom_histogram()-funktionen. 10) Lav et density plot: Det kan være svært at sammenligne fordelingerne i de tidligere oprettede histograms. Erstat geom_histogram med geom_density i din kode fra 9). Er det nu lettere at sammenligne fordelingerne efter de forskellige niveauer af cut? Tilføj lodrette linjer med beregnede medianværdier af variablen depth for hver af de cut-niveauer. Hint: Brug tapply til at beregne medianværdierne og geom_vline til at tilføje lodrette linjer. 11) Lav et line plot. Åbn datsættet BOD: data(BOD) #BOD: This dataset contains the biochemical oxygen demand (BOD) of water samples taken at different time points. Lav et line plot (geom_line()) variablen Time på x-aksen variablen demand på y-aksen vælg selv ettiketter, title og tema 12 Lav et line plot (geom_line()) Åbn datasættet CO2: data(CO2) Lav en delmængde til typen “Quebec” (variablen Type): CO2_subset &lt;- CO2[CO2$Type==&quot;Quebec&quot;,] Brug din delmængde til at lave et line plot med variablen conc på x-aksen, variablen uptake. Dit plot bør have seks linjer (en til hver Plant) og linjerne farves efter behandlingsmetode (variablen Treatment). 13) En ekstra øvelse: Leg frit med at lave andre plots fra diamonds med ggplot2. For eksempel: Boxplots med carat opdelt efter clarity. Barplots for de forskellige farver (variable color). Et scatter plot af depth vs price. I alle tilfælde, tilføj akse-labels, en titel, et tema osv. 3.11 Næste gang Efter at have lavet disse øvelser vil man kunne se, at der er rigtig meget fleksibilitet involveret i at lave et plot med ggplot2. Næste lektion vil vi fortsætte med andre plot-typer og lære, hvordan man manuelt kan vælge farver. "],["visual2.html", "Chapter 4 Visualisering - ggplot2 dag 2 4.1 Indledning og videoer 4.2 Koordinat systemer 4.3 Mere om farver og punkt former 4.4 Annotations (geom_text) 4.5 Adskille plots med facets (facet_grid/facet_wrap) 4.6 Gemme dit plot 4.7 Problemstillinger", " Chapter 4 Visualisering - ggplot2 dag 2 4.1 Indledning og videoer I det nuværende emne udvider du værktøjskassen af kommandoer i pakken ggplot2, så at du kan opnå større fleksibilitet og appel i dine visualiseringer. Jeg anbefaler, at du bruger notaterne som en form for reference samtidig at du arbejder med problemstillingerne. 4.1.1 Læringsmålene I skal være i stand til at: Arbejde fleksibelt med koordinatsystemer - transformere, modificere og “flippe” x- og y-aksen. Udvide brugen af farver og former. Tilføje tekst direkte på plottet ved hjælpe af geom_text(). Bruge facet_grid() eller facet_wrap() til at opdele plots efter en katagorisk variabel. Gemme dit færdige plot i en fil. library(ggplot2) #husk 4.1.2 Video ressourcer Video 1: Koordinat systemer (2021) Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/544201985 Video 2: Farver og punkt former (2021) Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/544218153 Video 3: Labels - geom_text() og geom_text_repel() (2021) Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/544226498 Video 4 - Facets Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/704140333 4.2 Koordinat systemer Her arbejder vi videre med koordinater i pakken ggplot2. 4.2.1 Zoom (coord_cartesian(), expand_limits()) Man kan bruge funktionen coord_cartesian() til at zoome ind på et bestemt område på plottet. Indenfor coord_cartesian() angives xlim() og ylim(), som specificerer de øvre og nedre grænser langs henholdsvis x-aksen og y-aksen. Man kan også bruge xlim() og ylim() uden om coord_cartesian(), men i dette tilfælde bliver punkterne, som ikke kan ses i plottet (fordi deres koordinater ligger udenfor de angivne grænser), smidt væk (med en advarsel). Med coord_cartesian() beholder man til gengæld samtlige data, og man får således ikke en advarsel. Nedenfor ses vores oprindelige scatter plot: ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width,color = Species)) + geom_point() + theme_minimal() Og her anvender jeg funktionen coord_cartesian() med xlim() og ylim() indenfor til at zoome ind på et ønsket område på plottet. ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width,color = Species)) + geom_point() + coord_cartesian(xlim = c(4,6), ylim = c(2.2,4.5)) + theme_minimal() Du kan også zoome ud ved at bruge expand_limits(). For eksempel, hvis jeg gerne vil have punkterne \\(x = 0\\) og \\(y = 0\\) (c(0,0), eller “origin”) med i selve plottet: ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width,col=Species)) + geom_point() + expand_limits(x = 0, y = 0) + theme_minimal() Det kan være brubart i situationer, hvor man for eksempel har flere etiketter omkring punkterne i selve plottet, som bedre kan ses, hvis man tillader lidt ekstra plads i plottets område. 4.2.2 Transformering af akserne - log, sqrt osv (scale_x_continuous). Nogle gange kan det være svært at visualisere visse variabler på grund af deres fordeling. Hvis der er mange outliers i variablen, vil de fleste punkter samles i et lille område i plottet. Transformering af x-aksen og/eller y-aksen med enten log eller sqrt er især en populær tilgang, så dataene kan ses på en mere informativ måde. ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width,col=Species)) + geom_point(size=3) + scale_x_continuous(trans = &quot;log2&quot;) + scale_y_continuous(trans = &quot;log2&quot;) + theme_minimal() Man kan også prøve at bruge “sqrt” i stedet for “log2”. Formålet er, at hvis dataene fordeler sig mere normalt, kan de nemmere visualiseres i et plot ved at transformere dem med enten “sqrt” eller “log2”. Det er dog vigtigt at bemærke, at dette er forskelligt fra at transformere selve dataene, som bruges i plottet. Jeg kan for eksempel opnå det samme resultat ved at ændre datasættet, før jeg anvender ggplot2. Her behøver jeg ikke at bruge scale_x_continuous(trans = \"log2\"), men jeg bemærker, at tallene på akserne reflekterer de transformerede data og ikke de oprindelige værdier. Beslutningen afhænger af, hvad man gerne vil opnå med analysen af dataene. iris$Sepal.Length &lt;- log2(iris$Sepal.Length) iris$Sepal.Width &lt;- log2(iris$Sepal.Width) ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width,col=Species)) + geom_point(size=3) + theme_minimal() 4.2.3 Flip coordinates (coord_flip) Vi kan bruge coord_flip() til at spejle x-aksen på y-aksen og omvendt (det svarer til at drejer plottet 90 grader). Se følgende eksempel, hvor jeg først opretter variablen Sepal.Group, laver en barplot og anvender coord_flip for at få søjlerne til at stå vandret. #Sepal.Group defineret som i går iris$Sepal.Group &lt;- ifelse(iris$Sepal.Length&gt;mean(iris$Sepal.Length),&quot;Long&quot;,&quot;Short&quot;) ggplot(iris,aes(x=Species,fill=Sepal.Group)) + geom_bar(stat=&quot;count&quot;,position=&quot;dodge&quot;,color=&quot;black&quot;) + coord_flip() + theme_minimal() Man kan ændre rækkefølgen af de tre Species ved at bruge funktionen scale_x_discrete() og angive den nye rækkefølge med indstillingen limits: ggplot(iris,aes(x=Species,fill=Sepal.Group)) + geom_bar(stat=&quot;count&quot;,position=&quot;dodge&quot;,color=&quot;black&quot;) + coord_flip() + scale_x_discrete(limits = c(&quot;virginica&quot;, &quot;versicolor&quot;,&quot;setosa&quot;)) + theme_minimal() 4.3 Mere om farver og punkt former Der er flere måder at specificere farver på i ggplot2. Man kan nøjes med den automatiske løsning, som er hurtig (og effektiv i mange situationer), eller man kan bruge den manuelle løsning, som tager lidt længere tid at kode, men er brugbar, hvis man gerne vil lave et plot til at præsentere for andre. 4.3.1 Automatisk farver Vi i det sidste emne, at man automatisk kan få forskellige farver ved at benytte colour=Species indenfor aes() i den ggplot() funktion. #automatisk løsning ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, colour=Species)) + geom_point() + theme_minimal() 4.3.2 Manuelle farver Hvis man foretrækker at bruge sine egne farver, kan man gøre det ved at benytte funktionen scale_colour_manual(). Her angiver man stadig colour=Species indenfor aes(), men man angiver derefter, hvilke bestemte farver de forskellige arter skal have indenfor scale_colour_manual, med indstillingen values. #manuelt løsning ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, colour=Species)) + scale_colour_manual(values=c(&quot;purple&quot;, &quot;yellow&quot;,&quot;pink&quot;)) + geom_point() + theme_minimal() En fantastisk pakke er RColorBrewer. Pakken indeholder mange forskellige “colour palettes”, det vil sige grupper af farver, der passer godt sammen. Man kan derfor slippe for selv at skulle sammensætte en farvekombination, der passer til plottet. Nogle af farvepaletterne tager også hensyn til, om man er farveblind, eller om man ønsker en farvegradient eller et sæt diskrete farver, som ikke ligner hinanden. I følgende eksempel indlæser jeg pakken RColorBrewer og anvender funktionen scale_colour_brewer med indstillingen palette=\"Set1\": #install.packages(&quot;RColorBrewer&quot;) library(RColorBrewer) #manuelt løsning ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, colour=Species)) + scale_colour_brewer(palette=&quot;Set1&quot;) + geom_point() + theme_minimal() Bemærk, at både scale_color_manual() og scale_color_brewer() bruges til at sætte farver på punkter og linjer, mens man i sammenhænge med boxplots eller barplots bruger scale_fill_manual() eller scale_fill_brewer() til at sætte farver på de udfyldte områder. For eksempel vil jeg i følgende eksempel gerne sætte farver på de udfyldte områder i en boxplot: ggplot(iris,aes(x=Species,y=Sepal.Length,fill=Species)) + geom_boxplot() + scale_fill_brewer(palette=&quot;Set2&quot;) + theme_minimal() Her er en oversigt over de fire funktioner: Funktion Beskrivelse scale_fill_manual(values=c(\"firebrick3\",\"blue\")) Bruges til manuelle farver i forbindelse med boxplots og barplots mv. scale_color_manual(values=c(\"darkorchid\",\"cyan4\")) Bruges til manuelle farver i forbindelse med punkter og linjer mv. scale_fill_brewer(palette=\"Dark2\") Bruger farvepaletter fra RColorBrewer i forbindelse med boxplots, barplots mv. scale_color_brewer(palette=\"Set1\") Bruger farvepaletter fra RColorBrewer i forbindelse med punkter og linjer mv. Der er også andre muligheder, hvis man har behov for dem - for eksempel kan man google efter scale_fill_gradient til kontinuerte data. Farver i RColourBrewer Her er en nyttig reference, der viser de forskellige farver tilgængelige i pakken RColourBrewer. Mulige colour palettes tilgængelige i RColourBrewer 4.3.3 Punkt former Ligesom man kan lave forskellige farver, kan man også lave forskellige punktformer. Vi starter med den automatiske løsning ligesom vi gjorde med farver. Når det er en variabel, vi angiver, skal variabelnavnet skrives indenfor aes(). Her, da shape er en parameter, der er meget specifik for geom_point, vælger jeg at skrive en ny aes() indenfor geom_point() i stedet for indenfor funktionen ggplot(). Husk, at man i funktionen ggplot() specificerer globale ting, der gælder for hele plottet, mens man i funktionen geom_point() angiver ting, der kun gælder for geom_point(). Se følgende eksempel: ggplot(data=iris, aes(x = Sepal.Length, y = Sepal.Width)) + scale_color_brewer(palette=&quot;Set2&quot;) + geom_point(aes(shape=Species)) + theme_minimal() Nu har jeg fået både en farve og en punkt form til hver art i variablen Species. Sætte punkt form manuelt Hvis vi ikke kan lide de tre automatiske punktformer, kan vi ændre dem ved at bruge scale_shape_manual. Her vælger jeg for eksempel values=c(1,2,3), men der er en reference nedenfor, hvor du kan se, mappingen mellem de numeriske tal og punktformer, så du kan vælge dine egne. ggplot(data=iris, aes(x = Sepal.Length, y = Sepal.Width, colour=Species)) + geom_point(aes(shape=Species)) + scale_color_brewer(palette=&quot;Set2&quot;) + scale_shape_manual(values=c(1,2,3)) + theme_minimal() Reference for punkt former Her er reference-tabellen for forskellige punktformer i ggplot2: 4.4 Annotations (geom_text) 4.4.1 Tilføjelse af labels direkte på plottet. Man kan bruge geom_text() til at tilføje tekst på punkterne direkte på plottet. Her skal man fortælle, hvad teksten skal være - i dette tilfælde specificerer vi navnene på biler fra datasættet mtcars. Plottet er et scatterplot mellem variablerne mpg og wt. data(mtcars) mtcars$my_labels &lt;- row.names(mtcars) #take row names and set as a variable ggplot(mtcars,aes(x=mpg,y=wt)) + geom_point() + geom_text(aes(label=my_labels)) + theme_minimal() For at gøre det nemmere at læse kan man også fjerne selve punkterne: ggplot(mtcars,aes(x=mpg,y=wt)) + #geom_point() + geom_text(aes(label=my_labels)) + theme_minimal() Teksten på plottet kan stadig være svær at læse. En god løsning kan være at bruge R-pakken ggrepel, som vist i følgende eksempel: 4.4.2 Pakken ggrepel for at tilføje tekst labeller #install.packages(ggrepel) #installere hvis nødvendeigt For at anvende pakken ggrepel på datasættet mtcars, skal man blot erstatte geom_text() med geom_text_repel(): library(ggrepel) ggplot(mtcars,aes(x=mpg,y=wt)) + geom_point() + geom_text_repel(aes(label=my_labels)) + theme_minimal() ## Warning: ggrepel: 9 unlabeled data points (too many overlaps). Consider ## increasing max.overlaps Nu kan vi se, at der ikke er nogen labels, som sidder lige overfor hinanden, fordi ggrepel() har været dygtig nok til at placere dem tæt på deres tilhørende punkter, og ikke ovenpå hinanden. Der er også nogle punkter, hvor funktionen har tilføjet en linje for at gøre det klart, hvilken punkt teksten refererer til. Vi har dog fået en advarsel i ovenstående kode. Hvis vi vil undgå denne advarsel, kan vi specificere max.overlaps = 20. library(ggrepel) ggplot(mtcars,aes(x=mpg,y=wt)) + geom_point() + geom_text_repel(aes(label=my_labels),max.overlaps = 20) + theme_minimal() Nu kan du se, at du ikke længere får en advarsel, og der er tilføjet tekst til alle punkterne. 4.4.3 Tilføjelse af rektangler i regioner af interesse (annotate) Hvis man gerne vil fremhæve et bestemt område i plottet, kan man bruge funktionen annotate(). Prøv selv at regne ud, hvad de indstillinger inden for annotate() betyder i følgende eksempel: ggplot(mtcars,aes(x=mpg,y=wt)) + geom_point() + geom_text_repel(aes(label=my_labels)) + annotate(&quot;rect&quot;,xmin=18,xmax=23,ymin=2.5,ymax=3,alpha=0.2,fill=&quot;orange&quot;) + theme_minimal() ## Warning: ggrepel: 9 unlabeled data points (too many overlaps). Consider ## increasing max.overlaps Man kan også benytte den samme funktion til at tilføje tekst på et bestemt sted: ggplot(mtcars,aes(x=mpg,y=wt)) + geom_point() + geom_text_repel(aes(label=my_labels)) + annotate(&quot;rect&quot;,xmin=18,xmax=23,ymin=2.5,ymax=3,alpha=0.2,fill=&quot;orange&quot;) + annotate(&quot;text&quot;,x=25,y=2.75,label=&quot;Cars of interest&quot;,col=&quot;orange&quot;) + theme_minimal() ## Warning: ggrepel: 9 unlabeled data points (too many overlaps). Consider ## increasing max.overlaps 4.5 Adskille plots med facets (facet_grid/facet_wrap) En stor fordel ved at bruge ggplot er evnen til at bruge funktionerne facet_grid() og facet_wrap() til at adskille efter en kategorisk variabel over flere plots. I følgende kode viser jeg et density plot, hvor de tre kurver, der tilhører de tre arter, ligger oven på hinanden i det samme plot: ggplot(iris,aes(x=Sepal.Length,fill=Species)) + geom_density(alpha=0.5) + theme_minimal() Med funktionerne facet_grid() eller facet_wrap() bruger vi ~ (tilde) til at angive, hvordan vi gerne vil visualisere de forskellige plots. Vi skal angive, om vi ønsker at opdele dem over rækker (variablerne venstre for ~) eller over kolonner (variablerne til højre for ~). #notrun variable(s) to split into row-wise plots ~ variables(s) to split into column-wise plots Ovenstående density plots af Sepal.Length kan adskilles efter Species, således at man får tre plots med en kolonne til hver af de tre arter ved hjælp af facet_wrap() funktionen: ggplot(iris,aes(x=Sepal.Length,fill=Species)) + geom_density(alpha=0.5) + facet_grid(~Species) + #split Species into different column-wise plots theme_minimal() Man kan også vælge at adskille plotsne over rækkerne ved hjælp af facet_wrap(). Her skal man dog huske at bruge en . efter ~ for at betegne, at man kun vil adskille plots over rækkerne, mens man af en eller anden grund kan droppe . hvis man kun vil adskille over kolonner som i det foregående eksempel. ggplot(iris,aes(x=Sepal.Length,fill=Species)) + geom_density(alpha=0.5) + facet_grid(Species~.) + #split Species into different column-wise plots theme_minimal() Her angives Sepal.Group ~ Species, hvilket betyder, at plotterne bliver adskilt efter både Sepal.Group og Species - Sepal.Group over rækkerne og Species over kolonnerne - ved hjælp af facet_grid() funktionen: ggplot(iris,aes(x=Sepal.Length,fill=Species)) + geom_density(alpha=0.5) + facet_grid(Sepal.Group~Species) + #split Species into different column-wise plots theme_minimal() Bemærk forskellen mellem facet_grid() og facet_wrap(): #same plot, replace facet_grid with facet_wrap ggplot(iris,aes(x=Sepal.Length,fill=Species)) + geom_density(alpha=0.5) + facet_wrap(Sepal.Group~Species) + theme_minimal() I facet_grid() bliver man tvunget til at få et “grid” layout. Vi har således 6 plot i en 2 x 3 grid (2 niveauer for variablen Sepal.Group og 3 niveauer for variablen Species), og det sker selvom den ene af dem ikke har nogen data - der findes altså ikke observationer, hvor Species er “Setosa” og Sepal.Group er “Long”, men vi får et plot alligevel for at bevare strukturen. Med facet_wrap() bliver plot uden data droppet, og i dette tilfælde får man 5 plot i, hvad der kaldes en “ribbon”. Med facet_wrap() kan man også angive antallet af rækker og kolonner man vil have for plotterne. For eksempel kan man angive nrow = 1 eller ncol = 5 for at få alle fem plots på en række. ggplot(iris,aes(x=Sepal.Length,fill=Species)) + geom_density(alpha=0.5) + facet_wrap(Sepal.Group~Species,nrow = 1) + theme_minimal() Til sidst kan det være, at jeg gerne vil frigøre skalaen på y-aksen. På den måde har ikke alle plot de samme maksimale y-værdier, og de enkelte plot benytter i stedet egne værdier til at bestemme skalaen. Det kan være brugbart, hvis man inddrager forskellige målinger, men vær dog opmærksom på, hvad der bedst giver mening - hvis man direkte vil sammenligne to af plotterne, så er det bedre, at de deler samme y-akseskala. #same plot, replace facet_grid with facet_wrap ggplot(iris,aes(x=Sepal.Length,fill=Species)) + geom_density(alpha=0.5) + facet_wrap(Sepal.Group~Species,ncol = 5,scales = &quot;free&quot;) + theme_minimal() Jeg håber, det er klart, at disse funktioner er meget brugbare, og selvom de opnår stort set samme resultat, er der små forskelle mellem dem, som det er værd at huske. 4.6 Gemme dit plot Her bruger vi R Markdown til at lave en rapport, som indeholder vores plots, men det kan også være, at man gerne vil gemme sit plot som en fil på computeren. Til at gemme et plot kan man bruge kommandoen ggsave(): ggsave(myplot, &quot;myplot.pdf&quot;) Figuren vil blive gemt i din working directory (eller den mappe, hvor din .Rmd fil ligger). Filtypen .pdf kan erstattes med andre formater, f.eks. .png eller .jpeg. Hvis man gerne vil redigere sit plot (f.eks. i Adobe Illustrator eller Inkscape), vil jeg anbefale at gemme det som .pdf. Man må gerne ændre højden og bredden på det gemt plot med width og height: ggsave(myplot, &quot;myplot.pdf&quot;, width = 4, height = 4) 4.7 Problemstillinger Problem 1) Lav quiz - “Quiz - ggplot2 part 2” Problem 2) (Factorer og plots) a) Åbn datasættet mtcars og lav en barplot: Brug variablen cyl på x-aksen og tildele forskellige farver til de forskellige niveauer af samme variablen. Fungerer din kode? Tjek x-aksen. Variablen er numerisk, men skal fortolkes som en faktor. Konverter variablen til en faktor (eller bare skriv as.factor(cyl) i selve plottet) og lav dit plot igen. b) Opdel søjlerne ved at angive farver efter variablen gear i dit plot (søjlerne skal sidde ved siden af hinanden). Vær OBS på, hvordan R fortolker variablen. ggplot(data = mtcars, aes(x = cyl,fill = (gear))) + geom_bar(stat=&quot;count&quot;,position=&quot;dodge&quot;) + theme_minimal() ## Warning: The following aesthetics were dropped during statistical transformation: fill ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? I følgende spørgsmål arbejder du med datasættet Palmer Penguins. Pakken palmerpenguins skal installeres hvis du ikke har brugt datasættet før. Data beskrivelse: The palmerpenguins data contains size measurements for three penguin species observed on three islands in the Palmer Archipelago, Antarctica. #install.packages(&quot;palmerpenguins&quot;) #køre hvis ikke allerede installeret library(palmerpenguins) library(ggplot2) library(tidyverse) head(penguins) FALSE # A tibble: 6 × 8 FALSE species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g FALSE &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; FALSE 1 Adelie Torgersen 39.1 18.7 181 3750 FALSE 2 Adelie Torgersen 39.5 17.4 186 3800 FALSE 3 Adelie Torgersen 40.3 18 195 3250 FALSE 4 Adelie Torgersen NA NA NA NA FALSE 5 Adelie Torgersen 36.7 19.3 193 3450 FALSE 6 Adelie Torgersen 39.3 20.6 190 3650 FALSE # ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt; Man kan altid anvende ?penguins for at se flere detaljer om variablenavner. Vi skal starte med at rydde op lidt i datasættet. Køre følgende for at fjerne al rækker som har NA (manglende) værdier (her skal man have tidyverse-pakken indlæste): penguins &lt;- drop_na(penguins) Problem 3) Manuelt farver og punkter a) Lav et scatter plot med ggplot()-funktionen: bill_length_mm på x-aksen bill_depth_mm på y-aksen giv hver art (variablen species) sin egen farve (brug den automatiske løsning) sæt et tema b) Lav følgende ændringer til dit plot fra a): Ændr farver manuelt - prøv både at angive farver med scale_color_manual() og afprøve også løsningen med pakken RColorBrewer (husk at installere/indlæse pakken, hvis nødvendigt). Brug forskellige punkt-former til hver art i variablen species. Prøv også at vælge nogle punkt-former fra listen (i kursusnotaterne) og specificer dem manuelt. Figure 4.1: Min løsning Problem 4) Koordinatsystemer Tag udgangspunkt i overstående scatter plot fra 3) og a) brug coord_cartesian(), så kun pingviner med en bill længde (variablen bill_length_mm) mellem 40 og 50 og en bill depth (variablen bill_depth_mm) mellem 16 og 19 er medtaget på plottet. b) brug pakken ggrepel (husk at installere/indlæse) og tilføj navnene på de forskellige øer som tekst direkte på plottet c) lav en delmængde af datasættet penguins efter samme betingelser som i a) og specificer din nye dataframe som parameteren data indenfor geom_text_repel()-funktionen. Dette undgår, at tekst bliver plottet for punkter udenfor området angivet med coord_cartesian(). ## Warning: ggrepel: 14 unlabeled data points (too many overlaps). Consider ## increasing max.overlaps Figure 4.2: Min løsning Problem 5) Histogram med facets Lav et histogram: Variablen flipper_length_mm på x-aksen Anvend facet_grid for at adskille dit plot i tre efter variablen species Giv også en forskellig farve til hver art i species Hvis nødvendigt, ændr parameteren bins til noget andet indenfor geom_histogram(). Her er min løsning: Problem 6) a) Lav et density plot af body_mass_g. Anvend funktionen facet_grid til at lave tre plots, en til hver art i variablen species Brug også fill til at opdele hver af dine tre density kurver efter variablen sex (dvs. du har stadig 3 plots, og hvert plot har to density kurver) Gør dine density plots gennemsigtige Skriv en sætning om forskellen i body_mass_g mellem “females” og “males”. b) Nu udvikl din facet_grid kommando til at adskille plots yderligere således at du har en “grid” struktur med de forskellige øer (variablen island) på rækkerne og de tre arter (variablen species) på kolonnerne. c) Kan du forklare, hvorfor der er blanke plots i din grid? Eksperimenter med facet_wrap i stedet for facet_grid. Problem 7) Koordinatsystemer Lav et søjlediagram af antallet for species opdelt efter sex. Anvend en ‘coordinate flip’ for at få den til at være vandret/horizontal. Vælg nogle farver - jeg benytter palette = \"Accent\" fra RColorBrewer løsningen Ændr rækkefølgen af de tre søjler, således at arten med flest observationer er øverst, og arten med færrest er nederst. Prøv også at tilføje scale_y_reverse() og kig på resultatet. Her er min løsning: Figure 4.3: Min løsning Problem 8) Lav boxplots af body_mass_g opdelt efter species. Tilføj “jitter” punkter ovenpå boksplot. Specificer nogle farver manuelt for både bokse og punkterne (en farve til hver art) Giv det en passende titel og nogle akse-etiketter Tilføj en ny variabel island_binary til penguins, som er “Biscoe” hvis island er ‘Biscoe’ og “not Biscoe” hvis ikke. Adskil plotterne ved at opdele efter island_binary. Ekstra: prøv ?geom_violin som erstatning for geom_boxplot. Problem 9) Annotationer og linjer. a) Lav et scatterplot af bill_length_mm vs bill_depth_mm. Anvend passende titel/etiketter/tema Anvend forskellige farver for de tre species. Tjek funktionen ?annotate og brug den med geom=\"text\" og passende x- og y-akse værdier til at tilføje species navne som tekst direkte på plottet (se eksempel nedenfor for at se, hvad jeg mener). Udforsk, hvordan man gør teksten større, som jeg har gjort i min løsning. Fjern legenden med show.legend = FALSE indenfor geom_point() Her er min løsning: b) Vi vil gerne tilføje nogle lodrette og vandrette linjer til plottet, som viser gennemsnitsværdierne for variablerne for de tre arter. Først skal du bruge tapply til at beregne de gennemsnitlige værdier for henholdsvis bill_length_mm og bill_depth_mm opdelt efter species (gem dem som henholdsvis mean_length og mean_depth). Brug mean_length og mean_depth til at tilføje linjer til plottet med den relevante funktion. c) Kan du tilpasse linjerne så deres farver matcher punkterne for deres respektive art (se min løsning nedenfor)? Der er sikkert mange måder at gøre det på, men hvis du har brug for en hint, kan du kigge nedenunder: Hint: start med følgende dataframe, der bruger dine beregnede værdier: mydf &lt;- data.frame(&quot;species&quot;=names(mean_length), &quot;mlength&quot;=mean_length, &quot;mdepth&quot;=mean_depth) mydf ## species mlength mdepth ## Adelie Adelie 38.82397 18.34726 ## Chinstrap Chinstrap 48.83382 18.42059 ## Gentoo Gentoo 47.56807 14.99664 Angiv parameteren data til at være ovenstående dataframe i geom_vline() og brug lokal æstetik (aes()) til at angive parametre til linjerne. Gør det samme for geom_hline() Specificer også “stiplede” linjer Her er min løsning: Figure 4.4: min løsning Problem 10) Ekstra. Kig på “cheatsheet” for ggplot2 (klik på “Help” &gt; “Cheatsheets” og vælg den for ggplot2) og afprøv nogle af de ting, som ikke er blevet dækket i kurset indtil videre! Jeg vil gerne høre, hvis du finder noget meget nyttigt for dig, som ellers er blevet glemt i notaterne. "],["data.html", "Chapter 5 Bearbejdning dag 1 5.1 Hvad er Tidyverse? 5.2 Video ressourcer 5.3 Oversigt over pakker 5.4 Principper for ‘tidy data’ 5.5 Lidt om tibbles 5.6 Transition fra base-R til tidyverse 5.7 Bearbejdning af data: dplyr 5.8 Visualisering: bruge som input i ggplot2 5.9 Misc funktioner som er nyttige at vide 5.10 Problemstillinger 5.11 Kommentarer", " Chapter 5 Bearbejdning dag 1 5.1 Hvad er Tidyverse? Tidyverse er en samling af pakker i R, som man bruger til at bearbejde datasæt. Formålet er ikke nødvendigvis at erstatte funktionaliteten af base-pakken, men til at bygge videre på den. Som vi vil se i detaljer, deler tidyverse faktisk mange af de samme principper som ggplot2 - men i stedet for at bruge + til at opbygge komponenter i et plot, bruger man %&gt;% (udtales ‘pipe’) til at kæde forskellige funktioner sammen. Most common tidyverse packages Læringsmålene til i dag I skal være i stand til at: Beskrive generelt, hvad R-pakken Tidyverse kan bruges til. Beskrive en tibble og genkende når et datasæt er betragtet som “tidy”. Benytte nogle vigtige Tidyverse-verbs til at bearbejde data (filter(),select(), mutate(), rename(), arrange(), recode()). Bruge %&gt;% til at forbinde Tidyverse-verber sammen og at overføre data til et plot. 5.2 Video ressourcer __Begynd med at læse “Principper for ‘tidy data’” og “Lidt om tibbles” nedenfor og derefter se følgende videoer. Video 1 - rydde op i datasættet titanic med select() og drop_na() Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/706266697 Video 2 - tidyverse verber: select og filter Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/705136725 Video 3 - flere tidyverse verber Lave en ny kolon med mutate() Ændre variabelnavne med rename() Ændre på værdierne med recode() Ændre rækkefølgen af observationerne med arrange() Bruge tidyverse kommandoer som input i ggplot2() Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/706266885 5.3 Oversigt over pakker Lad os starte med at indlæse pakken tidyverse. Vær opmærksom på, at hvis du ikke allerede har pakken på din computer, kan det tage lidt tid at installere den da tidyverse er afhængig af mange andre pakker, som også skal installeres eller opdateres. Hvis du allerede har pakken installeret, men oplever problemer, skal du tjekke, om du har det seneste version af pakkerne og R på dit system. #install.packages(&quot;tidyverse) library(tidyverse) Du kan se, at der faktisk ikke kun er én, men otte pakker, der er blevet indlæst. Det er muligt at indlæse hver pakke individuelt ved at bruge fx library(dplyr), men det er meget bekvemt at indlæse dem alle på én gang ved at bruge library(tidyverse). Her er en kort beskrivelse af hver pakke: Pakke Kort beskrivelse readr Indlæsning af data ggplot2 Plotning af data tibble Oprettelse af “tibbles” - tidyverse’s svar på datarammer (data.frame). tidyr Transformation af data til forskellige formater (fx fra ‘long’ til ‘wide’ format eller omvendt) purrr Functional programming, gentagelse dplyr Manipulation af tibbles - udvælgelse af undergrupper, oprettelse af nye variabler, beregning af oversigtsstatistikker osv. stringr Manipulation af strenge (ikke brugt i dette kursus) forcats Håndtering af faktorvariabler (også kaldet “categories”) 5.4 Principper for ‘tidy data’ Idéen bag tidyverse er, at hvis alle datasæt følger præcis den samme struktur, så er det enkelt at bearbejde dem præcis som vi ønsker det. Datasæt med denne struktur kaldes “tidy data”. For at betragte et datasæt som “tidy” skal det opfylde tre kriterier: Hver variabel i datasættet har sin egen kolonne Hver observation i datasættet har sin egen række Hver værdi i datasættet har sin egen celle Et godt eksempel på et datasæt i tidy format er Iris-datasættet: data(iris) head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa I datasættet har hver variabel (Sepal.Length, Sepal.Width, Petal.Length, Petal.Width og Species) sin egen kolonne, og hver observation (fx observation 1, 2, 3, osv.) har sin egen række. Derudover har hver celle sin egen værdi, hvilket gør datasættet meget læsbart og let at forstå ved blot at kigge på det. Principper af tidy data Det er tilfældet, at de fleste datasæt i dette kursus hører til kategorien “tidy data”, især i disse notater, hvor vi bruger en del af de indbyggede datasæt. Nogle gange er det dog nødvendigt at transformere et datasæt til “tidy data”. R-pakkerne dplyr og tidyr er velegnede til at hjælpe med at transformere et datasæt til “tidy data”, og derefter kan man analysere datasættet på sædvanlig vis. Bemærk dog, at bare fordi et datasæt er “tidy”, betyder det ikke nødvendigvis, at det er klar til analyse, da der stadig kan være behov for yderligere bearbejdning med pakkerne dplyr og tidyr. 5.5 Lidt om tibbles En tibble er tidyverse’s svar på en data.frame fra base-R. De ligner meget hinanden, og derfor behøver man ikke tænke så meget over forskellen. Men der er nogle opdaterede aspekter i en tibble. For eksempel bruger en tibble ikke row.names, og når man visualiserer en tibble i R Markdown, får man lidt ekstra oplysninger såsom dimensioner og datatyper. Det er vigtigt at bemærke, at de fleste tidyverse-funktioner fungerer lige så godt, uanset om man bruger en tibble eller en data.frame. Det er dog vigtigt at bemærke, at jeg vil bruge ordet “data frame” inden for almindelig tekst. Man kan oprette sin egen tibble på samme måde som en data.frame. tibble(x = 1:3, y = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)) ## # A tibble: 3 × 2 ## x y ## &lt;int&gt; &lt;chr&gt; ## 1 1 a ## 2 2 b ## 3 3 c Man kan også oprette en tribble, som er den samme som en tibble, men har en lidt anderledes måde at indsætte data på. For eksempel svarer følgende til den tidligere tibble: tribble(~x, ~y, 1, &quot;a&quot;, 2, &quot;b&quot;, 3, &quot;c&quot;) ## # A tibble: 3 × 2 ## x y ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 a ## 2 2 b ## 3 3 c Man kan omdanne en data.frame til en tibble ved at bruge funktionen as_tibble(), som vist nedenfor: as_tibble(iris) ## # A tibble: 150 × 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # ℹ 140 more rows 5.6 Transition fra base-R til tidyverse Jeg introducerer tidyverse med et meget berømt datasæt kaldet Titanic. Det er ikke biologisk data, men det er stadig ret interessant og sjovt at arbejde med. Titanic-datasættet er blevet brugt som en del af en åben konkurrence på Kaggle, hvor mindst 31.000 personer hidtil har arbejdet på at lave den bedste model til at forudsige, hvem der overlever katastrofen. Du kan læse mere om baggrunden for datasættet og konkurrencen på dette link: https://www.kaggle.com/c/titanic. 5.6.1 Om Titanic datasættet Man kan downloade datasættet, der hedder titanic_train, direkte fra Kaggle. Men der er faktisk en R-pakke kaldet titanic, som gør det mere bekvemt: #install.packages(&quot;titanic&quot;) #hvis ikke allerede installerede library(titanic) Her er beskrivelsen for pakken: titanic is an R package containing data sets providing information on the fate of passengers on the fatal maiden voyage of the ocean liner “Titanic”, summarized according to economic status (class), sex, age and survival. These data sets are often used as an introduction to machine learning on Kaggle. Vi vil gerne bruge titanic_train-datasættet, fordi det er det datasæt, der bliver brugt på Kaggle til at træne maskinlæringsmodeller (som derefter bliver testet på titanic_test-datasættet for at evaluere, hvor god modellen er). For at gøre tingene nemmere, vil vi blot omdøbe titanic_train til titanic og bruge funktionen glimpse() fra dplyr-pakken til at se på datasættet. titanic &lt;- as_tibble(titanic_train) glimpse(titanic) ## Rows: 891 ## Columns: 12 ## $ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,… ## $ Survived &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1… ## $ Pclass &lt;int&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3… ## $ Name &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bradley (Fl… ## $ Sex &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;mal… ## $ Age &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, … ## $ SibSp &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0… ## $ Parch &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0… ## $ Ticket &lt;chr&gt; &quot;A/5 21171&quot;, &quot;PC 17599&quot;, &quot;STON/O2. 3101282&quot;, &quot;113803&quot;, &quot;37… ## $ Fare &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,… ## $ Cabin &lt;chr&gt; &quot;&quot;, &quot;C85&quot;, &quot;&quot;, &quot;C123&quot;, &quot;&quot;, &quot;&quot;, &quot;E46&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;G6&quot;, &quot;C… ## $ Embarked &lt;chr&gt; &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;Q&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;… Jeg har også kopieret de variable beskrivelser her: PassengerId: unique index for each passenger Survived: Whether or not the passenger survived. 0 = No, 1 = Yes. Pclass: Ticket class: 1 = 1st Class, 2 = 2nd Class, 3 = 3rd Class. Name: A character string containing the name of each passenger. Sex: Character strings for passenger sex (“male”/ “female”). Age: Age in years. SibSp: The number of siblings/spouses aboard the titanic with the passenger Parch: The number of parents/children aboard the titanic with the passenger Ticket: Another character string containing the ticket ID of the passenger. Fare: The price paid for tickets in pounds Sterling (Keep in mind that unskilled workers made around 1 pound a week - these were expensive tickets!) Cabin: The cabin number of the passengers (character). Embarked: Where passengers boarded the titanic. C = Cherbourg, Q = Queenstown, S = Southampton). 5.6.2 Titanic: Rengøring Før vi kan fortsætte med analysen, er der nogle oprydninger, der skal foretages i datasættet. Vi kan se fra glimpse(titanic)-kommandoen, at der er 891 observationer. De fleste passagerer (687) har faktisk intet oplyst i variablen Cabin: sum(titanic$Cabin == &quot;&quot;) # antal observationer med ingenting for variablen &#39;Cabin&#39; ## [1] 687 Andre passagerer har mere end én cabin. Det ser ikke særlig tidy ud, og det er heller ikke særlig relevant for analysen, så vi vælger at fjerne hele kolonnen med funktionen select(): titanic_no_cabin &lt;- select(titanic, -Cabin) select() er en af de grundlæggende funktioner i tidyverse. Her angiver vi, hvilke kolonner vi ønsker at beholde eller fjerne fra datasættet. I dette tilfælde har vi specificeret -Cabin, hvilket betyder, at vi ikke ønsker at medtage variablen Cabin, men vi ønsker at beholde resten af kolonnerne. Prøv selv at køre select(titanic, Cabin) i stedet - så vil vi kun have variablen Cabin og fjerne resten af vores variabler. glimpse(titanic_no_cabin) ## Rows: 891 ## Columns: 11 ## $ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,… ## $ Survived &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1… ## $ Pclass &lt;int&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3… ## $ Name &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bradley (Fl… ## $ Sex &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;mal… ## $ Age &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, … ## $ SibSp &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0… ## $ Parch &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0… ## $ Ticket &lt;chr&gt; &quot;A/5 21171&quot;, &quot;PC 17599&quot;, &quot;STON/O2. 3101282&quot;, &quot;113803&quot;, &quot;37… ## $ Fare &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,… ## $ Embarked &lt;chr&gt; &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;Q&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;… Næste skridt er at undersøge, om der er manglende værdier (NA) i datasættet. NA er, hvordan R betegner manglende værdier. Som det fremgår af følgende kode, har de fleste variabler ikke NA-værdier, men variablen Age har 177 NA-værdier. colSums(is.na(titanic_no_cabin)) ## PassengerId Survived Pclass Name Sex Age ## 0 0 0 0 0 177 ## SibSp Parch Ticket Fare Embarked ## 0 0 0 0 0 I dette tilfælde vælger jeg at fjerne alle passagerer, der mangler aldersoplysninger (NA) i stedet for at estimere eller imputere deres alder. Til dette formål bruger jeg funktionen drop_na, som fjerner alle observationer, der har NA i mindst én variabel. titanic_clean &lt;- drop_na(titanic_no_cabin) colSums(is.na(titanic_clean)) ## PassengerId Survived Pclass Name Sex Age ## 0 0 0 0 0 0 ## SibSp Parch Ticket Fare Embarked ## 0 0 0 0 0 Nu kan vi tjekke, hvor mange observationer og variabler, der er tilbage. glimpse(titanic_clean) ## Rows: 714 ## Columns: 11 ## $ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19… ## $ Survived &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1… ## $ Pclass &lt;int&gt; 3, 1, 3, 1, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 3, 2, 2, 3… ## $ Name &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bradley (Fl… ## $ Sex &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;mal… ## $ Age &lt;dbl&gt; 22, 38, 26, 35, 35, 54, 2, 27, 14, 4, 58, 20, 39, 14, 55, … ## $ SibSp &lt;int&gt; 1, 1, 0, 1, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 1, 0, 0, 0… ## $ Parch &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0… ## $ Ticket &lt;chr&gt; &quot;A/5 21171&quot;, &quot;PC 17599&quot;, &quot;STON/O2. 3101282&quot;, &quot;113803&quot;, &quot;37… ## $ Fare &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 51.8625, 21.0750… ## $ Embarked &lt;chr&gt; &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;… Vi har beholdt 714 observationer og 11 variabler, og datasættet opfylder kravene for at være tidy. 5.6.3 Pipe Man kan faktisk opnå det samme som i ovenstående eksempel ved at bruge pipe %&gt;%: titanic_clean &lt;- titanic %&gt;% # vi tager titanic-datasættet select(-Cabin) %&gt;% # udvælger de ønskede kolonner drop_na() # fjerner alle observationer med manglende værdier Man bruger pipe %&gt;% til at kombinere adskillige Tidyverse-funktioner i samme kommando. Linjen slutter med %&gt;%, som fortæller, at vi skal bruge resultatet fra den foregående linje som input i den næste linje. Logikken er således, at vi starter med en dataframe, gør én ting ad gangen og slutter med en ny dataframe (som vi kan gemme med &lt;-). Bemærk, at denne proces ligner den, man bruger i ggplot2, men forskellen er, at man bruger %&gt;% i stedet for + i denne sammenhæng. Bemærk også, at jeg som i ggplot2 skriver koden over flere linjer. Det er ikke et krav, men det gør det nemmere at læse og forstå koden. For at illustrere logikken kan man se, at følgende to linjer er tilsvarende: #tag x og anvend en funktion f f(x) #traditionelt tilgang x %&gt;% f #tidyverse tilgang I begge tilfælde starter vi med x og anvender derefter funktionen f på x. En stor fordel ved den tidyverse-tilgangen er, at når man har flere funktioner, undgår man at skulle bruge mange parenteser, og rækkefølgen, som funktionerne anvendes i, læses fra venstre mod højre i stedet for omvendt, som i følgende eksempel: #tag x, anvend f, så g og til sidst h h(g(f(x))) #traditionelt tilgang x %&gt;% f %&gt;% g %&gt;% h #tidyverse tilgang På samme måde som i vores oprydning af titanic kan man både inkludere funktionen select() i drop_na() eller bruge tidyverse-tilgangen, som i følgende eksempel - de to giver samme resultat: Først fjerner vi kolonnen Cabin ved hjælp af select(), og derefter fjerner vi alle rækker, som har mindst én NA ved hjælp af drop_na(). titanic_clean &lt;- drop_na(select(titanic,-Cabin)) titanic_clean &lt;- titanic %&gt;% select(-Cabin) %&gt;% drop_na() 5.7 Bearbejdning af data: dplyr Pakken dplyr er nok den mest brugbare pakke til at bearbejde dataframes. Jeg gennemgår nogle af de mest almindelige muligheder med pakken, og der er også en “cheatsheet” som du kan downloade som reference: https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf. Jeg tager afsæt i følgende funktioner, og dækker flere gennem de forskellige øvelser og øvrige emner. dplyr verbs beskrivelse select() udvælge kolonner (variabler) filter() udvælge rækker (observationer) arrange() sortere rækker mutate() tilføje eller ændre eksisterende kolonner rename() ændre variablers navne recode() ændre selve data group_by() dele datasættet op efter en variabel summarise() aggregere rækker, findes ofte tilknyttet til group_by() Bemærk, at alle disse funktioner tager udgangspunkt i en dataframe, og man får altid en ny dataframe som output. Ved at kunne bruge disse funktioner og kombinere dem (ved hjælp af %&gt;%), har man godt styr på bearbejdningen af datarammer. 5.7.1 dplyr verbs: select() Som vi lige har set ovenfor, kan man med select() udvælge bestemte variabler i en dataframe. Vi kan vælge at beholde, fjerne eller ændre rækkefølgen af variablerne. Som et eksempel kan vi beholde kun variablerne Name og Age i titanic_clean-dataframen ved at bruge følgende kode: titanic_clean %&gt;% select(Name, Age) %&gt;% glimpse() ## Rows: 714 ## Columns: 2 ## $ Name &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bradley (Florence … ## $ Age &lt;dbl&gt; 22, 38, 26, 35, 35, 54, 2, 27, 14, 4, 58, 20, 39, 14, 55, 2, 31, … Hvis vi ønsker at fjerne en variabel fra en dataframe, kan vi bruge et minustegn. I nedenstående eksempel fjerner vi Name og Age fra titanic_clean-dataframen: titanic_clean %&gt;% select(-Name, -Age) %&gt;% glimpse() ## Rows: 714 ## Columns: 9 ## $ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19… ## $ Survived &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1… ## $ Pclass &lt;int&gt; 3, 1, 3, 1, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 3, 2, 2, 3… ## $ Sex &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;mal… ## $ SibSp &lt;int&gt; 1, 1, 0, 1, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 1, 0, 0, 0… ## $ Parch &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0… ## $ Ticket &lt;chr&gt; &quot;A/5 21171&quot;, &quot;PC 17599&quot;, &quot;STON/O2. 3101282&quot;, &quot;113803&quot;, &quot;37… ## $ Fare &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 51.8625, 21.0750… ## $ Embarked &lt;chr&gt; &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;… 5.7.1.1 Hjælper funktioner til select() Hjælpefunktioner til funktionen select() kan være nyttige, hvis man vil udvælge bestemte variabler efter visse kriterier. Nedenfor har jeg samlet nogle (men ikke alle mulige!) hjælpefunktioner og inddrager eksempler i problemstillingerne. select hjælpefunktion beskrivelse starts_with() starter med et præfiks ends_with() slutter med et præfiks contains() indeholder en tekststreng matches() matcher et regulært udtryk num_range() et numerisk interval såsom x01, x02, x03 one_of() variabler i en karaktervektor everything() alle variabler where() tager en funktion og returnerer alle variabler, hvor funktionen returnerer TRUE For eksempel: titanic_clean %&gt;% select(starts_with(&quot;P&quot;)) ## # A tibble: 714 × 3 ## PassengerId Pclass Parch ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 3 0 ## 2 2 1 0 ## 3 3 3 0 ## 4 4 1 0 ## 5 5 3 0 ## 6 7 1 0 ## 7 8 3 1 ## 8 9 3 2 ## 9 10 2 0 ## 10 11 3 1 ## # ℹ 704 more rows Specielt brugbar i statistiske metoder, der kræver kun numeriske variabler, er where(), når den kombineres med is.numeric. For eksempel, i følgende kode udvælger man kun numeriske variabler fra datasættet titanic_clean: titanic_clean %&gt;% select(where(is.numeric)) ## # A tibble: 714 × 7 ## PassengerId Survived Pclass Age SibSp Parch Fare ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 0 3 22 1 0 7.25 ## 2 2 1 1 38 1 0 71.3 ## 3 3 1 3 26 0 0 7.92 ## 4 4 1 1 35 1 0 53.1 ## 5 5 0 3 35 0 0 8.05 ## 6 7 0 1 54 0 0 51.9 ## 7 8 0 3 2 3 1 21.1 ## 8 9 1 3 27 0 2 11.1 ## 9 10 1 2 14 1 0 30.1 ## 10 11 1 3 4 1 1 16.7 ## # ℹ 704 more rows 5.7.2 dplyr verbs: filter() Med funktionen select() udvælger man bestemte variabler. Til gengæld anvender man funktionen filter() til at udvælge bestemte observationer (rækker) fra en dataframe. I nedenstående eksempel beholder vi kun rækkerne, hvor variablen Age er lig med 50. Bemærk, at vi bevarer alle variabler i dataframe. titanic_clean %&gt;% filter(Age == 50) %&gt;% glimpse() ## Rows: 10 ## Columns: 11 ## $ PassengerId &lt;int&gt; 178, 260, 300, 435, 459, 483, 527, 545, 661, 724 ## $ Survived &lt;int&gt; 0, 1, 1, 0, 1, 0, 1, 0, 1, 0 ## $ Pclass &lt;int&gt; 1, 2, 1, 1, 2, 3, 2, 1, 1, 2 ## $ Name &lt;chr&gt; &quot;Isham, Miss. Ann Elizabeth&quot;, &quot;Parrish, Mrs. (Lutie Davis)… ## $ Sex &lt;chr&gt; &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;female&quot;, &quot;male&quot;, &quot;f… ## $ Age &lt;dbl&gt; 50, 50, 50, 50, 50, 50, 50, 50, 50, 50 ## $ SibSp &lt;int&gt; 0, 0, 0, 1, 0, 0, 0, 1, 2, 0 ## $ Parch &lt;int&gt; 0, 1, 1, 0, 0, 0, 0, 0, 0, 0 ## $ Ticket &lt;chr&gt; &quot;PC 17595&quot;, &quot;230433&quot;, &quot;PC 17558&quot;, &quot;13507&quot;, &quot;F.C.C. 13531&quot;,… ## $ Fare &lt;dbl&gt; 28.7125, 26.0000, 247.5208, 55.9000, 10.5000, 8.0500, 10.5… ## $ Embarked &lt;chr&gt; &quot;C&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot; Man kan også vælge intervallet af en variabel - for eksempel hvis man vil vælge alle, der er i halvtredserne. titanic_clean %&gt;% filter(Age &gt;= 50 &amp; Age &lt; 60) %&gt;% head() ## # A tibble: 6 × 11 ## PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 7 0 1 &quot;McCarthy, M… male 54 0 0 17463 51.9 ## 2 12 1 1 &quot;Bonnell, Mi… fema… 58 0 0 113783 26.6 ## 3 16 1 2 &quot;Hewlett, Mr… fema… 55 0 0 248706 16 ## 4 95 0 3 &quot;Coxon, Mr. … male 59 0 0 364500 7.25 ## 5 125 0 1 &quot;White, Mr. … male 54 0 1 35281 77.3 ## 6 151 0 2 &quot;Bateman, Re… male 51 0 0 S.O.P… 12.5 ## # ℹ 1 more variable: Embarked &lt;chr&gt; Man kan også kombinere betingelser fra forskellige kolonner, for eksempel i nedenstående eksempel vælger vi alle personer, som er kvinder og som rejste i første klasse. titanic_clean %&gt;% filter(Sex == &#39;female&#39; &amp; Pclass == 1) %&gt;% head() ## # A tibble: 6 × 11 ## PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2 1 1 Cumings, Mrs… fema… 38 1 0 PC 17… 71.3 ## 2 4 1 1 Futrelle, Mr… fema… 35 1 0 113803 53.1 ## 3 12 1 1 Bonnell, Mis… fema… 58 0 0 113783 26.6 ## 4 53 1 1 Harper, Mrs.… fema… 49 1 0 PC 17… 76.7 ## 5 62 1 1 Icard, Miss.… fema… 38 0 0 113572 80 ## 6 89 1 1 Fortune, Mis… fema… 23 3 2 19950 263 ## # ℹ 1 more variable: Embarked &lt;chr&gt; Vi kan også kombinere flere betingelser med forskellige symboler. For eksempel i nedenstående eksempel vælger vi personer, som er kvinder og som rejste i enten første eller anden klasse og som er i trediverne. Husk at tilføje runde parenteser omkring de to Pclass - prøv selv at fjerne dem og se, hvad der sker. titanic_clean %&gt;% filter(Sex == &#39;female&#39; &amp; (Pclass == 1 | Pclass == 2) &amp; Age %in% c(30:39)) %&gt;% glimpse() ## Rows: 43 ## Columns: 11 ## $ PassengerId &lt;int&gt; 2, 4, 62, 99, 191, 212, 216, 219, 231, 258, 259, 270, 310,… ## $ Survived &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1… ## $ Pclass &lt;int&gt; 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 2… ## $ Name &lt;chr&gt; &quot;Cumings, Mrs. John Bradley (Florence Briggs Thayer)&quot;, &quot;Fu… ## $ Sex &lt;chr&gt; &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;… ## $ Age &lt;dbl&gt; 38, 35, 38, 34, 32, 35, 31, 32, 35, 30, 35, 35, 30, 31, 30… ## $ SibSp &lt;int&gt; 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0… ## $ Parch &lt;int&gt; 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0… ## $ Ticket &lt;chr&gt; &quot;PC 17599&quot;, &quot;113803&quot;, &quot;113572&quot;, &quot;231919&quot;, &quot;234604&quot;, &quot;F.C.C… ## $ Fare &lt;dbl&gt; 71.2833, 53.1000, 80.0000, 23.0000, 13.0000, 21.0000, 113.… ## $ Embarked &lt;chr&gt; &quot;C&quot;, &quot;S&quot;, &quot;&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;,… 5.7.3 Sammenligningsoperatorer Her er en tabel over sammenligningsoperatorer, som kan bruges i både filter() og i baseR (fordi konceptet bag er det samme, bare tilgangen er anderledes). Sammenligningsoperator Beskrivelse &lt; mindre end &gt; større end &lt;= mindre end eller lig med &gt;= større end eller lig med == lig med != forskellig fra &amp; og %in% inkluderet i | eller 5.7.4 Kombinere filter() og select() Man kan også kombinere både filter() og select() i samme kommando, som i følgende eksempel: titanic_clean %&gt;% filter(Sex == &#39;female&#39; &amp; (Pclass == 1 | Pclass == 2) &amp; Age %in% c(30:39)) %&gt;% select(Name, Fare) %&gt;% glimpse() ## Rows: 43 ## Columns: 2 ## $ Name &lt;chr&gt; &quot;Cumings, Mrs. John Bradley (Florence Briggs Thayer)&quot;, &quot;Futrelle,… ## $ Fare &lt;dbl&gt; 71.2833, 53.1000, 80.0000, 23.0000, 13.0000, 21.0000, 113.2750, 7… Bemærk at man skal være opmærksom på rækkefølgen, som man anvender de forskellige funktioner. Hvis man bytter rundt på filter() og select() i ovenstående eksempel, vil der opstå en advarsel. Prøv selv at køre følgende kode: ##virker ikke!!!!!##### titanic_clean %&gt;% select(Name, Fare) %&gt;% filter(Sex == &#39;female&#39; &amp; (Pclass == 1 | Pclass == 2) &amp; Age %in% c(30:39)) %&gt;% glimpse() Det skyldes, at hvis man først vælger at beholde variablerne Name og Age, så er de andre variabler ikke længere tilgængelige i den resulterende dataframe, som dernæst bruges i funktionen filter(). Derfor kan man ikke bruge funktionen filter() på variablerne Pclass,Sex og Age. 5.7.5 dplyr verbs: mutate() Man kan bruge funktionen mutate() til at tilføje en ny variabel til en dataframe. I nedenstående eksempel tilføjer jeg en ny variabel med navnet Adult, der angiver om personen kan betragtes som voksen (hvis vedkommende er mindst 18 år gammel). titanic_with_Adult &lt;- titanic_clean %&gt;% mutate(Adult = Age&gt;=18) titanic_with_Adult %&gt;% select(Adult) %&gt;% glimpse() ## Rows: 714 ## Columns: 1 ## $ Adult &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, FALSE, FALSE, T… Så kan man se, at der er 601 voksne og 113 børn som passagerere på skibet. Bemærk, at jeg gemmer resultatet som en ny dataframe, der hedder titanic_with_Adult, og derefter bruger jeg glimpse() på det nye objekt titanic_with_Adult for at se, hvordan min nye dataframe ser ud. I forudgående eksempler havde jeg ikke gemt resultatet - jeg havde bare brugt glimpse() for at se resultatet på skærmen. Hvis du gerne vil bruge din resulterende dataframe videre, så skal du huske at gemme den (ved brug af &lt;--tegnet). funktionen ifelse() indenfor mutate() Jeg kan oprette variablen Adult på en mere informativ måde end bare med TRUE eller FALSE. Jeg bruger funktionen ifelse(), som giver mulighed for at angive, at jeg gerne vil have teksten “adult”, hvis udsagnet Age&gt;=18 er sandt, og hvis det er falsk, vil jeg have teksten “child”: ifelse(Age&gt;=18,&quot;adult&quot;,&quot;child&quot;) Funktionen ifelse() bruges inden for mutate()-funktionen, fordi vi er i gang med at oprette en ny variabel, Adult - ifelse() giver os mulighed for at fortælle, hvordan den nye variabel skal se ud. titanic_clean %&gt;% mutate(Adult = ifelse(Age&gt;=18,&quot;adult&quot;,&quot;child&quot;)) %&gt;% select(Age,Adult) %&gt;% glimpse() ## Rows: 714 ## Columns: 2 ## $ Age &lt;dbl&gt; 22, 38, 26, 35, 35, 54, 2, 27, 14, 4, 58, 20, 39, 14, 55, 2, 31,… ## $ Adult &lt;chr&gt; &quot;adult&quot;, &quot;adult&quot;, &quot;adult&quot;, &quot;adult&quot;, &quot;adult&quot;, &quot;adult&quot;, &quot;child&quot;, &quot;… Så er variablen lidt mere informativ end før. Opret nye variabler ud fra andre variabler Man kan også oprette nye kolonner baseret på kombinationer af nogle af de eksisterende kolonner. For eksempel, lad os forestille os, at vi gerne vil have en ny kolonne, der viser summen af variablene Fare og Age, en der viser gennemsnittet af de to variabler, og en der hedder “Fare_per_year”. Det vises i følgende eksempel: titanic_clean %&gt;% mutate(&quot;Fare_Age_sum&quot; = Fare + Age, &quot;Fare_Age_mean&quot; = Fare_Age_sum / 2, &quot;Fare_per_year&quot; = Fare / Age) %&gt;% select(Age, Fare, Fare_Age_sum, Fare_Age_mean, Fare_per_year) %&gt;% glimpse() ## Rows: 714 ## Columns: 5 ## $ Age &lt;dbl&gt; 22, 38, 26, 35, 35, 54, 2, 27, 14, 4, 58, 20, 39, 14, 55… ## $ Fare &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 51.8625, 21.07… ## $ Fare_Age_sum &lt;dbl&gt; 29.2500, 109.2833, 33.9250, 88.1000, 43.0500, 105.8625, … ## $ Fare_Age_mean &lt;dbl&gt; 14.62500, 54.64165, 16.96250, 44.05000, 21.52500, 52.931… ## $ Fare_per_year &lt;dbl&gt; 0.3295455, 1.8758763, 0.3048077, 1.5171429, 0.2300000, 0… Det er klart, at fortolkningen af Fare_Age_mean måske ikke er særlig interessant, men der ville være mange situationer, hvor man gerne vil kombinere kolonner for at lave en bestemt beregning. 5.7.6 rename() Man kan bruge rename() til at ændre navnet på en eller flere variable i datasættet. Som et eksempel bruger jeg rename() til at give en variabel navnet Years i stedet for Age (bemærk, at variablen Age ikke findes længere). titanic_clean %&gt;% rename(Years = Age) %&gt;% glimpse() ## Rows: 714 ## Columns: 11 ## $ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19… ## $ Survived &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1… ## $ Pclass &lt;int&gt; 3, 1, 3, 1, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 3, 2, 2, 3… ## $ Name &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bradley (Fl… ## $ Sex &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;mal… ## $ Years &lt;dbl&gt; 22, 38, 26, 35, 35, 54, 2, 27, 14, 4, 58, 20, 39, 14, 55, … ## $ SibSp &lt;int&gt; 1, 1, 0, 1, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 1, 0, 0, 0… ## $ Parch &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0… ## $ Ticket &lt;chr&gt; &quot;A/5 21171&quot;, &quot;PC 17599&quot;, &quot;STON/O2. 3101282&quot;, &quot;113803&quot;, &quot;37… ## $ Fare &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 51.8625, 21.0750… ## $ Embarked &lt;chr&gt; &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;… Man kan også ændre navnene på flere kolonner på én gang. For eksempel i følgende kode laver jeg nogle oversættelsesarbejde: titanic_clean_dansk &lt;- titanic_clean %&gt;% rename(Overlevede = Survived, Navn = Name, Klasse = Pclass) Så du kan se, at jeg har ændret variablenes navne. Jeg kalder den nye dataframe for titanic_clean_dansk, så min danske version er blevet gemt et sted. Man kan også gøre sådan, at alle bogstaver i variablernes navne er små bogstaver. Jeg benytter den danske version, og jeg anvender rename_with() og specificerer tolower. titanic_clean_dansk %&gt;% rename_with(tolower) %&gt;% # alle variablernes navne er kun små bogstaver glimpse() ## Rows: 714 ## Columns: 11 ## $ passengerid &lt;int&gt; 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19… ## $ overlevede &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1… ## $ klasse &lt;int&gt; 3, 1, 3, 1, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 3, 2, 2, 3… ## $ navn &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bradley (Fl… ## $ sex &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;mal… ## $ age &lt;dbl&gt; 22, 38, 26, 35, 35, 54, 2, 27, 14, 4, 58, 20, 39, 14, 55, … ## $ sibsp &lt;int&gt; 1, 1, 0, 1, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 1, 0, 0, 0… ## $ parch &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0… ## $ ticket &lt;chr&gt; &quot;A/5 21171&quot;, &quot;PC 17599&quot;, &quot;STON/O2. 3101282&quot;, &quot;113803&quot;, &quot;37… ## $ fare &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 51.8625, 21.0750… ## $ embarked &lt;chr&gt; &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;… Prøv også at erstatte tolower med toupper. 5.7.7 dplyr verbs: recode() Med recode() kan man ændre hvordan en variable ser ud. For eksempel kan man ændre “male”/“female” til 0/1, som vist i følgende eksempel: titanic_clean %&gt;% mutate(Sex = recode(Sex, &quot;male&quot; = 0, &quot;female&quot; = 1)) %&gt;% select(PassengerId,Name,Sex) %&gt;% glimpse() ## Rows: 714 ## Columns: 3 ## $ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19… ## $ Name &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bradley (Fl… ## $ Sex &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1… Bemærk, at funktionen recode() er blevet brugt indenfor funktionen mutate(). Jeg lavede en ny variable af samme navn, men med ændret værdier indenfor variablen. Hvis man ønsker at ændre tilbage fra 0/1 til “male”/“female”, skal man skrive 1 / 0 for at specificere, at man har talværdier, og man ønsker at kalde dem for noget andet (“male”/“female” i dette tilfælde): #recodes variable Sex and then recodes it back to original form again titanic_clean %&gt;% mutate(Sex = recode(Sex, male = 1, female = 0)) %&gt;% mutate(Sex = recode(Sex, `1` = &quot;male&quot;, `0` = &quot;female&quot;)) %&gt;% #note use of `` in the numbers select(PassengerId,Name,Sex) %&gt;% glimpse() ## Rows: 714 ## Columns: 3 ## $ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19… ## $ Name &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bradley (Fl… ## $ Sex &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;mal… Bemærk brugen af `` i tallene. 5.7.8 dplyr verbs: arrange() Man anvender arrange() for at vælge rækkefølgen på observationerne. I nedenstående eksempel tager vi datarammen titanic_clean og arrangerer observationer efter variablen Fare. Det betyder, at personer, der har betalt mindst, vil være øverst i den resulterende dataramme, mens personer, der har betalt mest, vil være nederst. # Arrange by increasing Fare titanic_clean %&gt;% arrange(Fare) %&gt;% glimpse() ## Rows: 714 ## Columns: 11 ## $ PassengerId &lt;int&gt; 180, 264, 272, 303, 598, 807, 823, 379, 873, 327, 844, 819… ## $ Survived &lt;int&gt; 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0… ## $ Pclass &lt;int&gt; 3, 1, 3, 3, 3, 1, 1, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3… ## $ Name &lt;chr&gt; &quot;Leonard, Mr. Lionel&quot;, &quot;Harrison, Mr. William&quot;, &quot;Tornquist… ## $ Sex &lt;chr&gt; &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;m… ## $ Age &lt;dbl&gt; 36.0, 40.0, 25.0, 19.0, 49.0, 39.0, 38.0, 20.0, 33.0, 61.0… ## $ SibSp &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0… ## $ Parch &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ Ticket &lt;chr&gt; &quot;LINE&quot;, &quot;112059&quot;, &quot;LINE&quot;, &quot;LINE&quot;, &quot;LINE&quot;, &quot;112050&quot;, &quot;19972… ## $ Fare &lt;dbl&gt; 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 4.… ## $ Embarked &lt;chr&gt; &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;… Hvis man gerne vil have det omvendt - at personer som har betalt mest, skal være øverst i datarammen, kan man bruge desc() omkring Fare, som i nedenstående: # Arrange by decreasing Fare titanic_clean %&gt;% arrange(desc(Fare)) %&gt;% glimpse() ## Rows: 714 ## Columns: 11 ## $ PassengerId &lt;int&gt; 259, 680, 738, 28, 89, 342, 439, 312, 743, 119, 300, 381, … ## $ Survived &lt;int&gt; 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1… ## $ Pclass &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1… ## $ Name &lt;chr&gt; &quot;Ward, Miss. Anna&quot;, &quot;Cardeza, Mr. Thomas Drake Martinez&quot;, … ## $ Sex &lt;chr&gt; &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;mal… ## $ Age &lt;dbl&gt; 35.00, 36.00, 35.00, 19.00, 23.00, 24.00, 64.00, 18.00, 21… ## $ SibSp &lt;int&gt; 0, 0, 0, 3, 3, 3, 1, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1… ## $ Parch &lt;int&gt; 0, 1, 0, 2, 2, 2, 4, 2, 2, 1, 1, 0, 0, 0, 2, 1, 0, 1, 2, 1… ## $ Ticket &lt;chr&gt; &quot;PC 17755&quot;, &quot;PC 17755&quot;, &quot;PC 17755&quot;, &quot;19950&quot;, &quot;19950&quot;, &quot;199… ## $ Fare &lt;dbl&gt; 512.3292, 512.3292, 512.3292, 263.0000, 263.0000, 263.0000… ## $ Embarked &lt;chr&gt; &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;… 5.8 Visualisering: bruge som input i ggplot2 Efter man har udført bearbejdning med tidyverse-kommandoer, kan man specificere den resulterende dataramme som data i funktionen ggplot(). Man benytter %&gt;%-operatoren til at forbinde dplyr-kommandoerne med ggplot-funktionen, og i dette tilfælde behøver man ikke at angive navnet på datarammen inde i ggplot-funktionen. I nedenstående eksempel tager jeg udgangspunkt i titanic_clean og laver et søjlediagram, som viser antallet af passagerer, der rejste i hver af de tre klasser. titanic_clean %&gt;% ggplot(aes(x=Pclass,fill=as.factor(Pclass))) + geom_bar(stat=&quot;count&quot;) + theme_minimal() Jeg gør det lidt mere kompliceret i følgende eksempel, hvor jeg tager udgangspunkt i titanic_clean, laver en ny kolonne kaldet Adult ved at bruge mutate(), og derefter bruger jeg den resulterende dataframe i ggplot() funktionen til at lave et plot, hvor jeg tæller antallet af voksne og børn: titanic_clean %&gt;% mutate(Adult = ifelse(Age&gt;=18,&quot;Adult&quot;,&quot;Child&quot;)) %&gt;% ggplot(aes(x=Adult,fill=Adult)) + geom_bar(stat=&quot;count&quot;) + theme_minimal() Så kan man se, at der var 600 voksne og lidt over 100 børn ombord på skibet. 5.9 Misc funktioner som er nyttige at vide 5.9.1 Pull I tidyverse arbejder vi meget med dataframes. Tilgangen er, at man tager udgangspunkt i en dataframe, får en dataframe som resultat, og så arbejder videre på den dataframe. Nogle gange kan det dog være, at man gerne vil udtrække en variabel som en vektor fra en dataframe, fx hvis man gerne vil bruge den i en bestemt statistisk metode. Her er et eksempel, hvor man udtrækker variablen Age for “male” og “female” (variablen Sex) og bruger de resulterende vektorer i en t-test: ages_male &lt;- titanic_clean %&gt;% filter(Sex==&quot;male&quot;) %&gt;% pull(Age) ages_female &lt;- titanic_clean %&gt;% filter(Sex==&quot;female&quot;) %&gt;% pull(Age) t.test(ages_male,ages_female) ## ## Welch Two Sample t-test ## ## data: ages_male and ages_female ## t = 2.5259, df = 560.05, p-value = 0.01181 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.6250732 4.9967983 ## sample estimates: ## mean of x mean of y ## 30.72664 27.91571 Så kan man se, at mænd og kvinder i gennemsnit har signifikant forskellige aldre (hvor mændene er ældre end kvinderne). 5.9.2 Slice Med funktionen slice kan man vælge specifikke observationer i en dataframe. Følgende eksempel viser de to passagerer, der har betalt mest for deres billet (variabeln Fare). titanic %&gt;% arrange(desc(Fare)) %&gt;% select(Name,Age) %&gt;% slice(1,2) ## # A tibble: 2 × 2 ## Name Age ## &lt;chr&gt; &lt;dbl&gt; ## 1 Ward, Miss. Anna 35 ## 2 Cardeza, Mr. Thomas Drake Martinez 36 Se udvidet muligheder her: https://dplyr.tidyverse.org/reference/slice.html 5.10 Problemstillinger Problem 1) Lav quizzen på Absalon - “Quiz - tidyverse - part 1” Vi øver os med datasættet Titanic. Indlæs datasættet og udfør den overstående oprydning med følgende kode: library(tidyverse) library(titanic) titanic &lt;- as_tibble(titanic_train) titanic_clean &lt;- titanic %&gt;% select(-Cabin) %&gt;% drop_na() %&gt;% mutate(Adult = ifelse(Age&gt;=18,&quot;adult&quot;,&quot;child&quot;)) %&gt;% mutate(Survived = recode(Survived, `1` = &quot;yes&quot;, `0` = &quot;no&quot;)) glimpse(titanic_clean) #take a look! Problem 2) select(). Tag udgangspunkt i titanic_clean og fjern variablen Name (du behøver ikke at gemme din nye dataframe). titanic_clean %&gt;% select(...) #redigere her Tilføj også glimpse() for at se et overblik (man kan også bruge head()) Problem 3) select(). Lav en ny dataframe ud fra titanic_clean med kun variabler Name, Pclass og Fare (du behøver ikke at gemme den). Gør det nogen forskel, i hvilken rækkefølge man skriver Name, Pclass og Fare? Problem 4) select() og hjælper funktioner. Tag udgangspunkt i titanic_clean. Hvad sker der, når man skriver starts_with(\"S\") i stedet for at specificere bestemte kolonnenavne inden for select()? Prøv også contains(\"ar\") Prøv også -any_of(c(\"Survived\",\"Pclass\",\"FavouriteColour\")) og -all_of(c(\"Survived\",\"Pclass\",\"FavouriteColour\")) Hvis man bruger all_of(), så skal alle variable i vektoren c(\"Survived\",\"Pclass\",\"FavouriteColour\") findes i datasættet, ellers vil man få en advarsel. Hvis man bruger any_of(), så vil alle variable fra vektoren c(\"Survived\",\"Pclass\",\"FavouriteColour\"), som findes i datasættet, blive inkluderet, mens de andre variable vil blive ignoreret. Prøv også matches(\"^S[i|u]\") - kan du gætte hvad det betyder (se nedenunder)? Problem 5) filter(). Opret en ny dataframe ud fra titanic_clean med alle passagerer, der er mellem 10 og 15 år gammel og har rejst i enten første eller anden klasse (du behøver ikke at gemme den). Prøv at tilføje %&gt;% count() til kommandoen - Hvor mange observationer er der i din nye dataframe? Problem 6) filter() og select() : kombinering med %&gt;% Opret en ny dataframe ud fra titanic_clean med alle passagerer, der er “male” og har overlevet (variablen Survived er “yes”), og vælg kun kolonnerne Name, Age og Fare. Problem 7) filter() og select() kombinering med %&gt;% Opret en ny dataframe ud fra titanic_clean med kun variabler Name og Age og dernæst specificere kun de passagerer som er over 60. Få du så den samme sæt observationer hvis du skriver dine select() og filter() funktionerne omvendt? Hvorfor? Problem 8) Mutate(). Ud fra titanic_clean opret en ny kolonne, som hedder FareRounded og viser Fare rundet til det nærmest integar (hint: benyt funktionen round()). Problem 9) Mutate(). Ud fra titanic_clean opret en ny kolonne, som hedder Mean_ID_Age og viser gennemsnittet af variablen PassengerId og variablen Age (se sektion Opret nye variabler ud fra andre variabler i kursusnotaterne hvis du er i tvivl). Problem 10) mutate() og ifelse(). Opret en ny dataramme ud fra titanic_clean med en ny kolon som hedder Family som angiver TRUE hvis Parch er ikke nul, ellers FALSE. Anvend funktionen-ifelse() til at gøre variablen mere intuitiv - “Family” og “Not family”. Problem 11) Mutate() og ifelse() Kig en gang til på beskrivelsen af følgende to variabler i datasættet: SibSp: The number of siblings/spouses aboard the titanic with the passenger Parch: The number of parents/children aboard the titanic with the passenger Tag udgangspunkt i titanic_clean og lav en ny variabel Solo, som viser “Ja”, hvis passageren rejste alene, og “Nej”, hvis passageren rejste med andre. Brug mutate() igen til at omdanne den nye variabel til en faktor. Gem også din nye dataframe, så du kan bruge din nye variabel videre i næste spørgsmål. titanic_clean &lt;- titanic_clean %&gt;% ... Problem 12) pull() og t.test() Betalt passagererne, der rejste alene (variablen Solo fra sidste opgave), i gennemsnit det samme for deres billet (variablen Fare) som passagererne, der ikke rejste alene? Lav en t-test (anvend filter() og så pull() to gange til at udtrække passende vektorer og bruger dem i t.test()-funktionen - se også eksempel i kursusnoterne hvis du er usikker). Problem 13) Recode() I variablen Embarked: C står for Cherbourg Q står for Queenstown S står for Southampton a) Anvend recode (indenfor mutate) til at ændre værdierne i variablen Embarked således at man får de fulde navne af de steder folk gik ombord skibet, i stedet for kun den første bogstav. Gem også dit output (som titanic_clean igen) så du kan bruge din nye variable videre. b) Erstat recode-funktionen med recode_factor-funktionen og sammenlign datatypen af variablen Embarked i din nye dataframe. c) Prøv at tilføje funktionen count() for at optælle hvor mange gik om bord i de forskellige steder. Prøv også med to variabler indenfor count() - Solo og Embarked Resultatet ser sådan ud: ## # A tibble: 7 × 3 ## Solo Embarked n ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 No &quot;Southampton&quot; 229 ## 2 No &quot;Queenstown&quot; 9 ## 3 No &quot;Cherbourg&quot; 72 ## 4 Yes &quot;Southampton&quot; 325 ## 5 Yes &quot;Queenstown&quot; 19 ## 6 Yes &quot;Cherbourg&quot; 58 ## 7 Yes &quot;&quot; 2 d) Man kan se, at der er to passagerer hvor der ikke er noget skrevet i Embarked. Rejste de alene? Gem din dataframe med de to passagerer fjernet. Problem 14) Arrange(). Lav en ny dataramme ud fra titanic_clean med observationerne arrangerede således at de yngst er på toppen og ældste er på bunden. Kig på resultatet - hvad kan du fortælle om den yngste passager ombord skibet Titanic? Hvad kan du fortælle om den ældste passager ombord skibet? Overlevede de? Hvad med de andre ældste passagerer? Problem 15) Arrange() og kombinering med andre verber. Lav en ny dataramme fra titanic_clean med kun personer med SibSp&gt;0 og som gik ombord skibet i Southampton, arrangere de resulterende observationer efter Fare (højeste på toppen) og udvælg kun kolonnerne Name, Age og Fare. Problem 16) Rename(). Fra titanic_clean udvælg kun variabler Survived,Ticket, og Name og ændre deres navne til Overlevede, Billet og Navn. Gør variabler navne til store bogstaver ved at anvende rename_with(). Problem 17) Lave et plot. Fra titanic_clean bruge filter() til at lave en ny dataramme kun med personer under 30 og bruge den til at lave et barplot som viser antallet af personer opdelt efter Pclass. Bruge følgende struktur for koden: titanic_clean %&gt;% filter(...) %&gt;% #rediger linjen ggplot(aes(...)) + .... #tilføj plot Problem 18) Lave et plot. Fra titanic_clean, bruge mutate() til at lave et nyt kolon der hedder with_siblings_spouses der er TRUE hvis SibSp ikke er nul. Brug den til at lave boxplots som viser Fare på y-aksen og with_siblings_spouses på x-aksen. Ekstra: Ændre skalen på y-aksen for at gøre plottet klarer at fortolke. 5.11 Kommentarer matches(\"^S[i|u]\") betyder ^S variabel navn skal starter med en S [i|u] den næste bogstav i variabel navnet skal være enten i eller u OBS det er ikke vigtigt at lære pattern matching i kurset men det er meget brugbart i andre sammenhænge! Næste gange arbejder vi videre med tidyverse. Group_by kombinerede med Summarise Pivot_Longer/Pivot_Wider Join funktionerne "],["bearbejdning-dag-2.html", "Chapter 6 Bearbejdning dag 2 6.1 Indledning og læringsmålene 6.2 group_by() med summarise() i dplyr-pakken 6.3 pivot_longer()/pivot_wider() med Tidyr-pakken 6.4 Eksempel: Titanic opsummeringsstatistikker 6.5 left_join(): forbinde dataframes 6.6 Problemstillinger 6.7 Ekstra links", " Chapter 6 Bearbejdning dag 2 6.1 Indledning og læringsmålene I dag fortsætter vi arbejdet med tidyverse, især fokusere vi på pakkerne dplyr og tidyr, som kan bruges til at ændre strukturen af et datasæt, så det passer til den krævede struktur for at kunne lave plots med ggplot2. I biologi er det ofte tilfældet, at dataene er i en dataframe, mens yderligere oplysninger om prøverne er i en anden dataframe. Derfor vil vi gerne lære, hvordan man forbinder disse to dataframes i R, så vi kan bruge de ekstra oplysninger, når vi laver plots af dataene. 6.1.1 Læringsmålene Du skal kunne: Bruge kombinationen af group_by() og summarise(). Forstå forskellen mellem wide og long data og bruge pivot_longer() til at lette plotting. Bruge left_join() eller andre join-funktioner til at tilføje prøveinformation til datasættet. 6.1.2 Videoer Video 1 - vi skal kigge lidt nærmere på group_by() + summarise() og forbinde tidyverse kode og ggplot2 kode sammen med %&gt;%/+. Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/546910681 Video 2 - wide/long data forms og pivot_longer() og bruge den i ggplot2 Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/707081191 Video 3 - eksempel med titanic summary statistics Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/707223997 Video 4: left_join() for at forbine tables med ekstra oplysning Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/707082269 6.2 group_by() med summarise() i dplyr-pakken Ved at kombinere group_by() og summarise() kan man finde numeriske svar på spørgsmålet: Havde mænd eller kvinder en højere sandsynlighed for at overleve tragedien? Lad os starte med at se på en løsning med tapply, hvor vi udregner proportionen af mænd og kvinder, der overlevede. Følgende kode opdeler variablen Survived efter den kategoriske variabel Sex og tager middelværdien. Derved får vi proportionen af overlevende efter køn (da Survived er kodet sådan, at 1 betyder, at man overlevede, og 0 betyder, at man ikke overlevede). titanic_clean &lt;- titanic %&gt;% select(-Cabin) %&gt;% drop_na() #tapply løsning tapply(titanic_clean$Survived,titanic_clean$Sex,mean) ## female male ## 0.7547893 0.2052980 Nu skifter vi over til en tidyverse-løsning. Lad os tage udgangspunkt i summarise()-funktionen. Som et eksempel på, hvordan man bruger funktionen, vil vi beregne en variabel, som hedder “medianFare”, og som er lig med median(Fare). titanic_clean %&gt;% summarise(&quot;medianFare&quot;=median(Fare)) ## # A tibble: 1 × 1 ## medianFare ## &lt;dbl&gt; ## 1 15.7 Vi får faktisk en ny dataramme her, med kun den variabel, som vi lige har specificeret. Vi er dog interesseret i proportionen af overlevende, så vi tager middelværdien af variablen Survived. Lad os gøre det med summarise(): titanic_clean %&gt;% summarise(meanSurvived = mean(Survived)) ## # A tibble: 1 × 1 ## meanSurvived ## &lt;dbl&gt; ## 1 0.406 For at besvare spørgsmålet er vi også nødt til at opdele efter kolonnen Sex. Vi kan bruge kombinationen af group_by() og summarise(). Vi opdeler efter Sex ved at anvende funktionen group_by() og derefter bruger vi summarise() til at oprette en kolonne, der hedder meanSurvived, som viser proportionen af overlevende for både kvinder og mænd. #tidyverse løsning titanic_clean %&gt;% group_by(Sex) %&gt;% summarise(meanSurvived = mean(Survived)) ## # A tibble: 2 × 2 ## Sex meanSurvived ## &lt;chr&gt; &lt;dbl&gt; ## 1 female 0.755 ## 2 male 0.205 Lad os tage resultatet fra ovenstående og visualisere det i et barplot, som vist nedenfor: titanic_clean %&gt;% group_by(Sex) %&gt;% summarise(meanSurvived = mean(Survived)) %&gt;% ggplot(aes(x=Sex,y=meanSurvived,fill=Sex)) + geom_bar(stat=&quot;identity&quot;,show.legend = FALSE) + theme_minimal() 6.2.1 Reference af summarise()-funktioner Her er nogle funktioner, som man ofte bruger med summarise() (der er mange andre muligheder). Funktion Beskrivelse mean() giver os middelværdien af en variabel. sd() giver os standardafvigelsen af en variabel. min() giver os den laveste værdi af en variabel. max() giver os den højeste værdi af en variabel. n() giver os antallet af observationer i en variabel og mange flere. first() giver os de første værdier. 6.2.2 Flere summeringsstatistikker på én gang Vi kan også lave flere summeringsstatistikker på én gang. For eksempel kan vi anvende funktionen group_by med Sex igen, men beregne flere forskellige summeringsstatistikker: titanic_clean_summary_by_sex &lt;- titanic_clean %&gt;% group_by(Sex) %&gt;% summarise(count = n(), #count meanSurvived = mean(Survived), #middelværdi survived meanAge = mean(Age), #middelværdi age propFirst = sum(Pclass==1)/n()) #proportionen i første klass titanic_clean_summary_by_sex ## # A tibble: 2 × 5 ## Sex count meanSurvived meanAge propFirst ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 female 261 0.755 27.9 0.326 ## 2 male 453 0.205 30.7 0.223 Denne summeringstabel kan igen bruges som et datasæt til at lave et plot med ggplot2. Bemærk, at her bruger vi stat=\"identity\", fordi vi ikke skal tælle observationerne op, men blot plotte præcis de tal, der er i datarammen, på y-aksen. I nedenstående eksempel laver vi barplots for meanAge og propFirst. De er plottet ved hjælp af to forskellige ggplot-kommandoer, og bemærk, at de er plottet ved siden af hinanden ved hjælp af en funktion kaldet grid.arrange() fra R-pakken gridExtra. plotA &lt;- ggplot(data=titanic_clean_summary_by_sex,aes(x=Sex,y=meanAge,fill=Sex)) + geom_bar(stat=&quot;identity&quot;,show.legend = FALSE) + theme_minimal() plotB &lt;- ggplot(data=titanic_clean_summary_by_sex,aes(x=Sex,y=propFirst,fill=Sex)) + geom_bar(stat=&quot;identity&quot;,show.legend = FALSE) + theme_minimal() library(gridExtra) grid.arrange(plotA,plotB,ncol=2) #plot both together Vi kan se, at kvinder i gennemsnit var lidt yngre end mænd og havde en højere sandsynlighed for at være i første klasse. Et interessant spørgsmål er, hvordan man kan lave de ovenstående plots uden at bruge to forskellige ggplot-kommandoer. Med andre ord, hvordan man kan lave en automatisk løsning, hvor vi kan plotte flere summeringsstatistikker med kun én ggplot-kommando. Vi vil se, hvordan det kan gøres ved først at konvertere datasættet til long-form. 6.2.3 Mere avanceret group_by() Lad os også beregne, hvor mange passagerer der var, efter både deres klasse og hvor de gik om bord på skibet: titanic_clean %&gt;% group_by(Embarked, Pclass) %&gt;% # Grupper efter flere variable... summarise(count = n()) ## `summarise()` has grouped output by &#39;Embarked&#39;. You can override using the ## `.groups` argument. ## # A tibble: 10 × 3 ## # Groups: Embarked [4] ## Embarked Pclass count ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 &quot;&quot; 1 2 ## 2 &quot;C&quot; 1 74 ## 3 &quot;C&quot; 2 15 ## 4 &quot;C&quot; 3 41 ## 5 &quot;Q&quot; 1 2 ## 6 &quot;Q&quot; 2 2 ## 7 &quot;Q&quot; 3 24 ## 8 &quot;S&quot; 1 108 ## 9 &quot;S&quot; 2 156 ## 10 &quot;S&quot; 3 290 Man kan se, at størstedelen gik ombord i Southampton (S), men der var også forholdsvis mange førsteklasses-passagerer, der gik ombord i Cherbourg (C). Lad os fortsætte med vores Survived-eksempel og beregne proportionen af overlevende efter de tre variable Adult, Sex og Pclass. titanic_clean_summary_survived &lt;- titanic_clean %&gt;% mutate(Adult = ifelse(Age&gt;=18,&quot;Adult&quot;,&quot;Child&quot;)) %&gt;% group_by(Adult,Sex,Pclass) %&gt;% summarise(meanSurvived = mean(Survived)) ## `summarise()` has grouped output by &#39;Adult&#39;, &#39;Sex&#39;. You can override using the ## `.groups` argument. titanic_clean_summary_survived ## # A tibble: 12 × 4 ## # Groups: Adult, Sex [4] ## Adult Sex Pclass meanSurvived ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Adult female 1 0.974 ## 2 Adult female 2 0.903 ## 3 Adult female 3 0.418 ## 4 Adult male 1 0.371 ## 5 Adult male 2 0.0682 ## 6 Adult male 3 0.133 ## 7 Child female 1 0.875 ## 8 Child female 2 1 ## 9 Child female 3 0.543 ## 10 Child male 1 1 ## 11 Child male 2 0.818 ## 12 Child male 3 0.233 Og så kan vi også bruge resultatet i en ggplot, hvor vi kombinerer de tre variable og opdeler det i tre plots efter Pclass: ggplot(titanic_clean_summary_survived,aes(x=Sex,y=meanSurvived,fill=Adult)) + geom_bar(stat=&quot;identity&quot;,position = &quot;dodge&quot;) + facet_grid(~Pclass) + ylab(&quot;Proportion survived&quot;) + theme_bw() 6.2.4 Funktionen ungroup() Nogle gange, når man er færdig med en proces, men gerne vil arbejde videre med et datasæt, er det nyttigt at anvende ungroup() på datasættet igen. Det er mest relevant i længere projekter. Som et eksempel kan vi se på følgende kode, hvor der står “Groups: Adult [2]” øverst i den nye dataramme med summeringsstatistikker: titanic_clean_summary &lt;- titanic_clean %&gt;% mutate(Adult = ifelse(Age&gt;=18,&quot;Adult&quot;,&quot;Child&quot;)) %&gt;% group_by(Adult,Sex) %&gt;% summarise(meanSurvived = mean(Survived)) ## `summarise()` has grouped output by &#39;Adult&#39;. You can override using the ## `.groups` argument. titanic_clean_summary ## # A tibble: 4 × 3 ## # Groups: Adult [2] ## Adult Sex meanSurvived ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Adult female 0.772 ## 2 Adult male 0.177 ## 3 Child female 0.691 ## 4 Child male 0.397 Bemærk, at vi først brugte group_by() på både Adult og Sex. Men hver gang man laver en beregning, fjernes én opdeling - i dette tilfælde opdeles der ikke længere efter Sex, men der opdeles stadig efter Adult. Det er ikke et problem, hvis vi ikke vil arbejde videre med datarammen. Men forestil dig, at vi gerne vil vide, hvad den maksimale chance for overlevelse er, ud fra de fire beregnede tal. Hvis vi ikke vil opdele efter en kategorisk variabel, dropper vi group_by(): titanic_clean_summary %&gt;% summarise(&quot;maxChance&quot; = max(meanSurvived)) ## # A tibble: 2 × 2 ## Adult maxChance ## &lt;chr&gt; &lt;dbl&gt; ## 1 Adult 0.772 ## 2 Child 0.691 Man kan dog se, at outputtet er blevet opdelt efter variablen Adult. For at undgå dette skal man først anvende ungroup(), så effekten af group_by() fjernes. titanic_clean_summary %&gt;% ungroup() %&gt;% summarise(&quot;maxChance&quot; = max(meanSurvived)) ## # A tibble: 1 × 1 ## maxChance ## &lt;dbl&gt; ## 1 0.772 6.3 pivot_longer()/pivot_wider() med Tidyr-pakken Tidy data findes i to former: wide data og long data. Det kan være nyttigt at transformere datarammen fra den ene form til den anden, f.eks. for at lave et bestemt plot med ggplot2-pakken. Inden for pakken tidyr er der funktioner, der kan bruges til at lave disse transformationer. Før vi begynder at se lidt nærmere på tidyr, skal vi beskrive, hvad long data og wide data betyder. Figure 6.1: source: https://www.garrickadenbuie.com/project/tidyexplain/ Wide data: Her har man én kolonne for hver variabel og én række for hver observation. Dette gør dataene lette at forstå, og denne datatype findes ofte indenfor biologi - for eksempel, hvis man har forskellige prøver (behandlinger, kontroller, betingelser osv.) som variabler. Long data: Med long data har man værdier samlet i en enkelt kolonne og en kolonne som en slags nøgle, der også angiver, hvilken variabel hver værdi hørte til i det wide format. Datasættet betragtes stadig som tidy, men informationen opbevares på en anden måde. Det er lidt sværere at læse, men nemmere at arbejde med, når man analyserer dataene. Når man transformerer data fra wide til long eller omvendt, kaldes det for reshaping. 6.3.1 Tidyr pakke - oversigt Her er en oversigt over de fire vigtigste funktioner fra R-pakken tidyr. Vi fokuserer mest på pivot-funktionerne, men det kan være nyttigt at bruge separate og unite en gang imellem. tidyr funktion Beskrivelse pivot_longer() wide til long pivot_wider() long til wide separate() opdele strenge fra én kolonne til to unite() føje strenge sammen fra to til én kolonne 6.3.2 Wide -&gt; Long med pivot_longer() Lad os arbejde med datasættet Iris. Man får Iris i long format med følgende kommando. Her vil man gerne tage alle numeriske kolonner og placere deres værdier i en enkelt kolonne value (med en nøglekolonne name til at skelne imellem de forskellige variabler). iris %&gt;% pivot_longer(cols = where(is.numeric)) ## # A tibble: 600 × 3 ## Species name value ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 setosa Sepal.Length 5.1 ## 2 setosa Sepal.Width 3.5 ## 3 setosa Petal.Length 1.4 ## 4 setosa Petal.Width 0.2 ## 5 setosa Sepal.Length 4.9 ## 6 setosa Sepal.Width 3 ## 7 setosa Petal.Length 1.4 ## 8 setosa Petal.Width 0.2 ## 9 setosa Sepal.Length 4.7 ## 10 setosa Sepal.Width 3.2 ## # ℹ 590 more rows At beholde numeriske kolonner svarer i dette tilfælde til, at man ikke vil have variablen Species med i den enkelte kolonne: iris %&gt;% pivot_longer(cols = -Species) ## # A tibble: 600 × 3 ## Species name value ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 setosa Sepal.Length 5.1 ## 2 setosa Sepal.Width 3.5 ## 3 setosa Petal.Length 1.4 ## 4 setosa Petal.Width 0.2 ## 5 setosa Sepal.Length 4.9 ## 6 setosa Sepal.Width 3 ## 7 setosa Petal.Length 1.4 ## 8 setosa Petal.Width 0.2 ## 9 setosa Sepal.Length 4.7 ## 10 setosa Sepal.Width 3.2 ## # ℹ 590 more rows Her er et billed, der illustrerer wide- og long-form med datasættet iris: Figure 6.2: wide til long med Iris Til venstre har vi målingerne i datasættet fordelt over fire forskellige kolonner kaldet Sepal.Length, Sepal.Width, Petal.Length og Petal.Width, samt en ekstra kolonne, der skelner mellem de tre Species. Til højre har vi samlet alle målingerne i en enkelt kolonne kaldet values, og så bruger vi en anden ‘nøgle’ kolonne kaldet name til at fortælle os, om det er en måling for Sepal.Length eller Sepal.Width osv. Jeg kan ændre kolonnenavne for målingerne og nøglen til nogle andre end standardnavnene. For eksempel, i nedenstående eksempel skal målingerne hedde measurements og nøglen hedde trait. iris.long &lt;- iris %&gt;% pivot_longer(cols = -Species, names_to = &quot;trait&quot;, values_to = &quot;measurement&quot;) Man kan for eksempel bruge den long form til at visualisere samtlige mulige boxplots opdelt efter Species og trait på samme plot: ggplot(iris.long,aes(y=measurement,x=Species,fill=Species)) + geom_boxplot() + facet_grid(~trait) + theme_bw() 6.3.3 separate() Funktionen separate() fra pakken tidyr kan bruges til at opdele to forskellige dele, som eksisterer i samme kolonne. For eksempel, i iris har vi variabler med navne Sepal.Width, Sepal.Length osv. - man kan forestille sig at opdele disse navne over to kolonner i stedet for én - fx “Sepal” og “Width” i tilfældet af Sepal.Width. I nedenstående kan man se, hvordan man anvender separate(). iris %&gt;% pivot_longer(cols = -Species, names_to = &quot;trait&quot;, values_to = &quot;measurement&quot;) %&gt;% separate(col = trait, into = c(&quot;part&quot;, &quot;measure&quot;), sep = &quot;\\\\.&quot;) %&gt;% head() ## # A tibble: 6 × 4 ## Species part measure measurement ## &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 setosa Sepal Length 5.1 ## 2 setosa Sepal Width 3.5 ## 3 setosa Petal Length 1.4 ## 4 setosa Petal Width 0.2 ## 5 setosa Sepal Length 4.9 ## 6 setosa Sepal Width 3 Man specificerer variablen trait og angiver, at den skal opdeles til to variabler part og measure. Vi angiver sep = \"\\\\.\", hvilket betyder, at vi gerne vil have part som delen af trait foran ‘.’ og measure som delen af trait efter .. Vi bruger “\\.” for at fortælle, at vi er interesseret i punktummet og ikke en “anonym karakter”, som punktum normalt betyder i “streng”-sprog. Man behøver faktisk ikke at specificere sep = \"\\\\.\" i dette tilfælde - som standard kigger funktionen efter ‘non-character’ tegn og bruger dem til at lave opdelingen. Samme resultat: iris %&gt;% pivot_longer(cols = -Species, names_to = &quot;trait&quot;, values_to = &quot;measurement&quot;) %&gt;% separate(col = trait, into = c(&quot;part&quot;, &quot;measure&quot;)) %&gt;% head() ## # A tibble: 6 × 4 ## Species part measure measurement ## &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 setosa Sepal Length 5.1 ## 2 setosa Sepal Width 3.5 ## 3 setosa Petal Length 1.4 ## 4 setosa Petal Width 0.2 ## 5 setosa Sepal Length 4.9 ## 6 setosa Sepal Width 3 Bruger resultatet i et plot: iris %&gt;% pivot_longer(cols = -Species, names_to = &quot;trait&quot;, values_to = &quot;measurement&quot;) %&gt;% separate(col = trait, into = c(&quot;part&quot;, &quot;measure&quot;)) %&gt;% ggplot(aes(y=measurement,x=part,fill=part)) + geom_boxplot() + facet_grid(~measure) + theme_bw() Se også unite() som gøre det modsatte til separate(). 6.4 Eksempel: Titanic opsummeringsstatistikker Her er et eksempel med datasættet titanic, der inddrager mange af de tidyverse-koncepter, vi har lært indtil videre. group_by() og summarise() Vi laver vores opsummeringsstatistikker som i ovenstående. titanic_clean_summary_by_sex &lt;- titanic_clean %&gt;% group_by(Sex) %&gt;% summarise(count = n(), meanSurvived = mean(Survived), meanAge = mean(Age), propFirst = sum(Pclass == 1) / n()) titanic_clean_summary_by_sex ## # A tibble: 2 × 5 ## Sex count meanSurvived meanAge propFirst ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 female 261 0.755 27.9 0.326 ## 2 male 453 0.205 30.7 0.223 pivot_longer() Vi transformerer eller reshaper datarammen fra wide data til long data. Vi vil samle kun de numeriske opsummeringsstatistikker i en enkelt kolonne, så variablen Sex skal ikke indgå i den enkelte kolonne. titanic_clean_summary_by_sex %&gt;% pivot_longer(cols=-Sex) ## # A tibble: 8 × 3 ## Sex name value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 female count 261 ## 2 female meanSurvived 0.755 ## 3 female meanAge 27.9 ## 4 female propFirst 0.326 ## 5 male count 453 ## 6 male meanSurvived 0.205 ## 7 male meanAge 30.7 ## 8 male propFirst 0.223 ggplot() med facet_grid() Vi kombinerer pivot_longer() med et plot af vores opsummeringsstatistikker og benytter facet_grid() til at adskille de forskellige statistikker. titanic_clean_summary_by_sex %&gt;% pivot_longer(cols = -Sex) %&gt;% ggplot(aes(x = Sex, y = value, fill = Sex)) + geom_bar(stat = &quot;identity&quot;) + facet_grid(~name) + theme_bw() facet_wrap() Vi laver det samme som ovenstående, men specificerer facet_wrap() i stedet for facet_grid(). Indenfor facet_wrap() kan man bruge indstillingen scales=\"free\", som gør, at de fire plots får hver deres egne aksegrænser. titanic_clean_summary_by_sex %&gt;% pivot_longer(cols=-Sex) %&gt;% ggplot(aes(x=Sex,y=value,fill=Sex)) + geom_bar(stat=&quot;identity&quot;) + facet_wrap(~name,scales=&quot;free&quot;,ncol=4) + theme_bw() 6.4.1 Demonstration af pivot_wider() Det er også brugbart at kende måden at man skifter fra long form til wide form. Wide -&gt; Long titanic_summary_long &lt;- titanic_clean_summary_by_sex %&gt;% pivot_longer(cols=-Sex) Long -&gt; Wide titanic_summary_long %&gt;% pivot_wider(names_from = &quot;name&quot;,values_from = &quot;value&quot;) ## # A tibble: 2 × 5 ## Sex count meanSurvived meanAge propFirst ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 female 261 0.755 27.9 0.326 ## 2 male 453 0.205 30.7 0.223 Parametre er: names_from - nøglekolonne, som skal udgøre flere kolonner i den nye dataframe values_from - selve værdier, som skal være i de nye kolonner i den wide form 6.5 left_join(): forbinde dataframes Vi tager udgangspunkt i følgende to dataframes: gene_table &lt;- as_tibble(read.table(&quot;https://www.dropbox.com/s/6ll8ezrskly8joi/mouse_2gene_expr.txt?dl=1&quot;,header=T)) coldata &lt;- as_tibble(read.table(&quot;https://www.dropbox.com/s/jlrszakmqlnmu2m/bottomly_phenodata.txt?dl=1&quot;)) Lad os først kigge på datasættet gene_table, som viser genekspressionsmålinger over forskellige prøver fra mus. gene_table ## # A tibble: 3 × 22 ## gene SRX033480 SRX033488 SRX033481 SRX033489 SRX033482 SRX033490 SRX033483 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ENSMUSG… 158. 182. 119. 155. 167. 164. 180. ## 2 ENSMUSG… 143. 118. 91.6 106. 157. 95.1 131. ## 3 ENSMUSG… 132. 117. 100. 116. 88.1 125. 124. ## # ℹ 14 more variables: SRX033476 &lt;dbl&gt;, SRX033478 &lt;dbl&gt;, SRX033479 &lt;dbl&gt;, ## # SRX033472 &lt;dbl&gt;, SRX033473 &lt;dbl&gt;, SRX033474 &lt;dbl&gt;, SRX033475 &lt;dbl&gt;, ## # SRX033491 &lt;dbl&gt;, SRX033484 &lt;dbl&gt;, SRX033492 &lt;dbl&gt;, SRX033485 &lt;dbl&gt;, ## # SRX033493 &lt;dbl&gt;, SRX033486 &lt;dbl&gt;, SRX033494 &lt;dbl&gt; Man kan se, at der er 22 kolonner i datasættet - én der refererer til et gen-navn og 21, der er forskellige prøver fra eksperimentet. Men det er ikke klart, hvad den enkelte prøve egentlig er. Lad os derfor kigge på de prøveoplysninger, som kan være nyttige at inddrage i vores analyse/plots for at undersøge eventuelle batcheffekter osv. coldata ## # A tibble: 21 × 5 ## sample num.tech.reps strain batch lane.number ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 SRX033480 1 C57BL.6J 6 1 ## 2 SRX033488 1 C57BL.6J 7 1 ## 3 SRX033481 1 C57BL.6J 6 2 ## 4 SRX033489 1 C57BL.6J 7 2 ## 5 SRX033482 1 C57BL.6J 6 3 ## 6 SRX033490 1 C57BL.6J 7 3 ## 7 SRX033483 1 C57BL.6J 6 5 ## 8 SRX033476 1 C57BL.6J 4 6 ## 9 SRX033478 1 C57BL.6J 4 7 ## 10 SRX033479 1 C57BL.6J 4 8 ## # ℹ 11 more rows Man kan se forskellige oplysninger om de 21 prøver, blandt andet den stamme af mus, hver prøve stammer fra, og den batch. Her refererer batch til de forskellige omstændigheder eller tidspunkter, hvor prøverne blev samlet. Hvis man er interesseret i, om der er en forskel i ekspressionsniveau mellem de to stammer (strains), kan det være nødvendigt at kontrollere efter batch for at sikre, at forskellen skyldes strain og ikke tekniske effekter på grund af batch. 6.5.1 Funktionen left_join() fra dplyr-pakken Funktionen left_join() er en del af pakken dplyr, som vi har arbejdet meget med indtil videre i kurset. funktion Beskrivelse (kopieret) left_join() Tilføj matchende rækker fra den anden tabel til den første right_join() Tilføj matchende rækker fra den første tabel til den anden inner_join() Sammenføj to tabeller og returner alle rækker, der er til stede i begge full_join() Sammenføj data med alle mulige rækker til stede Vi fokuserer her på funktionen left_join() fordi den er mest brugbar i biologiske dataanalyser, men vi kigger også på de øvrige funktioner gennem problemstillingerne nedenfor. Her er en grafisk demonstration af left_join() (kilde: https://mgimond.github.io/ES218/Week03c.html): Det særlige ved left_join i forhold til de andre funktioner er, at left_join bevarer samtlige data i dataframen, man tager udgangspunkt i - det vil sige df i ovenstående billede, selvom d ikke matcher med en frugt i dj. I ovenstående genekspressionseksempel betyder det, at man bevarer alle målinger i gene_table, uanset om der er oplysninger om deres pågældende prøver. 6.5.2 Anvend left_join() for vores datasæt. Ligesom man matcher kolonnen y i df og dj i ovenstående eksempel, skal vi også have en kolonne, vi kan matche. Vi vil gerne bruge kolonnen sample fra sample_info til at sammenligne med de forskellige prøvenavne i gene_table, men først er vi nødt til at lave gene_table om til long-form, således at prøvenavne fremgår i en enkelt kolonne, sample (der kan bruges i left_join). gene_table_long &lt;- gene_table %&gt;% pivot_longer(cols = -gene, names_to = &quot;sample&quot;, values_to = &quot;expression&quot;) gene_table_long ## # A tibble: 63 × 3 ## gene sample expression ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 ENSMUSG00000006517 SRX033480 158. ## 2 ENSMUSG00000006517 SRX033488 182. ## 3 ENSMUSG00000006517 SRX033481 119. ## 4 ENSMUSG00000006517 SRX033489 155. ## 5 ENSMUSG00000006517 SRX033482 167. ## 6 ENSMUSG00000006517 SRX033490 164. ## 7 ENSMUSG00000006517 SRX033483 180. ## 8 ENSMUSG00000006517 SRX033476 263. ## 9 ENSMUSG00000006517 SRX033478 276. ## 10 ENSMUSG00000006517 SRX033479 328. ## # ℹ 53 more rows Dernæst kan vi tilføje oplysningsdata fra sample_info. Her angiver vi by = \"sample\" fordi det er navnet på kolonnen, som vi gerne vil bruge til at forbinde de to datarammer - altså, det er med i begge datarammer, så left_join() kan bruge det som en slags nøgle til at vide, hvor alle de forskellige oplysninger skal tilføjes. data_join &lt;- gene_table_long %&gt;% left_join(coldata, by=&quot;sample&quot;) Nu, hvor vi har fået forbundet de to datarammer, kan man inddrage de ekstra oplysninger vi har fået i et plot. Her laver vi et plot med en farve til hver stamme og et plot med en farve til hver batch. gg2 &lt;- data_join %&gt;% ggplot(aes(y=expression,x=as.factor(strain),fill=gene)) + geom_boxplot() + facet_wrap(~gene,scales=&quot;free&quot;) + theme_minimal() + theme(legend.position = &quot;none&quot;) + ggtitle(&quot;Expression split according to strain&quot;) gg2 gg1 &lt;- data_join %&gt;% ggplot(aes(y=expression,x=as.factor(batch),fill=gene)) + geom_boxplot() + facet_wrap(~gene,scales=&quot;free&quot;) + theme_minimal() + theme(legend.position = &quot;none&quot;) + ggtitle(&quot;Expression split according to batch&quot;) gg1 6.6 Problemstillinger Problem 1) Lav quizzen - “Quiz - tidyverse - part 2”. Vi øver os videre med datasættet Titanic. Indlæs datasættet og udfør oprydning med følgende kode: library(tidyverse) library(titanic) titanic &lt;- as_tibble(titanic_train) titanic_clean &lt;- titanic %&gt;% select(-Cabin) %&gt;% drop_na() Problem 2) Fra titanic_clean datasættet, beregn den gennemsnitlige alder af alle passagerer ombord på skibet. titanic_clean %&gt;% summarise(....) #rediger her I samme kommando, beregn også den maksimale alder og den minimale alder, samt proportionen af passagerer, der er under 18 (for den sidste, se mit eksempel med Pclass tidligere i sektion 6.2.2). Dataframen skal se sådan ud: ## # A tibble: 1 × 4 ## mean_alder max_alder min_alder under_18p ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 29.7 80 0.42 0.158 Problem 3) a) Beregn samme opsummeringsstatistikker som i sidste problem, men brug group_by() til først at opdele efter variablen Pclass. b) Brug din nye dataframe med dine opsummeringsstatistikker til at lave et søjlediagram med stat=\"identity\" (i stedet for stat=\"count\" som er standarden), der viser den gennemsnitlige alder på y-aksen og er opdelt efter Pclass på x-aksen (vær opmærksom på datatypen for Pclass med hensyn til farverne/x-aksen). c) Anvend pivot_longer() på din dataframe med dine opsummeringsstatistikker (brug indstillingen cols = -Pclass i funktionen). d) Brug din long-form dataframe af dine opsummeringsstatistikker til at lave plots af alle opsummeringsstatistikker med én ggplot kommando (adskil dem ved at benytte facet_wrap og opdele efter Pclass indenfor hvert plot, ligesom i følgende). Problem 4) a) Beregn de samme opsummeringsstatistikker som i 2), men anvend group_by() for først at opdele efter både variablerne Pclass og Sex. OBS: Du får en advarsel “summarise() has grouped output by ‘Pclass’ …”, fordi din dataframe stadig betragtes som opdelt efter Pclass. Dette skal tages i betragtning, hvis du foretager yderligere beregninger på den. Brug til sidst ungroup() på din nye dataframe for at sikre, at den ikke længere er opdelt efter nogen variabel. b) Brug pivot_longer()-funktionen til at omdanne datasættet til long-form med dine opsummeringsstatistikker i en enkelt kolonne. Nøglekolonnen skal hedde stat, og kolonnen med værdierne skal hedde values. ## `summarise()` has grouped output by &#39;Pclass&#39;. You can override using the ## `.groups` argument. c) Lav et plot af alle opsummeringsstatistikker, som er i long-format og ligner følgende plot. Problem 5) group_by() med tre variabler og summarise(). Prøv en kombination med tre forskellige variabler (vælg selv) indenfor group_by() og brug summarise() til at beregne middelværdien for variablen Fare. Anvend ungroup() når du er færdig med at opsummere Lav et plot for at visualisere meanFare. Idé: som en mulighed, kan man tilføje variabler til facet_grid() - for eksempel facet_grid(~Var1 + Var2). Problem 6) pivot_longer() Først skal du lave to nye variabler ud fra SibSp og Parch, hvor der står “yes”, hvis værdien er større end 0. Anvend derefter select() på Fare, Age og dine to nye variabler. Lav derefter følgende plot: Problem 7) Pivot_wider() Vi har en tribble, som jeg har kopieret fra https://r4ds.had.co.nz/index.html. people &lt;- tribble( ~name, ~names, ~values, #-----------------|--------|------ &quot;Phillip Woods&quot;, &quot;age&quot;, 45, &quot;Phillip Woods&quot;, &quot;height&quot;, 186, &quot;Jessica Cordero&quot;, &quot;age&quot;, 37, &quot;Jessica Cordero&quot;, &quot;height&quot;, 156, &quot;Brady Smith&quot;, &quot;age&quot;, 23, &quot;Brady Smith&quot;, &quot;height&quot;, 177 ) Brug pivot_wider() på people for at får datasættet i wide-form således at age og height hver har deres egne kolonner. Problem 8) left_join() øvelse. Kør følgende kode med to tribbles: superheroes &lt;- tribble( ~name, ~alignment, ~gender, ~publisher, &quot;Magneto&quot;, &quot;bad&quot;, &quot;male&quot;, &quot;Marvel&quot;, &quot;Storm&quot;, &quot;good&quot;, &quot;female&quot;, &quot;Marvel&quot;, &quot;Mystique&quot;, &quot;bad&quot;, &quot;female&quot;, &quot;Marvel&quot;, &quot;Batman&quot;, &quot;good&quot;, &quot;male&quot;, &quot;DC&quot;, &quot;Joker&quot;, &quot;bad&quot;, &quot;male&quot;, &quot;DC&quot;, &quot;Catwoman&quot;, &quot;bad&quot;, &quot;female&quot;, &quot;DC&quot;, &quot;Hellboy&quot;, &quot;good&quot;, &quot;male&quot;, &quot;Dark Horse Comics&quot; ) publishers &lt;- tribble( ~publisher, ~yr_founded, &quot;DC&quot;, 1934L, &quot;Marvel&quot;, 1939L, &quot;Image&quot;, 1992L ) Vi har to dataframes - superheroes og publishers. Hvilken kolon kan man bruge til at forbinde de to dataframes? Brug left_join() til at tilføje oplysninger fra publishers til datarammen superheroes. Får man alle observationerne fra dataframen superheroes med i din nye dataframe? Benyt inner_join() til at forbinde publishers til superheroes - få man så nu alle observationer med denne gang? Benyt full_join() til at forbinde publishers til superheroes - hvor mange observationer få man med nu? Hvorfor? Problem 9) left_join() øvelse. Kør nedenstående kode, hvor der er to dataframes - iris2 og sample_table. Dataframen iris2 er ikke særlig informativ med hensyn til, hvad de forskellige prøver egentlig er, men oplysningerne om dem findes i sample_table. Brug left_join() til at tilføje sample_table til iris2 for at få en dataramme, som indeholder både data og oplysninger om prøverne. data(iris) iris2 &lt;- as_tibble(iris) names(iris2) &lt;- c(&quot;sample1&quot;,&quot;sample2&quot;,&quot;sample3&quot;,&quot;sample4&quot;,&quot;Species&quot;) samp_table &lt;- tribble( ~sample, ~part, ~measure, #------|-------|--------# &quot;sample1&quot;, &quot;Sepal&quot;, &quot;Length&quot;, &quot;sample2&quot;, &quot;Sepal&quot;, &quot;Width&quot;, &quot;sample3&quot;, &quot;Petal&quot;, &quot;Length&quot;, &quot;sample4&quot;, &quot;Sepal&quot;, &quot;Width&quot; ) iris2 %&gt;% glimpse() ## Rows: 150 ## Columns: 5 ## $ sample1 &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.8, 4.… ## $ sample2 &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.4, 3.… ## $ sample3 &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.6, 1.… ## $ sample4 &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.… ## $ Species &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, setosa… samp_table %&gt;% glimpse() ## Rows: 4 ## Columns: 3 ## $ sample &lt;chr&gt; &quot;sample1&quot;, &quot;sample2&quot;, &quot;sample3&quot;, &quot;sample4&quot; ## $ part &lt;chr&gt; &quot;Sepal&quot;, &quot;Sepal&quot;, &quot;Petal&quot;, &quot;Sepal&quot; ## $ measure &lt;chr&gt; &quot;Length&quot;, &quot;Width&quot;, &quot;Length&quot;, &quot;Width&quot; Problem 10) Separate() øvelse Tag udgangspunkt i datasættet titanic_clean og benyt funktionen separate() til at opdele variablen Name i to variabler, “Surname” og “Rest” (Godt råd: brug sep=\", \" for at undgå, at man får et unødvendigt mellemrum lige før “Rest”). Anvend separate() en gang til, men for at opdele variablen Rest i to variabler, “Titel” og “Names”. Hvad bruger man som sep? (Hint: brug “\\\\” foran en punktum). Beregn opsummeringsstatistikker for hver “Titel” - antal passagerer, gennemsnitsalder, andelen der overlevede og andelen der rejste i første klasse. Arrangér din nye dataframe efter, hvor mange personer der er for hver “Titel” - flest øverst og færrest nederst. Problem 11 Ekstra pivot_longer() øvelse Åbn datasættet airquality (data(airquality)) og lav følgende plot: ## `summarise()` has grouped output by &#39;Month&#39;. You can override using the ## `.groups` argument. Problem 12) Valgfri ekstra: lav en ny dataramme med alle passagerer, der hedder “Alice” eller “Elizabeth” (brug Google her). 6.7 Ekstra links Cheatsheet: https://github.com/rstudio/cheatsheets/blob/master/data-import.pdf "],["functional-programming-med-purrr-pakken.html", "Chapter 7 Functional programming med purrr-pakken 7.1 Inledning og læringsmålene 7.2 Iterative processer med map() funktioner 7.3 Brugerdefinerede funktioner 7.4 Nesting med nest() 7.5 Andre brugbar purrr 7.6 Problemstillinger 7.7 Ekstra notater og næste gang", " Chapter 7 Functional programming med purrr-pakken 7.1 Inledning og læringsmålene Emnet omhandler, hvordan man kan integrere funktioner for at forbedre reproducibilitet og gennemsigtighed i dine analyser. Det er ofte tilfældet i biologi, at man arbejder med flere datasæt eller variabler, der henviser til fx forskellige prøver, replikater eller batches, og ønsker at udføre den samme proces på dem alle samtidig. I dette emne beskæftiger du dig med især pakken Purrr og map() funktioner, som kan benyttes til at lave gentagne baserende analyser i R. 7.1.1 Læringsmål Du skal være i stand til at: Anvende map()-funktioner til at udføre beregninger iterativt over flere kolonner. Bruge group_by() og nest() til at gennemføre reproducerbare analyser over forskellige dele af datasættet. Kombinere map() og map2() med brugerdefinerede funktioner for at øge fleksibiliteten i analyserne. 7.1.2 Videorressourcer Video 1: Introduktion til map()-funktioner for iteration over kolonner Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/549630848 Video 2: Introduction to custom functions and combining them with map Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/549630825 Video 3: Introduction to nest functions for breaking data into sections Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/549630798 7.2 Iterative processer med map() funktioner Når man udfører en iterativ proces, vil man ofte gentage den samme handling flere gange. Det kan for eksempel være, at vi har ti variabler, og vi ønsker at beregne middelværdien for hver variabel. Vi arbejder med datasættet eukaryotes, som indeholder oplysninger om forskellige organismer, der tilhører eukaryoter - for eksempel deres navne, grupper, undergrupper, antal proteiner/gener, genomstørrelse, og så videre. Du kan indlæse dataene med følgende kommando og se en liste over de forskellige kolonnenavne nedenfor. eukaryotes &lt;- read_tsv(&quot;https://www.dropbox.com/s/3u4nuj039itzg8l/eukaryotes.tsv?dl=1&quot;) ## Rows: 11508 Columns: 19 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;\\t&quot; ## chr (10): organism_name, bioproject_accession, group, subgroup, assembly_ac... ## dbl (7): taxid, bioproject_id, size_mb, gc, scaffolds, genes, proteins ## date (2): release_date, modify_date ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Vi tager udgangspunkt i kun fire variabler. For at gøre tingene mere overskuelige har jeg brugt select() til kun at få de fire variabler organism_name, center, group og subgroup ind i en dataframe. #eukaryotes_full &lt;- eukaryotes eukaryotes_subset &lt;- eukaryotes %&gt;% select(organism_name, center, group, subgroup) eukaryotes_subset %&gt;% glimpse() ## Rows: 11,508 ## Columns: 4 ## $ organism_name &lt;chr&gt; &quot;Pyropia yezoensis&quot;, &quot;Emiliania huxleyi CCMP1516&quot;, &quot;Arab… ## $ center &lt;chr&gt; &quot;Ocean University&quot;, &quot;JGI&quot;, &quot;The Arabidopsis Information … ## $ group &lt;chr&gt; &quot;Other&quot;, &quot;Protists&quot;, &quot;Plants&quot;, &quot;Plants&quot;, &quot;Plants&quot;, &quot;Plan… ## $ subgroup &lt;chr&gt; &quot;Other&quot;, &quot;Other Protists&quot;, &quot;Land Plants&quot;, &quot;Land Plants&quot;,… Lad os antage, at vi gerne vil beregne antallet af unikke organismer (variablen organism_name). Der er en funktion, der hedder n_distinct(), som beregner antallet af unikke værdier i en vektor/variabel. Her vælger vi variablen organism_name, og tilføjer så n_distinct()-funktionen. eukaryotes_subset %&gt;% select(organism_name) %&gt;% n_distinct() ## [1] 6111 Lad os forestille os, at vi også er interesseret i antallet af unikke værdier i variablerne center, group og subgroup - som er de tre andre kolonner i datasættet. Vi har forskellige muligheder: Vi kan skrive dem ud - men hvad nu hvis vi havde 100 variabler at håndtere? eukaryotes_subset %&gt;% select(organism_name) %&gt;% n_distinct() eukaryotes_subset %&gt;% select(center) %&gt;% n_distinct() eukaryotes_subset %&gt;% select(group) %&gt;% n_distinct() eukaryotes_subset %&gt;% select(subgroup) %&gt;% n_distinct() ## [1] 6111 ## [1] 2137 ## [1] 5 ## [1] 19 Vi har brug for en mere automatiseret løsning på dette. Vi bruger ikke tid på det her, men der er den traditionelle programmeringsløsning: en for-løkke, som også fungerer i R: col_names &lt;- names(eukaryotes_subset) for(column_name in col_names) { print(eukaryotes_subset %&gt;% select(column_name) %&gt;% n_distinct()) } ## Warning: Using an external vector in selections was deprecated in tidyselect 1.1.0. ## ℹ Please use `all_of()` or `any_of()` instead. ## # Was: ## data %&gt;% select(column_name) ## ## # Now: ## data %&gt;% select(all_of(column_name)) ## ## See &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. ## [1] 6111 ## [1] 2137 ## [1] 5 ## [1] 19 Man kan i teorien nøjes med for-løkker, men jeg vil gerne præsentere tidyverse-løsningen, som bliver mere intuitiv og lettere at læse, når man først er blevet vant til den (den integrerer også bedre med de andre tidyverse-pakker). 7.2.1 Introduktion til map() funktioner Tidyverse-løsningen er de såkaldte map()-funktioner, som er en del af purrr-pakken. Jeg introducerer dem her frem for base-R-løsningerne, ikke kun fordi de er en del af tidyverse, men også fordi de er en meget fleksibel og letforståelig tilgang, når man først er blevet vant til dem. Jeg vil vise, hvordan de fungerer ved hjælp af eukaryotes-datasættet, og derefter introducere dem i konteksten af brugerdefinerede funktioner og nest(), som kan bruges til at opdele datasættet i forskellige dele (oveni hvilke man kan gentage den samme proces). Man anvender map() ved at angive funktionsnavnet n_distinct inden i map(), og map() beregner så n_distinct() for hver kolonne i datasættet. eukaryotes_subset %&gt;% map(n_distinct) #do &#39;n_distinct&#39; for every single column ## $organism_name ## [1] 6111 ## ## $center ## [1] 2137 ## ## $group ## [1] 5 ## ## $subgroup ## [1] 19 Så kan man se, at vi har fået en list tilbage, der indeholder tal, som viser antallet af unikke værdier for hver af de fire kolonner. Det fungerer lidt som base-R funktionen apply, men med apply skal man bruge 2 på anden pladsen for at angive, at vi gerne vil iterere over kolonnerne. apply(eukaryotes_subset,2,n_distinct) ## organism_name center group subgroup ## 6111 2137 5 19 Bemærk, at vi her har fået en vektor af tal tilbage, men med map har vi fået en list. Der er faktisk andre varianter af map, som kan benyttes til at returnere resultatet i forskellige datatyper. For eksempel, kan man bruge map_dbl() til at få en double dbl tilbage - en vektor af tal, ligesom vi fik med apply i ovenstående. # Apply n_distinct to all variables, returning a double eukaryotes_subset %&gt;% map_dbl(n_distinct) ## organism_name center group subgroup ## 6111 2137 5 19 Man kan også bruge map_df() for at få en dataramme (tibble) tilbage - det er særligt nyttigt for os, da vi altid tager udgangspunkt i en dataramme, når vi skal lave et plot. # Apply n_distinct to all variables, returning a dataframe eukaryotes_subset %&gt;% map_df(n_distinct) ## # A tibble: 1 × 4 ## organism_name center group subgroup ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 6111 2137 5 19 For eksempel, kan man tilføje de tal fra map_df direkte ind i et ggplot. eukaryotes_subset %&gt;% map_df(n_distinct) %&gt;% pivot_longer(everything(), names_to = &quot;variable&quot;, values_to = &quot;count&quot;) %&gt;% ggplot(aes(x = variable, y = count,fill = variable)) + geom_col() + coord_flip() + theme_minimal() 7.2.2 Reference for de forskellige map-funktioner Dette er en kort oversigt over de forskellige map-funktioner i R og hvilken type data, de returnerer. Funktion Beskrivelse map_lgl() returnerer en logisk vektor map_int() returnerer en integervektor map_dbl() returnerer en doublevektor map_chr() returnerer en karaktervektor map_df() returnerer en dataramme 7.3 Brugerdefinerede funktioner Vi kan lave vores egne funktioner og benytte dem indenfor map()-funktionen for at yderligere øge fleksibiliteten i R. For eksempel, kan det være, at vi har en bestemt metode, vi gerne vil bruge til at normalisere vores data, og der eksisterer ikke en relevant funktion i R i forvejen. Ved at lave vores egne funktioner kan vi skræddersy vores dataanalyse til specifikke behov. 7.3.1 Simple funktioner Vi starter med en simpel funktion fra base-R og forklarer derefter dens struktur i tabellen nedenfor. Vi benytter oftest en anden form for funktioner i tidyverse, som vi ser på næste gang, men konceptet er det samme. my_function &lt;- function(.x) { return(sum(.x)/length(.x)) } Kode Beskrivelse my_function_name funktionens navn &lt;- function(.x) fortæller R, at vi laver en funktion, der tager data .x som input sum(.x)/length(.x) beregner gennemsnittet af data .x return() det output, som funktionen skal give - her gennemsnittet Lad os også afprøve vores nye funktion ved at beregne den gennemsnitlige værdi for Sepal.Length i datasættet iris. my_function(iris$Sepal.Length) mean(iris$Sepal.Length) ## [1] 5.843333 ## [1] 5.843333 7.3.2 Brugerdefinerede funktioner med mapping Inden for tidyverse skriver man funktioner på en lidt anden måde. Her er et eksempel på, hvordan den samme funktion kan skrives. my_function &lt;- ~ sum(.x)/length(.x) ~ betyder, at vi definerer en funktion. .x repræsenterer de data, som vi anvender funktionen på (for eksempel variablen Sepal.Length fra iris). Man bruger symbolet .x konsekvent, og R forstår automatisk, hvad det repræsenterer. Vi kan bruge my_function inden for map() for at beregne den gennemsnitlige værdi for alle variabler (uden Species), og vi kan se, at vi får et resultat, der svarer til funktionen mean(): iris %&gt;% select(-Species) %&gt;% map_df(my_function) iris %&gt;% select(-Species) %&gt;% map_df(mean) ## # A tibble: 1 × 4 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.84 3.06 3.76 1.20 ## # A tibble: 1 × 4 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.84 3.06 3.76 1.20 Man kan også placere funktionen direkte inden for map_df, i stedet for at oprette og henvise til den ved navn (f.eks. my_function): iris %&gt;% select(-Species) %&gt;% map_df(~ sum(.x)/length(.x)) #for hver datakolonne, beregn summen og divider med længden ## # A tibble: 1 × 4 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.84 3.06 3.76 1.20 Vi kan også specificere andre funktioner. iris %&gt;% map_df(~nth(.x,10)) #tag hver kolonne, kald den for .x og find den 10. værdi ## # A tibble: 1 × 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 4.9 3.1 1.5 0.1 setosa eller når nth er en tidyverse funktion, kan vi bruge %&gt;%: iris %&gt;% map_df(~.x %&gt;% nth(10)) #tag hver kolonne, kald den for .x og find den 10. værdi ## # A tibble: 1 × 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 4.9 3.1 1.5 0.1 setosa Antallet af distinkte værdier, som ikke er NA: #tag hver kolonne, kald den for .x og beregn n_distinct iris %&gt;% map_df(~.x %&gt;% n_distinct(na.rm = TRUE)) #n_dinstict er fra tidyverse ## # A tibble: 1 × 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 35 23 43 22 3 Bemærk, at hvis det er en indbygget funktion og vi benytter standardparametre (altså na.rm = FALSE i ovenstående), kan man blot skrive: iris %&gt;% map_df(n_distinct) ## # A tibble: 1 × 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 35 23 43 22 3 Et andet eksempel: læg 3 til og kvadrer resultatet: iris %&gt;% select(-Species) %&gt;% map_df(~(.x + 3)^2) %&gt;% head() ## # A tibble: 6 × 4 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 65.6 42.2 19.4 10.2 ## 2 62.4 36 19.4 10.2 ## 3 59.3 38.4 18.5 10.2 ## 4 57.8 37.2 20.2 10.2 ## 5 64 43.6 19.4 10.2 ## 6 70.6 47.6 22.1 11.6 Jo mere kompleks en funktion bliver, desto mere mening giver det at definere den uden for map()-funktionen: my_function &lt;- ~(.x - mean(.x))^2 + 0.5*(.x - sd(.x))^2 #en lang, meningsløs funktion iris %&gt;% select(-Species) %&gt;% map_df(my_function) #beregn my_function for hver kolonne og output en dataramme ## # A tibble: 150 × 4 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 9.68 4.89 5.63 1.16 ## 2 9.18 3.29 5.63 1.16 ## 3 8.80 3.84 6.15 1.16 ## 4 8.66 3.55 5.13 1.16 ## 5 9.41 5.30 5.63 1.16 ## 6 10.6 6.71 4.24 0.705 ## 7 8.66 4.51 5.63 0.916 ## 8 9.41 4.51 5.13 1.16 ## 9 8.46 3.06 5.63 1.16 ## 10 9.18 3.55 5.13 1.43 ## # ℹ 140 more rows 7.3.3 Effekten af map på andre datatyper I det ovenstående fokuserede jeg på map i forhold til dataframes. I group_by + nest anvender man map() på en liste af dataframes, kaldet data, hvilket tillader os at arbejde med hvert datasæt individuelt. Det er derfor værd at bruge lidt tid på at se, hvordan map() håndterer forskellige datatyper. Input: vektor .x refererer til en værdi i vektoren. Hvis man tager heltallet 1:10 og anvender map, så tager man hvert tal for sig og beregner en funktion med det - i det følgende simulerer man et tal fra den normale fordeling med parameteren mean=.x: c(1:10) %&gt;% map_dbl(~rnorm(1,mean=.x)) ## [1] 1.746477 2.037710 0.655867 3.612059 4.272457 7.067252 5.249570 ## [8] 8.898509 9.868653 10.101649 Input: dataframe .x refererer til en variabel fra dataframe. I det ovenstående er den første variabel int1, og i map tager man det første element med funktionen pluck(1). tibble(&quot;int1&quot;=1:10,&quot;int2&quot;=21:30) %&gt;% map(~.x %&gt;% pluck(1)) ## $int1 ## [1] 1 ## ## $int2 ## [1] 21 Med nest ser vi på muligheden for at lave map over en liste, der er skabt med funktionen nest(). Input: liste .x refererer til et element i listen - i det nedenstående er det første element c(1,2), så hvis man anvender funktionen max, så finder man den højeste værdi (2 i dette tilfælde). list(c(1,2),c(2,3),c(3,4)) %&gt;% map(~max(.x)) ## [[1]] ## [1] 2 ## ## [[2]] ## [1] 3 ## ## [[3]] ## [1] 4 Bemærk, at hvis der kun kommer et tal som resultat, kan man bruge map_dbl i stedet for map - så får man en vektor som output, selvom inputtet er en liste. list(c(1,2),c(2,3),c(3,4)) %&gt;% map_dbl(~max(.x)) ## [1] 2 3 4 Liste af dataframes .x refererer til et datasæt - så kan man referere til de forskellige variabler i .x, som man plejer i tidyverse. Det følgende er ligesom tilfældet med konceptet “nesting” i den næste sektion. Man tager en liste af tibbles og vælger det første tal fra variablen int. list(tibble(&quot;int&quot;=1:10),tibble(&quot;int&quot;=1:10),tibble(&quot;int&quot;=1:10)) %&gt;% map_int(~.x %&gt;% pluck(&quot;int&quot;,1)) ## [1] 1 1 1 7.4 Nesting med nest() Vi vil i den næste lektion se, at det er meget nyttigt at bruge funktionen nest() til at besvare en række statistiske spørgsmål. Det kan for eksempel være: Vi har udført 10 eksperimenter under lidt forskellige betingelser og ønsker at udføre nøjagtig den samme analyse på alle 10. Vi har 5 forskellige typer bakterier med 3 replikater hver, og vi ønsker at transformere data på samme måde for hver type bakterie og replikat. Funktionen nest() kan virke lidt abstrakt i starten, men konceptet er faktisk ret simpelt. Vi kan opdele vores datasæt (som indeholder vores forskellige betingelser/replikater osv.) med group_by() og derefter bruge nest() til at gemme de opdelte “underdatasæt” i en liste. Disse gemmes indenfor en kolonne i en tibble, hvilket gør det bekvemt at arbejde med de forskellige datasæt på samme tid (med hjælp fra map()). Lad os opdele eukaryotes_subset efter variablen ‘group’ og anvende nest(): eukaryotes_subset_nested &lt;- eukaryotes_subset %&gt;% group_by(group) %&gt;% nest() eukaryotes_subset_nested ## # A tibble: 5 × 2 ## # Groups: group [5] ## group data ## &lt;chr&gt; &lt;list&gt; ## 1 Other &lt;tibble [51 × 3]&gt; ## 2 Protists &lt;tibble [888 × 3]&gt; ## 3 Plants &lt;tibble [1,304 × 3]&gt; ## 4 Fungi &lt;tibble [6,064 × 3]&gt; ## 5 Animals &lt;tibble [3,201 × 3]&gt; Vi kan se, at vi har to variabler - group og data. Variablen data indeholder faktisk fem datarammer (tibbles). For eksempel indeholder det første datasæt kun observationer, hvor group er lig med “Other”, det andet datasæt har kun observationer, hvor group er lig med “Protists”, osv. Vi kan kontrollere dette ved at kigge på det første datasæt. Her er to måder at gøre det på: first_dataset &lt;- eukaryotes_subset_nested$data[[1]] first_dataset &lt;- eukaryotes_subset_nested %&gt;% pluck(&quot;data&quot;,1) first_dataset %&gt;% head() ## # A tibble: 6 × 3 ## organism_name center subgroup ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Pyropia yezoensis Ocean University Other ## 2 Thalassiosira pseudonana CCMP1335 Diatom Consortium Other ## 3 Guillardia theta CCMP2712 JGI Other ## 4 Cyanidioschyzon merolae strain 10D National Institute of Genetics… Other ## 5 Galdieria sulphuraria Galdieria sulphuraria Genome P… Other ## 6 Phaeodactylum tricornutum CCAP 1055/1 Diatom Consortium Other Hvis vi ønsker at vende tilbage til vores oprindelige datasæt, kan vi bruge unnest() og specificere kolonnen data: eukaryotes_subset_nested %&gt;% unnest(data) %&gt;% head() ## # A tibble: 6 × 4 ## # Groups: group [1] ## group organism_name center subgroup ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Other Pyropia yezoensis Ocean University Other ## 2 Other Thalassiosira pseudonana CCMP1335 Diatom Consortium Other ## 3 Other Guillardia theta CCMP2712 JGI Other ## 4 Other Cyanidioschyzon merolae strain 10D National Institute of Ge… Other ## 5 Other Galdieria sulphuraria Galdieria sulphuraria Ge… Other ## 6 Other Phaeodactylum tricornutum CCAP 1055/1 Diatom Consortium Other Spørgsmålet er så: hvordan kan vi inkorporere “nested” data i vores analyser? 7.4.1 Anvendelse af map() med nested data De fleste gange vi arbejder med nested data, er fordi vi ønsker at udføre den samme operation på hvert af de “sub” datasæt. Derfor er det her, funktionen map() kommer ind i billedet. Den typiske proces er: Tag det nestede datasæt Tilføj en ny kolonne med mutate(), hvor vi: Tager hvert datasæt fra kolonnen data og bruger map(), i det nedenstående eksempel til at finde antallet af rækker. eukaryotes_subset_nested %&gt;% mutate(n_row = map_dbl(data,nrow)) ## # A tibble: 5 × 3 ## # Groups: group [5] ## group data n_row ## &lt;chr&gt; &lt;list&gt; &lt;dbl&gt; ## 1 Other &lt;tibble [51 × 3]&gt; 51 ## 2 Protists &lt;tibble [888 × 3]&gt; 888 ## 3 Plants &lt;tibble [1,304 × 3]&gt; 1304 ## 4 Fungi &lt;tibble [6,064 × 3]&gt; 6064 ## 5 Animals &lt;tibble [3,201 × 3]&gt; 3201 Vi kan også bruge en brugerdefineret funktion. I det nedenstående eksempel beregner vi antallet af unikke organismer fra variablen organism_name i datasættet. Husk: ~ betyder, at vi laver en funktion, som kommer til at fungere for alle fem datasæt. Tag et datasæt og kald det for .x - det refererer til et bestemt datasæt fra en af de fem datasæt, som hører under kolonnen data i det nestede datasæt. Vælg variablen organism_name fra .x Beregn n_distinct n_distinct_organisms &lt;- ~ .x %&gt;% #tag data select(organism_name) %&gt;% #vælg organism_name n_distinct #returner antallet af unikke værdier # Gentag funktionen for hver af de fem datasæt: eukaryotes_subset_nested %&gt;% mutate(n_organisms = map_dbl(data, n_distinct_organisms)) ## # A tibble: 5 × 3 ## # Groups: group [5] ## group data n_organisms ## &lt;chr&gt; &lt;list&gt; &lt;dbl&gt; ## 1 Other &lt;tibble [51 × 3]&gt; 35 ## 2 Protists &lt;tibble [888 × 3]&gt; 490 ## 3 Plants &lt;tibble [1,304 × 3]&gt; 673 ## 4 Fungi &lt;tibble [6,064 × 3]&gt; 2926 ## 5 Animals &lt;tibble [3,201 × 3]&gt; 1987 Her er et andet eksempel. Her handler det om eukaryotes data (ikke subsettet), som har oplysninger om fx GC-indholdet med variablen gc. Her bruger vi pull i stedet for select - det er næsten det samme, men med pull() får vi en vektor, som fungerer med median, som er en base-R-funktion. # func_gc &lt;- ~ .x %&gt;% # pull(gc) %&gt;% # ligesom select, men vi har brug for en vektor for at beregne median # median(.x,na.rm=T) # `na.rm` fjerner `NA` værdier) func_gc &lt;- ~median(.x %&gt;% pull(gc),na.rm=T) ekaryotes_gc_by_group &lt;- eukaryotes %&gt;% group_by(group) %&gt;% nest() %&gt;% mutate(&quot;median_gc&quot;=map_dbl(data, func_gc)) ekaryotes_gc_by_group ## # A tibble: 5 × 3 ## # Groups: group [5] ## group data median_gc ## &lt;chr&gt; &lt;list&gt; &lt;dbl&gt; ## 1 Other &lt;tibble [51 × 18]&gt; 46.7 ## 2 Protists &lt;tibble [888 × 18]&gt; 49.4 ## 3 Plants &lt;tibble [1,304 × 18]&gt; 37.9 ## 4 Fungi &lt;tibble [6,064 × 18]&gt; 47.5 ## 5 Animals &lt;tibble [3,201 × 18]&gt; 40.6 Og jeg kan bruge resultatet i et plot, ligesom vi plejer: ekaryotes_gc_by_group %&gt;% ggplot(aes(x=group,y=median_gc,fill=group)) + geom_bar(stat=&quot;identity&quot;) + coord_flip() + theme_minimal() flere statistik på en gang Lave funktionerne: func_genes &lt;- ~median(.x %&gt;% pull(genes), na.rm=T) func_proteins &lt;- ~median(.x %&gt;% pull(proteins),na.rm=T) func_size &lt;- ~median(.x %&gt;% pull(size_mb), na.rm=T) Anvende nest(): eukaryotes_nested &lt;- eukaryotes %&gt;% group_by(group) %&gt;% nest() Tilføje resultatet over de fem datasæt med mutate(): eukaryotes_stats &lt;- eukaryotes_nested %&gt;% mutate(mean_genes = map_dbl(data,func_genes), proteins = map_dbl(data,func_proteins), mean_size_mb = map_dbl(data,func_size)) Husk at fjerne kolonnen data før man anvende pivot_longer() (ellers får man en advarsel): eukaryotes_stats %&gt;% select(-data) %&gt;% pivot_longer(-group) %&gt;% ggplot(aes(x=group,y=value,fill=group)) + geom_bar(stat=&quot;identity&quot;) + facet_wrap(~name,scales=&quot;free&quot;,ncol=4) + theme_bw() 7.5 Andre brugbar purrr 7.5.1 map2() funktion for flere inputs Funktionen map2() kan bruges ligesom map(), men tager to “inputs” i stedet for kun én. I det følgende eksempel angiver jeg to kolonner fra datasættet eukaryotes_stats, mean_genes og proteins, og beregner sum(), som bliver gemt takket være funktionen mutate i kolonnen colstat. eukaryotes_stats %&gt;% mutate(colstat = map2_dbl(mean_genes,proteins,sum)) ## # A tibble: 5 × 6 ## # Groups: group [5] ## group data mean_genes proteins mean_size_mb colstat ## &lt;chr&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Other &lt;tibble [51 × 18]&gt; 11354. 11240. 49.7 22594 ## 2 Protists &lt;tibble [888 × 18]&gt; 8813 8628. 33.5 17442. ## 3 Plants &lt;tibble [1,304 × 18]&gt; 33146. 37660 358. 70806. ## 4 Fungi &lt;tibble [6,064 × 18]&gt; 10069 10034 32.2 20103 ## 5 Animals &lt;tibble [3,201 × 18]&gt; 20733 25161 692. 45894 Bemærk, at præcis det samme resultat kan opnås ved blot at lægge de to kolonner sammen: eukaryotes_stats %&gt;% mutate(colstat2 = mean_genes + proteins) ## # A tibble: 5 × 6 ## # Groups: group [5] ## group data mean_genes proteins mean_size_mb colstat2 ## &lt;chr&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Other &lt;tibble [51 × 18]&gt; 11354. 11240. 49.7 22594 ## 2 Protists &lt;tibble [888 × 18]&gt; 8813 8628. 33.5 17442. ## 3 Plants &lt;tibble [1,304 × 18]&gt; 33146. 37660 358. 70806. ## 4 Fungi &lt;tibble [6,064 × 18]&gt; 10069 10034 32.2 20103 ## 5 Animals &lt;tibble [3,201 × 18]&gt; 20733 25161 692. 45894 Der er dog mange indviklet situationer hvor man ikke kan gå udenom map2: eukaryotes_stats_with_plots &lt;- eukaryotes_stats %&gt;% mutate(log10_genes = map(data,~log10(.x %&gt;% pull(genes)))) %&gt;% mutate(myplots = map2(group,log10_genes, ~ tibble(&quot;log10_genes&quot;=.y) %&gt;% ggplot(aes(x=log10_genes)) + geom_density(colour=&quot;red&quot;,alpha=0.3) + theme_bw() + ggtitle(paste(&quot;Density plot of log10(genes) in&quot;,.x)))) eukaryotes_stats_with_plots %&gt;% pluck(&quot;myplots&quot;,2) ## Warning: Removed 613 rows containing non-finite values (`stat_density()`). Der er flere map funktion der tager flere input fk. pmap - jeg har ikke tid til at dække dem men du kan godt læse om dem hvis du har bruge for dem: https://purrr.tidyverse.org/reference/map2.html 7.5.2 Transformering af numeriske variabler Som en sidste bemærkning, her er en nyttig variant af map - her kan man udføre en operation på kun bestemte variabler - for eksempel anvender jeg i det følgende funktionen log2() på alle numeriske variabler. Bemærk, at man er nødt til at anvende as_tibble() igen bagefter (som kun fungerer, hvis alle variabler stadig har samme længde efter map_if()): eukaryotes %&gt;% map_if(is.numeric,~log2(.x)) %&gt;% as_tibble() ## # A tibble: 11,508 × 19 ## organism_name taxid bioproject_accession bioproject_id group subgroup size_mb ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Pyropia yezo… 11.4 PRJNA589917 19.2 Other Other 6.75 ## 2 Emiliania hu… 18.1 PRJNA77753 16.2 Prot… Other P… 7.39 ## 3 Arabidopsis … 11.9 PRJNA10719 13.4 Plan… Land Pl… 6.90 ## 4 Glycine max 11.9 PRJNA19861 14.3 Plan… Land Pl… 9.94 ## 5 Medicago tru… 11.9 PRJNA10791 13.4 Plan… Land Pl… 8.69 ## 6 Solanum lyco… 12.0 PRJNA119 6.89 Plan… Land Pl… 9.69 ## 7 Hordeum vulg… 16.8 PRJEB34217 19.1 Plan… Land Pl… 12.1 ## 8 Oryza sativa… 15.3 PRJNA12269 13.6 Plan… Land Pl… 8.55 ## 9 Triticum aes… 12.2 PRJNA392179 18.6 Plan… Land Pl… 13.9 ## 10 Zea mays 12.2 PRJNA10769 13.4 Plan… Land Pl… 11.1 ## # ℹ 11,498 more rows ## # ℹ 12 more variables: gc &lt;dbl&gt;, assembly_accession &lt;chr&gt;, replicons &lt;chr&gt;, ## # wgs &lt;chr&gt;, scaffolds &lt;dbl&gt;, genes &lt;dbl&gt;, proteins &lt;dbl&gt;, ## # release_date &lt;date&gt;, modify_date &lt;date&gt;, status &lt;chr&gt;, center &lt;chr&gt;, ## # biosample_accession &lt;chr&gt; 7.6 Problemstillinger Problem 1) Lave Quiz på Absalon “Quiz - functional programming” Problem 2) Basis øvelser med map() Indlæse diamonds med data(diamonds). Eksempel: diamonds %&gt;% select(cut,color,depth) %&gt;% map_df(n_distinct) ## # A tibble: 1 × 3 ## cut color depth ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 5 7 184 Husk også referencen med de forskellige varianter af map() som kan bruges for at få en anden output type. Brug map() funktioner til at beregne følgende: a) Andvend select for at udvælge variabler cut, color og clarity, og dernæst beregn antallet af unikke værdier til hver (n_distinct-funktionen). Dit resultat skal være en list (lst - anvende standard map() funktion). b) Udvalg variablerne som er numeriske og dernæst beregne gennemsnittet til hver. Dit resultat skal være en double (dbl). c) Beregne datatypen (anvend funktionen typeof()) til alle variabler. Resultatet skal være en dataframe. Problem 3) map() øvelse med brugerdefinerede funktioner Indlæse diamonds med data(diamonds). Husk, at når man inddrager nogle data .x, for eksempel når man vil bruge en custom funktion eller specificer ikke-standard indstillinger såsom na.rm=TRUE (for at fjerne NA værdier i beregningen) i funktionen, skal man angiv ~ i starten: diamonds %&gt;% map_df(n_distinct) #specificere funktion unden instillinger diamonds %&gt;% map_df(~n_distinct(.x,na.rm = TRUE)) #custom funktion - skal have ~ og .x a) Afprøve følgende kode linjer og beskrive hvad der sker (nth(.x,1) angiver den første værdi fra .x) : diamonds %&gt;% select(carat, depth, price) %&gt;% map_df(~mean(.x,na.rm=T)) diamonds %&gt;% select(carat, depth, price) %&gt;% map_df(~ifelse(.x&gt;mean(.x),&quot;big_value&quot;,&quot;small_value&quot;)) diamonds %&gt;% filter(cut==&quot;Ideal&quot;) %&gt;% select(&quot;color&quot;,&quot;clarity&quot;) %&gt;% map(~nth(.x,100)) b) Brug brugerdefinerede funktioner inden for map() til at beregne følgende: Vælg variablerne carat, depth, table og price, og for hver kolonne, læg tre til værdierne og kvadrer derefter resultatet (^2). Det endelige resultat skal være en dataramme. Vælg de numeriske variabler og returner TRUE, hvis den første værdi i kolonnen (angivet med nth(.x,1)) er større end medianværdien i samme kolonne. Hvis ikke, returner FALSE. Det endelige resultat skal være en logisk værdi. Problem 4) Brug af map på forskellige datatyper Vi har set, at når vi anvender map() på en dataframe, anvendes en funktion på hver kolonne. Lad os se, hvad der sker, når vi har forskellige datatyper: a) (En vektor af tal) Kør det følgende og bemærk, at funktionen i map() anvendes til hvert tal i vectoren. c(1:10) %&gt;% map_dbl(~.x*2) c(1:10) %&gt;% map_dbl(~rnorm(1,mean=.x,sd=1)) Tag udgangspunkt i c(1:10) og brug map_dbl til at beregne log() for hvert tal i vektoren (angiv indstillingen base=5): c(1:10) %&gt;% ??? b) Omdan c(1:10) til en liste ved at bruge as.list(c(1:10)). Anvend de samme funktioner som i a) på listen. Bemærk, at funktionerne denne gang anvendes på hvert element i listen. Disse elementer kan også være dataframes - ligesom i det næste spørgsmål. Problem 5) group_by/nest øvelse a) For datasættet iris, anvend group_by(Species) og tilføj dernæst nest(), og kigger på resultatet. b) Tag udgangspunkt i dit nested dataframe fra a) tilføj pull(data) og se på resultatet fjern pull(data) og tilføj pluck(\"data\",1) i stedet for, for at se den første dataramme. fjern pluck(\"data\",1) og tilføj unnest(data) i stedet for og se på resultatet fjern unnest(data) og tilføj følgende i stedet for og prøve at forstå hvad der sker: mutate(new_column_nrow = map_dbl(data,nrow)) mutate(new_column_ratio = map(data,~(.x$Sepal.Width/.x$Sepal.Length))) Problem 6) Åbn datasættet msleep ved at bruge data(msleep). a) Bruge map()-funktionen for at beregn gennemsnitsværdierne for de numeriske variabler i msleep-datasættet (data(msleep)). Husk at anvende parameteren na.rm=T i mean()-funktionen for at fjerne manglende værdier i beregningen. b) Foretag samme beregning som i a), men kun for observationerne, hvor variablen vore er “carni”. c) Brug funktionerne group_by() og nest() til at opdele datasættet efter variablen vore. d) Tag udgangspunkt i din nestede dataframe fra c) og anvend map()-funktionen inden for mutate() for at oprette tre nye kolonner: num_rows - antallet af rækker i hver delmængde (resultat skal være heltal) mean_sleep - gennemsnitlig søvn (variablen sleep_total) i hver delmængde (bruge en brugerdefinerede funktion for at fjerne NA-værdierne i beregningen og an angiv resultat som en dbl) e) tilføj også en kolonne til din dataframe fra d), der hedder unique_genus - som viser antal unikke værdier i kolonne genus i hver delmængde (hint: brug funktionenerne length() og unique(), samt pull for at trækker variablen genus fra datasættet .x). Resultat skal være int. f) Tag udgangspunkt i dit resultat fra d) + e) og lav plots af dine opsummeringsstatistikker. f) I dette tilfælde, kunne samme plots fra e) også opnås ved at bruge group() og summarise()-funktioner på den oprindelige datasæt msleep. Prøv det. Problem 7) a) Anvend group_by og nest() for at opdel msleep efter variablen vore og brug følgende funktion sammen med map() for at oprette en ny kolonne i din nested dataframe, der hedder my_plots. Funktionen er: my_plot_func &lt;- ~ggplot(.x,aes(brainwt,sleep_total)) + geom_point() msleep_nested &lt;- msleep_nested %&gt;% ??? #opret ny kolonne her hvor du anvender funktionen b) Brug funktionen grid.arrange() fra R-pakken gridExtra til at vise plottene fra din nye kolonne (angive at parameteren grobs skal være din nye kolonne). Gør din plots pænere ved at tilføje et tema/farver osv. til my_plot_func fra a). Problem 8) Skift mellem long og wide form Tag udgangspunkt i datasættet iris. OBS: vi tilføjer kolonnen id så at hver plante (række) kan identificeres når vi går fra long- til wide- form i b). #kør denne kode data(iris) iris &lt;- iris %&gt;% mutate(id=1:nrow(iris)) #tilføj en id a) Anvend group_by() og nest() til at opdele datasættet efter Species b) Brug følgende funktion med map() for at tilføje en ny kolonne med navnet new_column_long til din nestede dataframe. #put data into long form my_func_longer &lt;- ~.x %&gt;% pivot_longer(cols=-id) c) Skriv en ny funktion og anvend den på kolonnen new_column_long (ikke data), der laver hvert (long-form) datasæt i kolonnen om til wide-form igen (lav ny kolonne new_column_wide). Her skal du bruge parameteren id_cols=id for at korrekte identificere de forskellige plante (uden id ved funktionen ikke, om eksempelvis en bestemt Sepal.Length værdi og en bestemt Sepal.Width værdi referere til præcis samme plante og derfor skal have samme række i wide-form). my_func_wider &lt;- ??? #lave long data om til wide form (husk at angiv names_from,values_from,id_cols) iris_nested %&gt;% ???#anvend din funktion d) Anvend pluck()-funktionen på kolonnerne new_column_long og new_column_wide til at kigge på den første datasæt for at se, om du har outputtet i long/wide form som forventede. Problem 9) Forberedelse til næste lektion For at bedre kunne se værdien af at bruge group_by()/nest() + map() kan vi gennemgå en simpel eksampel som indledning til vores næste lektion. a) Vi bruger følgende funktion: my_func &lt;- ~ t.test(.x$Petal.Width,.x$Sepal.Length) anvend group_by(Species) og dernæst nest() på datasættet iris. tilføj mutate() til at lave en ny kolon som hedder t_test og bruge funktionen indenfor map() på kolonnen data. tilføj pull(t_test) til din kommando - man får de tre t-tests frem, som man lige har beregnet. prøv unnest(t_test) i stedet for pull(t_test) - man får en advarsel fordi de t-test resultater ikke er i en god form til at vise indenfor en dataramme. Vi vil gerne ændre deres output til tidy-form først. b) Nu installer R-pakken broom (install.packages(\"broom\")) og indlæs pakken. Vi vil gerne bruge funktionen glance(), der få statistikkerne fra t.test() ind i en pæn form. Lav samme som i a) men bruge følgende funktion i stedet for: library(broom) my_func &lt;- ~ t.test(.x$Petal.Width,.x$Sepal.Length) %&gt;% glance() Tilføj pull eller unnest til din kommando som før og se på resultatet. Man får en pæn dataramme frem med alle de forskellige statistikker fra t.test(). Vælg en statistik og omsætte den til et plot. Problem 10 Kun ekstra hvis du vil øve mere group_by/nest + map på datasættet mtcars –&gt; a) Åbn mtcars med data(mtcars) og anvende group_by()/nest() for at opdele datasættet i tre efter variablen cyl. b) Lave nye kolonner med map og inddrage hensigtsmæssige funktioner, som beskriver dine tre datasæt, der er lagret i kolonne data (outputtet skal være dbl): Antal observationer Korrelationskoefficient mellem wt og drat (funktionen cor) Antal unikke værdier fra variablen gear c) Omsætte dine statistikke til et plot for at sammenligne de tre datasæt. 7.7 Ekstra notater og næste gang https://r4ds.had.co.nz/iteration.html https://sanderwuyts.com/en/blog/purrr-tutorial/ "],["visualisering-af-trends.html", "Chapter 8 Visualisering af trends 8.1 Indledning og læringsmål 8.2 nest() og map(): eksempel med korrelation 8.3 Lineær regression - visualisering 8.4 Plot linear regresion estimates 8.5 Multipel regression og model sammenligning 8.6 Problemstillinger 8.7 Ekstra", " Chapter 8 Visualisering af trends #load following packages library(ggplot2) library(tidyverse) library(broom) library(glue) library(ggsignif) 8.1 Indledning og læringsmål 8.1.1 Læringsmål Du skal være i stand til at Anvende nest() og map() strukturen til at gentage en korrelationsanalyse over flere forskellige datasæt. Bruge ggplot funktionen geom_smooth() til at visualisere lineær regression eller loess-kurver. Kombinere map()/nest() og lm() til at beregne regressionsstatistikker for flere lineære regressionsmodeller på samme tid og sammenligne dem med anova(). 8.1.2 Introduktion til kapitlet I dette kapitel viser jeg flere eksempler på processen, hvor man anvender group_by() og nest() og dernæst map()-funktioner for at lave reproducerbare statistiske analyser. Vi fokuserer på eksempler med korrelationsanalyse og lineære regressionsmodeller, men den overordnede ramme kan anvendes i mange forskellige kontekster. 8.1.3 Videoressourcer OBS: Der er mange videoer til i dag, men de gentager samme proces fra sidste emner med group_by/nest og map mange gange (med forskellige statistiske metoder). Video 1: Korrelationskoefficient med nest() og map() Jeg gennemgår processen langsomt med en korrelationsanalyse Jeg introducerer glance til at lave outputtet fra statistiske metoder i pæn-format. OBS: Jeg sagde “antal gener” flere gange i videoen, men variablen log10_size_mb er faktisk genomstørrelse i megabaser. Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/709225323 Video 2: Lineær regression linjer med ggplot2 Jeg viser hvordan man tilføjer regression linjer på et plot Jeg sammenligne linjen med resultatet fra lm() Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/709225203 Video 3: Lineær regression med nest() og map() Den proces igen fra Video 1 men anvendte på lineær regression Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/709225158 Video 4: Multiple linær regression model Den samme process men med flere modeller og flere uafhængige variabler Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/709225266 Video 5: anova+map (OBS: muligvis mest udfordrende del i kurset) Benyt funktionen anova for at sammenligne to modeller, beregnet på datasættet penguins, og få outputtet i “tidy”-format med funktionen tidy() Lav en funktion med anova, der kan anvendes over alle arter med map2() Omsæt p-værdier fra sammenligningerne til et plot og tilføj signifikansannotationer Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/710108716 8.2 nest() og map(): eksempel med korrelation Man laver en korrelationsanalyse i R ved at benytte cor.test() (cor() fungerer også, hvis du kun ønsker at beregne koefficienten og ikke signifikans). Forestil dig, at du gerne vil finde ud af korrelationen mellem GC-indhold (variablen gc, procent G/C baser i genomet) og genomstørrelse (variablen log10_size_mb) i datasættet eukaryotes fra sidste lektion. I det følgende plotter jeg en density mellem gc og den transformerede variabel log10_size_mb, som er log10 genomstørrelse (ikke antal gener, som jeg sagde i videoen). eukaryotes &lt;- eukaryotes %&gt;% mutate(log10_size_mb = log10(size_mb)) eukaryotes %&gt;% mutate(log10_size_mb = log10(size_mb)) %&gt;% select(log10_size_mb,gc) %&gt;% pivot_longer(everything()) %&gt;% ggplot(aes(x=value,fill=name)) + geom_density(colour=&quot;black&quot;) + facet_wrap(~name,scales=&quot;free&quot;) + theme_bw() ## Warning: Removed 388 rows containing non-finite values (`stat_density()`). Plottet ser ud til at have flere “peaks”, og jeg mistænker, at der kan være nogle understrukturer indenfor dataene - eksempelvis på grund af de forskellige organismegrupper i variablen Group (Animals, Plants osv.). I det følgende benytter jeg alligevel cor.test() til at teste for korrelation mellem gc og log10_size_mb over hele datasættet: my_cor_test &lt;- cor.test(eukaryotes %&gt;% pull(gc), eukaryotes %&gt;% pull(log10_size_mb)) my_cor_test ## ## Pearson&#39;s product-moment correlation ## ## data: eukaryotes %&gt;% pull(gc) and eukaryotes %&gt;% pull(log10_size_mb) ## t = -15.678, df = 11118, p-value &lt; 2.2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.1652066 -0.1288369 ## sample estimates: ## cor ## -0.1470715 Outputtet fra cor.test (og mange andre metoder i R) er ikke særlig velegnet til at bruge indenfor en dataframe, så jeg introducerer en funktion, der hedder glance(), som findes i R-pakken broom. Funktionen glance() anvendes til at omdanne outputtet fra en statistisk test (f.eks. cor.test() eller lm()) til et tidy dataframe. Det gør det nemmere, for eksempel til at lave et plot, eller til at samle statistikker fra forskellige tests. library(broom) my_cor_test %&gt;% glance() FALSE # A tibble: 1 × 8 FALSE estimate statistic p.value parameter conf.low conf.high method alternative FALSE &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; FALSE 1 -0.147 -15.7 8.25e-55 11118 -0.165 -0.129 Pearson&#39;… two.sided Man kan se, at over hele datasættet, er der en signifikant negativ korrelation (estimate -0.147 og p-værdi 8.25054^{-55}) mellem de to variabler. Men jeg er imidlertid stadig mistænkelig over for eventuelle forskelle blandt de fem grupper fra variablen group. Jeg vil gerne gentage den samme analyse for de fem grupper fra variablen group hver for sig. En god tilgang til at undersøge det er at bruge rammen med group_by() og nest(), som vi lærte sidst. 8.2.1 Korrelation over flere datasæt på en gang Jeg tjekker først fordelingen af de to variabler opdelt efter variablen group: eukaryotes %&gt;% select(log10_size_mb,gc,group) %&gt;% pivot_longer(-group) %&gt;% ggplot(aes(x=value,fill=group)) + geom_density(colour=&quot;black&quot;,alpha=0.5) + #geom_histogram(bins=40,alpha=0.5,colour=&quot;black&quot;) + scale_fill_brewer(palette = &quot;Set1&quot;) + facet_wrap(~name,scales=&quot;free&quot;) + theme_bw() ## Warning: Removed 388 rows containing non-finite values (`stat_density()`). Man kan se, at der er forskelle blandt de fem grupper, og der kan sagtens forekomme forskellige sammenhænge mellem de to variabler. I det følgende benytter jeg rammen group_by() + nest(), som blev introduceret i sidste lektion. Trin 1: Benyt group_by() + nest() Jeg anvender group_by() på variablen group og derefter funktionen nest() for at opdele eukaryotes i fem forskellige datasæt (gemt i samme dataframe i en kolonne ved navn data): eukaryotes_nest &lt;- eukaryotes %&gt;% group_by(group) %&gt;% nest() eukaryotes_nest ## # A tibble: 5 × 2 ## # Groups: group [5] ## group data ## &lt;chr&gt; &lt;list&gt; ## 1 Other &lt;tibble [51 × 19]&gt; ## 2 Protists &lt;tibble [888 × 19]&gt; ## 3 Plants &lt;tibble [1,304 × 19]&gt; ## 4 Fungi &lt;tibble [6,064 × 19]&gt; ## 5 Animals &lt;tibble [3,201 × 19]&gt; Trin 2: Definer korrelationsfunktion Lad os definere korrelationstesten mellem gc og log10_size_mb i en funktion. Brug ~ lige i starten for at fortælle R, at man arbejder med en funktion. Specificer et bestemt datasæt (som er en delmængde af eukaryotes) indenfor cor.test() med .x For det specifikke datasæt benytter jeg .x %&gt;% pull(gc) og .x %&gt;% pull(size_mb) til at udtrække de relevante vektorer for at udføre testen cor.test. cor_test &lt;- ~cor.test(.x %&gt;% pull(gc), .x %&gt;% pull(log10_size_mb)) Vi vil gerne få statistikkerne fra cor.test() i en pæn form, så vi tilføjer glance() til den ovenstående funktion: library(broom) my_cor_test &lt;- ~cor.test(.x$gc,log10(.x$size_mb)) %&gt;% glance() Trin 3: Brug map() på det nestede datasæt Nu lad os køre vores funktion på det nestede dataframe. Vi bruger map() til at anvende funktionen my_cor_test på hvert af de fem datasæt. Det gøres ved at bruge funktionen map() indenfor funktionen mutate() til at oprette en ny kolonne, der hedder test_stats, hvor resultaterne fra hver af de fem tests gemmes. eukaryotes_cor &lt;- eukaryotes_nest %&gt;% mutate(test_stats=map(data,my_cor_test)) eukaryotes_cor ## # A tibble: 5 × 3 ## # Groups: group [5] ## group data test_stats ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; ## 1 Other &lt;tibble [51 × 19]&gt; &lt;tibble [1 × 8]&gt; ## 2 Protists &lt;tibble [888 × 19]&gt; &lt;tibble [1 × 8]&gt; ## 3 Plants &lt;tibble [1,304 × 19]&gt; &lt;tibble [1 × 8]&gt; ## 4 Fungi &lt;tibble [6,064 × 19]&gt; &lt;tibble [1 × 8]&gt; ## 5 Animals &lt;tibble [3,201 × 19]&gt; &lt;tibble [1 × 8]&gt; Trin 4: Anvend unnest() for at kunne se resultaterne For at kunne se statistikkerne bruger jeg funktionen unnest() på den nye variabel test_stats: eukaryotes_cor &lt;- eukaryotes_cor %&gt;% unnest(test_stats) eukaryotes_cor ## # A tibble: 5 × 10 ## # Groups: group [5] ## group data estimate statistic p.value parameter conf.low conf.high ## &lt;chr&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Other &lt;tibble&gt; 0.489 3.80 4.22e- 4 46 0.238 0.679 ## 2 Protists &lt;tibble&gt; 0.301 9.26 1.54e- 19 860 0.239 0.361 ## 3 Plants &lt;tibble&gt; -0.203 -7.37 3.10e- 13 1267 -0.255 -0.149 ## 4 Fungi &lt;tibble&gt; 0.377 31.2 3.87e-198 5884 0.355 0.399 ## 5 Animals &lt;tibble&gt; 0.0437 2.42 1.57e- 2 3053 0.00825 0.0790 ## # ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt; Trin 5: Lav et plot fra statistikker Vi kan bruge det direkte i et plot. Jeg fokuserer på korrelationskoefficienten i variablen estimate og omsætter den til et plot som følger: cor_plot &lt;- eukaryotes_cor %&gt;% ggplot(aes(x=group,y=estimate,fill=group)) + geom_bar(stat=&quot;identity&quot;,colour=&quot;black&quot;) + scale_fill_brewer(palette = &quot;Set3&quot;) + ylab(&quot;Correlation estimate&quot;) + theme_classic() cor_plot Bemærk at den overordnede proces her med cor.test ligner processen, hvis man anvender andre metoder såsom t.test, lm osv. Jeg gennemgår lidt om lineær regression og visualisering, og dernæst anvender processen på et eksempel med funktionen lm() og datasættet penguins. 8.3 Lineær regression - visualisering 8.3.1 Lineære trends Vi skifter over til datasættet penguins, som findes i pakken palmerpenguins. Man kan se i det følgende scatterplot mellem bill_length_mm og body_mass_g, at der er plottet en bedste rette linje gennem punkterne, som viser, at der er en positiv sammenhæng mellem de to variabler. ## `geom_smooth()` using formula = &#39;y ~ x&#39; Husk, at den bedste rette linje har en formel \\(y = a + bx\\), hvor \\(a\\) er skæringspunktet, og \\(b\\) er hældningen af linjen. Ideen med simpel lineær regression er, at man gerne vil finde de bedste mulige værdier for \\(a\\) og \\(b\\) for at plotte ovenstående linje således, at afstanden mellem linjen og punkterne bliver minimeret. Uden at gå i detaljer om, hvordan det beregnes, kan man bruge funktionen lm() som følger: mylm &lt;- lm(body_mass_g~bill_length_mm,data=penguins) mylm ## ## Call: ## lm(formula = body_mass_g ~ bill_length_mm, data = penguins) ## ## Coefficients: ## (Intercept) bill_length_mm ## 388.85 86.79 Skæringspunktet er således 388.85 og hældningen er 86.79. Det betyder, at hvis variablen bill_length_mm stiger med 1, så ville den forventede body_mass_g stige med 86.79. Man kan således bruge linjen til at lave forudsigelser. For eksempel, hvis jeg målte en ny pingvin og fandt ud af, at den havde en bill_length_mm på 50 mm, kunne jeg bruge min linje til at gætte dens body_mass_g: y &lt;- mylm$coefficients[1] + mylm$coefficients[2] * 50 y ## (Intercept) ## 4728.433 Jeg forventer derfor, at en pingvin med en næblængde på 50 mm vil have en vægt omkring 4728.4331411 g: ## `geom_smooth()` using formula = &#39;y ~ x&#39; 8.3.2 geom_smooth(): lm trendlinjer Indbygget i ggplot2 er en funktion kaldet geom_smooth(), som kan bruges til at tilføje den bedste rette linje til plottet. Man benytter den ved at specificere + geom_smooth(method=\"lm\") i plot-kommandoen: ggplot(penguins,aes(x=bill_length_mm,y=body_mass_g)) + geom_point() + theme_minimal() + geom_smooth(method=&quot;lm&quot;,se=FALSE) ## `geom_smooth()` using formula = &#39;y ~ x&#39; Det er nemt at bruge, og man kan tilføje et konfidensinterval, hvis man ønsker det. I ovenstående plot specificerede jeg se=FALSE, men hvis jeg angav se=TRUE (som er standard), ville jeg få følgende plot: ggplot(penguins,aes(x=bill_length_mm,y=body_mass_g)) + geom_point() + theme_minimal() + geom_smooth(method=&quot;lm&quot;,se=TRUE) ## `geom_smooth()` using formula = &#39;y ~ x&#39; 8.3.3 geom_smooth(): flere lm trendlinjer på samme plot For at tilføje en bedste rette linje for hver af de tre species i stedet for alle dataene samlet, er det meget nemt i ggplot2: man angiver bare colour=species indenfor æstetik (aes): ggplot(penguins,aes(x=bill_length_mm,y=body_mass_g,colour=species)) + geom_point() + theme_minimal() + geom_smooth(method=&quot;lm&quot;,se=FALSE) ## `geom_smooth()` using formula = &#39;y ~ x&#39; Så kan vi se, at der faktisk er tre forskellige trends her, så det giver god mening at bruge de tre forskellige linjer i stedet for kun én. 8.3.4 Trendlinjer med method==\"loess\" I ggplot er vi ikke begrænset til method=\"lm\" indenfor geom_smooth(). Lad os prøve med method=\"loess\" i stedet: library(palmerpenguins) penguins &lt;- drop_na(penguins) ggplot(penguins,aes(x=bill_length_mm,y=body_mass_g,colour=species)) + geom_point() + theme_minimal() + geom_smooth(method=&quot;loess&quot;,se=FALSE) ## `geom_smooth()` using formula = &#39;y ~ x&#39; På denne måde kan man fange trends, som ikke nødvendigvis er lineære - men bemærk, at det er mere ligetil at beskrive og fortolke en lineær trend (og beregne forudsigelser ud fra en lineær trend). 8.4 Plot linear regresion estimates For at finde vores estimates og tjekke signifikansen af en lineær trend, arbejder vi direkte med den lineære model funktion lm(): my_lm &lt;- lm(body_mass_g~bill_length_mm,data=penguins) summary(my_lm) ## ## Call: ## lm(formula = body_mass_g ~ bill_length_mm, data = penguins) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1759.38 -468.82 27.79 464.20 1641.00 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 388.845 289.817 1.342 0.181 ## bill_length_mm 86.792 6.538 13.276 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 651.4 on 331 degrees of freedom ## Multiple R-squared: 0.3475, Adjusted R-squared: 0.3455 ## F-statistic: 176.2 on 1 and 331 DF, p-value: &lt; 2.2e-16 Husk, at de tal, der er vigtige her (se også emne 1 og 2): p-værdien: &lt;2e-16 - den uafhængige variabel bill_length_mm har en signifikant effekt/betydning for body_mass_g. R-squared værdien: - den viser den andel af variancen i body_mass_g, som bill_length_mm forklarer: Hvis R-squared er tæt på 1, er der tæt på en perfekt korrespondance mellem bill_length_mm og body_mass_g. Hvis R-squared er tæt på 0, er der nærmest ingen korrespondance. 8.4.1 Anvendelse af lm() over nestede datasæt Vi kan benytte den samme proces som ovenpå i korrelationsanalysen. Vi bruger group_by til at opdele efter de tre species og så “nester” vi de tre datarammer: penguins_nest &lt;- penguins %&gt;% group_by(species) %&gt;% nest() penguins_nest ## # A tibble: 3 × 2 ## # Groups: species [3] ## species data ## &lt;fct&gt; &lt;list&gt; ## 1 Adelie &lt;tibble [146 × 7]&gt; ## 2 Gentoo &lt;tibble [119 × 7]&gt; ## 3 Chinstrap &lt;tibble [68 × 7]&gt; Jeg definerer en funktion, hvor man kan lave lineær regression og tilføjer glance() for at få modelstatistikkerne i en pæn form. #husk ~ og skriv .x for data og IKKE penguins lm_model_func &lt;- ~lm(body_mass_g~bill_length_mm,data=.x) %&gt;% glance() Vi kører en lineær model på hver af de tre datasæt med map() og ved at specificere funktionen lm_model_func, som vi definerede ovenfor. Vi bruger mutate() ligesom før til at tilføje statistikkerne som en ny kolonne kaldet lm_stats: penguins_lm &lt;- penguins_nest %&gt;% mutate(lm_stats=map(data,lm_model_func)) penguins_lm ## # A tibble: 3 × 3 ## # Groups: species [3] ## species data lm_stats ## &lt;fct&gt; &lt;list&gt; &lt;list&gt; ## 1 Adelie &lt;tibble [146 × 7]&gt; &lt;tibble [1 × 12]&gt; ## 2 Gentoo &lt;tibble [119 × 7]&gt; &lt;tibble [1 × 12]&gt; ## 3 Chinstrap &lt;tibble [68 × 7]&gt; &lt;tibble [1 × 12]&gt; Til sidst bruger vi funktionen unnest() på vores statistikker: penguins_lm &lt;- penguins_lm %&gt;% unnest(cols=lm_stats) penguins_lm ## # A tibble: 3 × 14 ## # Groups: species [3] ## species data r.squared adj.r.squared sigma statistic p.value df logLik ## &lt;fct&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie &lt;tibble&gt; 0.296 0.291 386. 60.6 1.24e-12 1 -1076. ## 2 Gentoo &lt;tibble&gt; 0.445 0.440 375. 93.6 1.26e-16 1 -873. ## 3 Chinst… &lt;tibble&gt; 0.264 0.253 332. 23.7 7.48e- 6 1 -490. ## # ℹ 5 more variables: AIC &lt;dbl&gt;, BIC &lt;dbl&gt;, deviance &lt;dbl&gt;, df.residual &lt;int&gt;, ## # nobs &lt;int&gt; Nu kan vi se, at vi har fået en dataramme med vores lineære modelstatistikker. Jeg tager r.squared og p.value og omsætter dem til et plot for at sammenligne dem over de tre species af pingviner. penguins_lm %&gt;% select(species,r.squared,p.value) %&gt;% mutate(&quot;-log10pval&quot; = -log10(p.value)) %&gt;% select(-p.value) %&gt;% pivot_longer(-species) %&gt;% ggplot(aes(x=species,y=value,fill=species)) + geom_bar(stat=&quot;identity&quot;) + scale_fill_brewer(palette = &quot;Set2&quot;) + facet_wrap(~name,scale=&quot;free&quot;,ncol=4) + coord_flip() + theme_bw() 8.4.2 Funktionen glue() til at tilføje etiketter Det kan være nyttigt at tilføje etiketter til vores plots, der indeholder de statistikker, vi netop har beregnet. For at gøre dette kan vi benytte følgende kode. Vi tager vores datasæt penguins_lm med vores beregnede statistikker og bruger det til at lave et datasæt, som kan benyttes i geom_text() i vores trend plot. Funktionen glue() (fra pakken glue) er en praktisk måde at sammensætte r.squared og p.value værdierne i en streng, der beskriver vores forskellige trends (lidt ligesom paste i base-R). library(glue) # til at sammensætte værdierne i en etiket label_data &lt;- penguins_lm %&gt;% mutate( rsqr = signif(r.squared, 2), # afrunder til 2 signifikante cifre pval = signif(p.value, 2), label = glue(&quot;r^2 = {rsqr}, p-værdi = {pval}&quot;) ) %&gt;% select(species, label) label_data FALSE # A tibble: 3 × 2 FALSE # Groups: species [3] FALSE species label FALSE &lt;fct&gt; &lt;glue&gt; FALSE 1 Adelie r^2 = 0.3, p-værdi = 1.2e-12 FALSE 2 Gentoo r^2 = 0.44, p-værdi = 1.3e-16 FALSE 3 Chinstrap r^2 = 0.26, p-værdi = 7.5e-06 Vi kan tilføje vores etiketdata ved hjælp af geom_text(). x og y specificerer, hvor på plottet teksten skal placeres, og husk at angive data=label_data og label=label indenfor aes(), når det drejer sig om en variabel i label_data. ggplot(penguins, aes(body_mass_g, flipper_length_mm, colour=species)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + geom_text( x = 5500, y = c(175,180,185), data = label_data, aes(label = label), #specificerer etiketdata fra ovenstående size = 4 ) + scale_color_brewer(palette = &quot;Set2&quot;) + theme_minimal() ## `geom_smooth()` using formula = &#39;y ~ x&#39; 8.5 Multipel regression og model sammenligning Vi kan også benytte samme ramme som ovenfor til at sammenligne forskellige modeller på tværs af de samme tre datasæt. Her definerer jeg lm_model_func, som kun har sex som den uafhængige variabel, og jeg bygger videre på denne model ved at definere lm_model_func2 og lm_model_func3, hvor jeg tilføjer ekstra uafhængige variabler, bill_length_mm og flipper_length_mm. Jeg er interesseret i, hvor meget af variansen i body_mass_g, de tre variabler kan forklare tilsammen, og om der er forskelle mellem de tre arter i species. lm_model_func &lt;- ~lm(body_mass_g ~ sex ,data=.x) lm_model_func2 &lt;- ~lm(body_mass_g ~ sex + bill_length_mm ,data=.x) lm_model_func3 &lt;- ~lm(body_mass_g ~ sex + bill_length_mm + flipper_length_mm ,data=.x) Bemærk, at jeg endnu ikke har tilføjet glance() her, men jeg har planer om at gøre det lidt senere i processen for at undgå at få for mange statistikker i min dataframe med mine resultater. Jeg anvender først group_by() efter species og derefter nest(): penguins_nest &lt;- penguins %&gt;% group_by(species) %&gt;% nest() penguins_nest ## # A tibble: 3 × 2 ## # Groups: species [3] ## species data ## &lt;fct&gt; &lt;list&gt; ## 1 Adelie &lt;tibble [146 × 7]&gt; ## 2 Gentoo &lt;tibble [119 × 7]&gt; ## 3 Chinstrap &lt;tibble [68 × 7]&gt; Her bruger jeg map tre gange indenfor den samme mutate-funktion for at konstruere de tre modeller for hver art (ni modeller i alt). penguins_nest_lm &lt;- penguins_nest %&gt;% mutate( model_sex = map(data,lm_model_func), model_sex_bill = map(data,lm_model_func2), model_sex_bill_flipper = map(data,lm_model_func3)) penguins_nest_lm ## # A tibble: 3 × 5 ## # Groups: species [3] ## species data model_sex model_sex_bill model_sex_bill_flipper ## &lt;fct&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; ## 1 Adelie &lt;tibble [146 × 7]&gt; &lt;lm&gt; &lt;lm&gt; &lt;lm&gt; ## 2 Gentoo &lt;tibble [119 × 7]&gt; &lt;lm&gt; &lt;lm&gt; &lt;lm&gt; ## 3 Chinstrap &lt;tibble [68 × 7]&gt; &lt;lm&gt; &lt;lm&gt; &lt;lm&gt; Nu vil jeg gerne trække nogle statistikker fra modellerne, så jeg kan sammenligne dem. Jeg vil gerne udføre samme proces på alle ni modeller - hvor jeg benytter funktionen glance til at få outputtet i en tidy-form, og så trække r.squared ud bagefter for at undgå at få for mange statistikker i min nye dataframe. get_r2_func &lt;- ~.x %&gt;% glance() %&gt;% pull(r.squared) Nu gælder det om at køre ovenstående funktion på alle mine modeller, som er gemt i tre kolonner, model_sex,model_sex_bill og model_sex_bill_flipper. Jeg gør dette indenfor map, så det også bliver udført for hver af de tre arter. penguins_nest_lm &lt;- penguins_nest_lm %&gt;% mutate(model_sex_r2 = map_dbl(model_sex, get_r2_func), model_sex_bill_r2 = map_dbl(model_sex_bill, get_r2_func), model_sex_bill_flipper_r2 = map_dbl(model_sex_bill_flipper, get_r2_func)) penguins_nest_lm %&gt;% select(species,model_sex_r2,model_sex_bill_r2,model_sex_bill_flipper_r2) ## # A tibble: 3 × 4 ## # Groups: species [3] ## species model_sex_r2 model_sex_bill_r2 model_sex_bill_flipper_r2 ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie 0.545 0.563 0.602 ## 2 Gentoo 0.649 0.691 0.716 ## 3 Chinstrap 0.291 0.331 0.476 Omdann til et plot: penguins_nest_lm %&gt;% pivot_longer(cols=c(&quot;model_sex_r2&quot;,&quot;model_sex_bill_r2&quot;,&quot;model_sex_bill_flipper_r2&quot;)) %&gt;% ggplot(aes(x=species,y=value,fill=name)) + geom_bar(stat=&quot;identity&quot;,position=&quot;dodge&quot;) + theme_minimal() Man kan se i plottet, at body_mass_g for arten “Gentoo” bedst forklares af de tre variabler, og den laveste r.squared er i det tilfælde, hvor variablen sex er den eneste uafhængige variabel og species er “Chinstrap”. 8.5.1 anova til at sammenligne de forskellige modeller Årsagen til, at jeg valgte at bruge glance() i en ny funktion til at udtrække r.squared værdier, var fordi jeg gerne ville bevare mine modeller i deres oprindelige form, så de kunne bruges indenfor anova(). Med anova() kan jeg direkte sammenligne to modeller og dermed få en p-værdi, der tester hypotesen om, at den ekstra variabel i den ene model signifikant forklarer den afhængige variabel (når man tager højde for de variabler, der er fælles for begge modeller). I det følgende skriver jeg en funktion, hvor jeg kan sammenligne to modeller med anova og udtrække p-værdien: aov_func &lt;- ~anova(.x,.y) %&gt;% tidy() %&gt;% pluck(&quot;p.value&quot;,2) ~ fordi det er en funktion (som jeg benytter for hver art og model sammenligning - i alt 9 gange!) anova for at sammenligne modellerne, der er angivet ved .x og .y (vi bruger map2, der tager to input i stedet for én, som i map) tidy() fungerer ligesom glance, men giver oversigt over statistikker og flere linjer - herunder p-værdien pluck - jeg vil kun have én statistik (“p.value”) - og den er gemt på anden position. Se følgende kode for anvendelse af anova og tidy på modellerne model_sex og model_sex_bill i arten “Adelie” (da jeg har brugt pluck med “1”, hvilket betyder den første position i listen): myaov &lt;- anova(penguins_nest_lm %&gt;% pluck(&quot;model_sex&quot;,1), penguins_nest_lm %&gt;% pluck(&quot;model_sex_bill&quot;,1)) myaov %&gt;% tidy #p.value for comparing the two models is in the second position ## # A tibble: 2 × 7 ## term df.residual rss df sumsq statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 body_mass_g ~ sex 144 1.39e7 NA NA NA NA ## 2 body_mass_g ~ sex + bill_l… 143 1.33e7 1 551805. 5.92 0.0162 Man kan se, at p-værdien er 0.016, som er signifikant, og det betyder, at den mere komplekse model, der også inddrager bill_length_mm, er den model, vi accepterer (dvs. effekten af variablen bill_length_mm på body_mass_g er signifikant i vores endelige model). Man kan lave en lignende sammenligning mellem samtlige par af modeller for de tre arter: penguins_nest_lm &lt;- penguins_nest_lm %&gt;% mutate(model_sex_vs_model_sex_bill = map2_dbl(model_sex,model_sex_bill,aov_func), model_sex_vs_model_sex_bill_flipper = map2_dbl(model_sex,model_sex_bill_flipper,aov_func), model_sex_bill_vs_model_sex_bill_flipper = map2_dbl(model_sex_bill,model_sex_bill_flipper,aov_func)) penguins_nest_lm %&gt;% select(species,model_sex_vs_model_sex_bill,model_sex_vs_model_sex_bill_flipper,model_sex_bill_vs_model_sex_bill_flipper) ## # A tibble: 3 × 4 ## # Groups: species [3] ## species model_sex_vs_model_s…¹ model_sex_vs_model_s…² model_sex_bill_vs_mo…³ ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie 0.0162 0.0000730 0.000273 ## 2 Gentoo 0.000142 0.00000592 0.00193 ## 3 Chinstrap 0.0540 0.0000621 0.0000795 ## # ℹ abbreviated names: ¹​model_sex_vs_model_sex_bill, ## # ²​model_sex_vs_model_sex_bill_flipper, ## # ³​model_sex_bill_vs_model_sex_bill_flipper Det kunne være nyttigt at inddrage p-værdierne i ovenstående plot med r.squared værdierne, for at se om der er en signifikant effekt, når man tilføjer flere variabler til modellen, samtidig med at r.squared stiger. I det følgende omsætter jeg r.squared statistikkerne for kun “Chinstrap” til et plot: library(ggsignif) stats_plot &lt;- penguins_nest_lm %&gt;% filter(species==&quot;Chinstrap&quot;) %&gt;% pivot_longer(cols=c(&quot;model_sex_r2&quot;,&quot;model_sex_bill_r2&quot;,&quot;model_sex_bill_flipper_r2&quot;)) %&gt;% ggplot(aes(x=name,y=value,fill=name)) + geom_bar(stat=&quot;identity&quot;,position=&quot;dodge&quot;) + coord_flip() + theme_bw() stats_plot I det følgende tilføjer jeg funktionen geom_signif til plottet - den tillader mig at tilføje signifikanslinjer/annotationer til plottet - det vil sige, den viser, hvilke to modeller jeg sammenligner, og angiver stjerner i henhold til de beregnede p-værdier. Du er velkommen til at kopiere min kode og tilpasse den til dine egne behov. Når jeg sammenligner modellerne “model_sex” og “model_sex_bill” for “Chinstrap”, er p-værdien over 0.05, så tilføjelsen af bill_length_mm i modellen var ikke signifikant - jeg tilføjer ingen stjerner men skriver “.” for at matche outputtet i lm. Når jeg sammenligner modellerne “model_sex” og “model_sex_bill_flipper”, kan jeg se, at p-værdien er under 0.05, så der er en signifikant effekt - bill_length_mm og flipper_length_mm forklarer den afhængige variabel body_mass_g, udover variablen sex. Jeg angiver “***“, fordi p-værdien er under 0.001 (se signifikanskoder i lm summary). Indstillingen y_position angiver, hvor jeg vil placere linjerne. stats_plot + geom_signif(comparisons = list(c(&quot;model_sex_r2&quot;, &quot;model_sex_bill_r2&quot;)), annotations=&quot;.&quot;, y_position = 0.35, tip_length = 0.03) + geom_signif(comparisons = list(c(&quot;model_sex_bill_r2&quot;, &quot;model_sex_bill_flipper_r2&quot;)), annotations=&quot;***&quot;, y_position = 0.5, tip_length = 0.03) + geom_signif(comparisons = list(c(&quot;model_sex_r2&quot;, &quot;model_sex_bill_flipper_r2&quot;)), annotations=&quot;***&quot;, y_position = 0.55, tip_length = 0.03) 8.6 Problemstillinger Problem 1) Quizzen på Absalon. Husk at have indlæste følgende: library(tidyverse) library(broom) data(msleep) msleep %&gt;% drop_na(vore) # data(iris) Problem 2) Grundlæggende korrelationsøvelse Brug data(mtcars) og cor.test() til at udføre en test af korrelationen mellem variablerne qsec og drat. Tip: Hvis du foretrækker at undgå brugen af $ til at specificere en kolonne indenfor cor.test(), kan du bruge mtcars %&gt;% pull(qsec) i stedet for mtcars$qsec. Tilføj funktionen glance() til dit resultat fra cor.test() for at se statistikkerne i tidy form (installer pakken broom hvis det er nødvendigt). Kan du genkende statistikkerne fra cor.test() i den resulterende dataramme? Problem 3) Nesting øvelse For datasættet msleep, anvend group_by() og nest() for at skabe en nested dataframe, hvor datasættet er opdelt efter variablen vore. Kald det for msleep_nest. Tilføj en ny kolonne til msleep_nest med mutate, der hedder n_rows og viser antallet af rækker i hvert af de fire datasæt - husk følgende struktur: msleep_nest %&gt;% mutate(&quot;n_rows&quot; = map(???,???)) #erstat ??? her I dette tilfælde kan du ændre map til map_dbl - gør det. Problem 4) Multiple korrelation Vi vil gerne beregne korrelationen mellem variablerne sleep_total og sleep_rem for hvert af de fire datasæt lagret i msleep_nest. Tilpas følgende funktion, så vi kan teste korrelationen mellem de to variabler. Tilføj glance() for at få vores data i tidy form. cor_test &lt;- ~cor.test(????,???) #erstat ??? og tilføj glance funktion Brug map() indenfor mutate() med din funktion for at beregne korrelationsstatistikkerne for hvert af de fire datasæt. Unnest din nye kolonne bagefter med unnest()-funktionen. Lav barplots af estimate og -log10(p.value) med den resulterende dataramme. Prøv også at tilføje %&gt;% pluck(\"estimate\",1) til din cor_test funktion og se på resultatet. Problem 5) Lineær regressionsøvelse Åbn LungCapData (inklusiv Age.Groups): LungCapData &lt;- read.csv(&quot;https://www.dropbox.com/s/ke27fs5d37ks1hm/LungCapData.csv?dl=1&quot;) glimpse(LungCapData) #se variabelnavne ## Rows: 725 ## Columns: 6 ## $ LungCap &lt;dbl&gt; 6.475, 10.125, 9.550, 11.125, 4.800, 6.225, 4.950, 7.325, 8.… ## $ Age &lt;int&gt; 6, 18, 16, 14, 5, 11, 8, 11, 15, 11, 19, 17, 12, 10, 10, 13,… ## $ Height &lt;dbl&gt; 62.1, 74.7, 69.7, 71.0, 56.9, 58.7, 63.3, 70.4, 70.5, 59.2, … ## $ Smoke &lt;chr&gt; &quot;no&quot;, &quot;yes&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;,… ## $ Gender &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;female&quot;, &quot;male&quot;… ## $ Caesarean &lt;chr&gt; &quot;no&quot;, &quot;no&quot;, &quot;yes&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;yes&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;… Anvend lm() med LungCap som den afhængige variabel og Age som den uafhængige variabel. Hvad er skæringstidspunktet og hældningen af den beregnede linje? Prøv at tilføje funktionen glance() til din lm funktion og angiv værdierne for r.squared og p.value. Problem 6) Lav et scatterplot med Age på x-aksen og LungCap på y-aksen. Ændre linjen til geom_smooth(method=\"lm\") Ændre linjen til geom_smooth(method=\"lm\",se=FALSE) Specificer nu en forskellig farve baseret på Gender. Hvordan adskiller de to linjer sig? Specificer nu en forskellig farve baseret på Smoke. Hvordan adskiller de to linjer sig? Problem 7) Øvelse i lineær regression på flere datasæt Vi vil gerne udføre lineær regression med LungCap og Age, men opdelt efter variablen Smoke. BEMÆRK: Vi følger den samme proces som i kursusnoterne, men med LungCapData i stedet for Penguins - se gerne kursusnoterne for inspiration. a) Brug group_by() og nest() for at opdele dit datasæt efter Smoke b) Lav en funktion, lm_model_func, som beregner en lineær regression med LungCap som den afhængige variabel og Age som den uafhængige variabel. Tilføj glance() til lm_model_func. c) Brug map() med din funktion inden i mutate() for at tilføje en ny kolonne kaldet lm_stats til din dataframe. Husk at unnest kolonnen lm_stats for at kunne se statistikkerne. d) Fortolkning - er variablen LungCap bedre forklaret af variablen Age hos rygere eller ikke-rygere? Problem 8) Her er tre modeller, alle med LungCap som den afhængige variabel, og alle tager højde for Age: my_lm_func1 &lt;- ~lm(LungCap ~ Age ,data=.x) my_lm_func2 &lt;- ~lm(LungCap ~ Age + Gender ,data=.x) my_lm_func3 &lt;- ~lm(LungCap ~ Age + Gender + Height,data=.x) a) Brug map til at lave tre nye kolonner i LungCapData_nest, én til hver af de tre modeller (uden glance() her, så vi kan bruge vores lm objekter senere). b) Skriv en funktion my_r2_func, der udtrækker “r.squared” værdierne fra dine modeller (her refererer .x i funktionen ikke til en dataframe, men til en beregnet model - hvad skal tilføjes?). Lav tre yderligere kolonner i LungCapData_nest, hvor du kører din funktion på dine modeller med map (outputtet skal være dbl). my_r2_func &lt;- ... LungCapData_nest &lt;- LungCapData_nest %&gt;% mutate(&quot;Age_only_R2&quot; = ..., &quot;Age_Gender_R2&quot; = ..., &quot;Age_Gender_Height_R2&quot;= ...) c) Omsæt dine beregnede r.squared værdier til et plot Problem 9 a) Skriv en funktion hvor man anvende anova() til at sammenligne to modeller, .x og .y og dernæst udtrækker p-værdien (det er den samme funktion som i kursusnotaterne). my_aov_func &lt;- ... b) Anvend din funktion med map2 til at sammenligne de tre modeller fra sidste spørgsmål. c) Lav et plot med dine resultater. d) Tilføj signifikans annotations på plottet med funktionen geom_signif() (tilpas gerne kode fra kursusnotaterne). 8.7 Ekstra https://www.tidymodels.org/learn/statistics/tidy-analysis/ "],["clustering.html", "Chapter 9 Clustering 9.1 Indledning og læringsmål 9.2 Method 1: K-means clustering 9.3 Kmeans: hvor mange clusters? 9.4 Metode 2: Hierarchical clustering 9.5 Problemstillinger", " Chapter 9 Clustering 9.1 Indledning og læringsmål 9.1.1 Læringsmål Du skal være i stand til at: Beskrive hvad k-means clustering går ud på Anvende kmeans og præsentere resultatet på en pæn (tidy) måde Anvende map over forskellige antal clusters og vælge det antal, der passer til dataene Anvende funktionen hclust for at lave en simpel hierarkisk clustering 9.1.2 Indledning til kapitel Formålet med clustering er at opdele observationerne i et datasæt i forskellige grupper (clusters eller klynger på dansk), således at observationerne i samme cluster ligner hinanden. Dette øger indsigt i datasættet ved f.eks. bedre at forstå strukturen. F.eks. hvor mange forskellige clusters er repræsenteret i mit datasæt? Og hvilke individuelle observationer tilhører hvilken cluster? I dette kapitel ser vi på, hvordan vi kan implementere både k-means clustering og hierarchical clustering inden for rammerne af tidyverse. 9.1.3 Video ressourcer Video 1: K-means clustering Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/553656150 Video 2: augment, glanced og tidy med K-means. OBS der er en lille fejl i koden omkring 6:00 - den anden geom_point skal være geom_point(data = kclust_tidy,aes(x=bill_length,y=bill_depth),shape=\"x,colour=\"black\") fordi tallerne er allerede basaserede på “scaled” data i kclust_tidy - se sektion 9.2.5 for uddybelse. Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/553656139 Video 3: Hvor mange clusters skal man vælge? Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/553656129 Video 4: Hierarchical clustering (OBS Video 4 mangler: se gerne kursusnotaterne og jeg laver videoen ASAP) 9.2 Method 1: K-means clustering library(palmerpenguins) library(tidyverse) library(broom) I k-means clustering bliver samtlige observationer tilknyttet den nærmeste cluster “centroid” (se “hvordan fungerer kmeans?” nedenunder). I k-means skal man specificere antallet af clusters, som observationerne skal opdeles i, på forhånd. Derfor kræver det en vis undersøgelsesindsats at vælge det bedste antal clusters, der passer til problemstillingen, eller som bedst repræsenterer datasættet. Lad os tage udgangspunkt i datasættet penguins. Vi begynder med at fjerne observationerne med NA i mindst én variabel ved at bruge funktionen drop_na, og ved at specificere at year skal være en faktor (for at skelne den fra de andre numeriske kolonner): data(penguins) penguins &lt;- penguins %&gt;% mutate(year=as.factor(year)) %&gt;% drop_na() Vi ved allerede i forvejen, at der er 3 species i disse data, som vi plotter her med forskellige farver. penguins %&gt;% ggplot(aes(x=bill_length_mm,y=body_mass_g,colour=species)) + geom_point() + theme_classic() Vi vil gerne bruge k-means clustering på de numeriske variabler i datasættet og beregne 3 clusters ud fra disse. Derefter kan det være interessant at sammenligne de clusters, vi får, med de tre arter af pingviner - hvor gode er disse clusters til at skelne mellem de forskellige arter, eller indfanger de en anden struktur i datasættet (for eksempel køn eller den ø, de bor på)? 9.2.1 Hvordan fungerer kmeans? K-means er en iterativ proces. Lad os forestille os, at vi gerne vil have tre clusters i vores data. Man starter med tre tilfældige observationer og kalder dem for clusterens middelværdier eller “centroids”. Man tilknytter alle observationer til én af de tre clusters (den nærmeste af de tre centroids), og beregner herefter en ny middelværdi/centroid for hver cluster. Man tilknytter samtlige observationer igen efter den nærmeste af de tre nye cluster centroids, og så gentager man processen flere gange. Efter flere gange konvergerer de tre centroids mod nogle faste værdier, der ikke længere ændrer sig meget, hver gang man gentager processen. Disse tre centroids definerer de tre endelige clusters, og samtlige observationer er tilknyttet én af disse. Figure 9.1: source: https://towardsdatascience.com/k-means-a-complete-introduction-1702af9cd8c Jeg beder ikke om detaljerne i metoden, men der er mange videoer på YouTube, der bedre forklarer, hvordan k-means fungerer, for eksempel: https://www.youtube.com/watch?v=4b5d3muPQmA Bemærk, at der er noget tilfældighed indbygget i algoritmen. Det betyder, at hver gang man anvender k-means, får man et lidt anderledes resultat. 9.2.2 Within/between sum of squares Man kan forestille sig, at hvis man laver en god clustering af et datasæt, så ligner observationerne inden for den samme cluster hinanden meget, mens observationerne i forskellige clusters er meget forskellige fra hinanden. Med andre ord, skal afstanden mellem observationerne i samme cluster være så lille som muligt, og afstanden mellem observationerne i forskellige clusters skal være så stor som muligt. For at måle dette kan man beregne følgende: total within sum of squares - den totale kvadrerede afstand fra observationerne til deres nærmeste centroid. total between sum of squares - den totale afstand fra centroids til alle andre centroids. Denne skal være så stor som muligt. 9.2.3 Kør k-means i R K-means fungerer kun på numeriske data, som vi kan vælge fra datasættet med select() i kombination med hjælpefunktionen where(is.numeric). Vi bruger også scale(), hvilket betyder, at alle variabler får den samme skala, og det forhindrer, at nogle får mere indflydelse end andre i det endelige resultat. penguins_scaled &lt;- penguins %&gt;% select(where(is.numeric)) %&gt;% scale() Man er også nødt til at specificere på forhånd, hvor mange clusters man ønsker at opdele datasættet i, så lad os sige centers=3 inden for funktionen kmeans() her og beregne vores clusters: kclust &lt;- kmeans(penguins_scaled,centers = 3) kclust ## K-means clustering with 3 clusters of sizes 119, 85, 129 ## ## Cluster means: ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 1 0.6537742 -1.1010497 1.1607163 1.0995561 ## 2 0.6710153 0.8040534 -0.2889118 -0.3835267 ## 3 -1.0452359 0.4858944 -0.8803701 -0.7616078 ## ## Clustering vector: ## [1] 3 3 3 3 3 3 3 3 3 3 3 3 2 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 ## [38] 3 2 3 3 3 3 2 3 3 3 2 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 2 3 3 3 2 3 2 3 3 3 2 ## [75] 3 2 3 3 3 3 3 3 3 3 3 2 3 3 3 2 3 3 3 2 3 2 3 3 3 3 3 3 3 2 3 2 3 2 3 2 3 ## [112] 3 3 3 3 3 3 3 3 3 3 3 3 2 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 1 1 ## [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## [260] 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 2 2 2 2 2 2 2 3 ## [297] 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 ## ## Within cluster sum of squares by cluster: ## [1] 139.4684 109.4813 120.7030 ## (between_SS / total_SS = 72.2 %) ## ## Available components: ## ## [1] &quot;cluster&quot; &quot;centers&quot; &quot;totss&quot; &quot;withinss&quot; &quot;tot.withinss&quot; ## [6] &quot;betweenss&quot; &quot;size&quot; &quot;iter&quot; &quot;ifault&quot; Man får forskellige ting frem, for eksempel: Cluster means - det svarer til de centroids markeret med x i figuren ovenfor - bemærk, at de er 4-dimensionelle, da vi har brugt 4 variabler til at beregne resultatet. Clustering vector - hvilken cluster hver observation er blevet tilknyttet. Within cluster sum of squares - Jo mindre, jo bedre - hvor meget observationerne inden for samme cluster ligner hinanden (den totale kvadrerede afstand fra observationerne til deres nærmeste centroid). 9.2.4 Ryd op i k-means resultaterne med pakken broom Fra pakken broom har vi indtil videre mest beskæftiget os med glance(). Med glance() får man én-linje baserede summary statistikker fra én eller flere modeller samlet i én dataramme, for at lette et plot/labels osv. Der er også to andre funktioner vi tager i brug her. Her er en beskrivelse af de tre. Broom verb Beskrivelse glance() single line summary - lav et elbow plot augment() Tilføj datasæt til clusters - lav plots farvet efter cluster tidy() Multi-line summary - ekstraher centroids For at lave et plot af clusters kan det især være nyttigt at benytte augment. Her kan man se, at vi har fået en kolonne, der hedder .cluster med i den oprindelige dataramme (jeg flyttede kolonnen til første plads i nedenstående kode, så man kan se den i outputtet af kursusnoterne). kc1 &lt;- augment(kclust, penguins) #clustering = første plads, data = anden plads kc1 %&gt;% select(.cluster,all_of(names(penguins))) ## # A tibble: 333 × 9 ## .cluster species island bill_length_mm bill_depth_mm flipper_length_mm ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 3 Adelie Torgersen 39.1 18.7 181 ## 2 3 Adelie Torgersen 39.5 17.4 186 ## 3 3 Adelie Torgersen 40.3 18 195 ## 4 3 Adelie Torgersen 36.7 19.3 193 ## 5 3 Adelie Torgersen 39.3 20.6 190 ## 6 3 Adelie Torgersen 38.9 17.8 181 ## 7 3 Adelie Torgersen 39.2 19.6 195 ## 8 3 Adelie Torgersen 41.1 17.6 182 ## 9 3 Adelie Torgersen 38.6 21.2 191 ## 10 3 Adelie Torgersen 34.6 21.1 198 ## # ℹ 323 more rows ## # ℹ 3 more variables: body_mass_g &lt;int&gt;, sex &lt;fct&gt;, year &lt;fct&gt; Nu benytter vi kc1 til at lave et plot. Her giver jeg en farve efter .cluster og form efter species, så vi kan sammenligne vores beregnede clusters med de tre forskellige arter. Bemærk her, at jeg kun har to variabler i plottet, men der er faktisk fire variabler, som blev brugt til at lave clusters med funktionen kmeans. En anden måde er at plotte de første to principal components i stedet for to af de fire variabler - det beskæftiger vi os med næste gang. ggplot(kc1, aes(x = scale(bill_length_mm), y = scale(bill_depth_mm))) + geom_point(aes(color = .cluster, shape = species)) + theme_minimal() Vi kan også f.eks. optælle, hvor mange af de tre arter vi får i hver af vores tre clusters, hvor vi kan se, at Adelie og Chinstrap er blevet mere blandet mellem to af de tre clusters end Gentoo. kc1 %&gt;% count(.cluster, species) ## # A tibble: 5 × 3 ## .cluster species n ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 1 Gentoo 119 ## 2 2 Adelie 22 ## 3 2 Chinstrap 63 ## 4 3 Adelie 124 ## 5 3 Chinstrap 5 9.2.5 Plot cluster centroids Næste skridt er at se på resultatet af funktionen tidy() fra broom-pakken. Her har vi fået en overskuelig dataramme med middelværdierne (centroids) for de tre clusters over de fire variabler, som blev brugt i beregningerne. kclust_tidy &lt;- kclust %&gt;% tidy() kclust_tidy ## # A tibble: 3 × 7 ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g size withinss ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 0.654 -1.10 1.16 1.10 119 139. ## 2 0.671 0.804 -0.289 -0.384 85 109. ## 3 -1.05 0.486 -0.880 -0.762 129 121. ## # ℹ 1 more variable: cluster &lt;fct&gt; Herefter benytter jeg kclust_tidy som et ekstra datasæt i ovenstående plot, men indenfor en anden geom_point() for at tilføje en x-form i midten af de tre clusters - se de følgende tre punkter, der forklarer nogle detaljer i koden: Jeg bruger funktionen scale() på bill_length_mm og bill_depth_mm, fordi mine centroids, som også skal med i plottet, blev beregnet på skalerede data. Jeg behøver ikke at anvende scale() på mine centroids lagret i kclust_tidy, så jeg angiver bare akser-variablerne i aes() uden at anvende scale(). Jeg har brugt color og shape som lokale aesthetics i den første geom_point() her, da de ikke eksisterer som kolonner i kclust_tidy. ggplot(kc1, aes(x = scale(bill_length_mm), # skal skalere de oprindelige data y = scale(bill_depth_mm))) + geom_point(aes(color = .cluster, shape = species)) + geom_point(data = kclust_tidy, aes(x = bill_length_mm, # behøver ikke at skalere igen y = bill_depth_mm), size = 10, shape = &quot;x&quot;, show.legend = FALSE) + theme_bw() Vi kan se, at vores clusters ikke præcist fanger de samme tre grupper, som variablen species - der er forskelle. Det kan være, at vi også har fanget nogle oplysninger om fx den ø, pingvinerne bor på, eller deres køn. 9.3 Kmeans: hvor mange clusters? Vi gættede på 3 clusters i den ovenstående analyse (da vi havde oplysninger om arter i forvejen), men det kunne godt være, at et andet antal clusters passer bedre til datasættet. Vi kan beregne flere clusterings og angive forskellige antal clusters, og dernæst bruge resultaterne fra disse til at træffe en beslutning om, hvor mange clusters vi vil angive i vores endelige clustering. Det er vigtigt at kunne finde frem til et passende antal clusters: For mange clusters kan resultere i overfitting, hvor vi har for mange til at fortolke eller give mening. For få kan betyde, at vi overser indsigter i strukturen eller vigtige tendenser i datasættet. 9.3.1 Få Broom output for forskellige antal clusters I det følgende laver jeg en brugerdefineret funktion, der laver en clustering på datasættet penguins_scaled, og hvor jeg angiver, at antallet af beregnede clusters skal være .x, der er et heltal (fx 1,3,99 osv.). Bemærk derfor, at selve data er den samme hver gang jeg anvender funktionen - det er bare antallet af clusters jeg beregner, der kan variere. my_func &lt;- ~kmeans(penguins_scaled,centers = .x) Dernæst laver jeg en tibble med variablen k, som indeholder heltal fra 1 op til 9. Når jeg anvender funktionen map på kolonnen k med ovenstående funktion my_func, svarer det til, at jeg anvender kmeans ni gange, med antal clusters fra 1 til 9. Jeg gemmer clustering resultaterne i en kolonne kaldet kclust, og så anvender jeg tidy, glance og augment til at få de forskellige outputter fra mine clusterings. kclusts &lt;- tibble(k = 1:9) %&gt;% mutate( kclust = map(k, my_func), tidied = map(kclust, tidy), glanced = map(kclust, glance), augmented = map(kclust, ~.x %&gt;% augment(penguins)) ) Husk, at for at få frem resultaterne i de forskellige formater fra tidy,glance og augment, er vi nødt til at anvende funktionen unnest() - her gemmer jeg resultaterne i tre nye dataframes, som vi kan referere til efterfølgende: kclusts_tidy &lt;- kclusts %&gt;% unnest(tidied) kclusts_augment &lt;- kclusts %&gt;% unnest(augmented) kclusts_glance &lt;- kclusts %&gt;% unnest(glanced) 9.3.2 Elbow plot (glance) Vi bruger tot.withinss fra outputtet fra glance() (dataframen kclusts_glance). Det giver målinger for den totale afstand af observationerne fra deres nærmeste centroid (within sum of squares). kclusts_glance ## # A tibble: 9 × 8 ## k kclust tidied totss tot.withinss betweenss iter augmented ## &lt;int&gt; &lt;list&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;list&gt; ## 1 1 &lt;kmeans&gt; &lt;tibble [1 × 7]&gt; 1328 1328. 9.09e-13 1 &lt;tibble&gt; ## 2 2 &lt;kmeans&gt; &lt;tibble [2 × 7]&gt; 1328 551. 7.77e+ 2 1 &lt;tibble&gt; ## 3 3 &lt;kmeans&gt; &lt;tibble [3 × 7]&gt; 1328 371. 9.57e+ 2 2 &lt;tibble&gt; ## 4 4 &lt;kmeans&gt; &lt;tibble [4 × 7]&gt; 1328 293. 1.03e+ 3 2 &lt;tibble&gt; ## 5 5 &lt;kmeans&gt; &lt;tibble [5 × 7]&gt; 1328 276. 1.05e+ 3 3 &lt;tibble&gt; ## 6 6 &lt;kmeans&gt; &lt;tibble [6 × 7]&gt; 1328 211. 1.12e+ 3 3 &lt;tibble&gt; ## 7 7 &lt;kmeans&gt; &lt;tibble [7 × 7]&gt; 1328 195. 1.13e+ 3 3 &lt;tibble&gt; ## 8 8 &lt;kmeans&gt; &lt;tibble [8 × 7]&gt; 1328 174. 1.15e+ 3 4 &lt;tibble&gt; ## 9 9 &lt;kmeans&gt; &lt;tibble [9 × 7]&gt; 1328 198. 1.13e+ 3 3 &lt;tibble&gt; Jo flere clusters, jo mindre er statistikken tot.withinss typisk, men vi kan se i det følgende plot, at efter 2 eller 3 clusters, er der ikke meget gevinst ved at bruge flere clusters. Derfor vælger man ofte enten 2 eller 3. Dette plot kaldes ofte for en ‘elbow’ plot - man vælger det antal, der ligger på ‘elbuen’, hvor der ikke er meget gevinst ved at inkludere flere clusters i datasættet (men det er selvfølgelig meget subjektivt, hvilket tal man vælger til sidst). kclusts_glance %&gt;% ggplot(aes(x = k, y = tot.withinss)) + geom_line() + geom_point() + theme_bw() 9.3.3 Automatisk beslutning med pakken NbClust Man kan også overveje at prøve noget mere automatisk. For eksempel, pakken NbClust laver 30 forskellige clustering-algoritmer på datasættet for antal clusters fra 2 op til 9, og for hver af disse tages en beslutning om det bedste antal clusters. Man kan således se, hvilket antal clusters der blev valgt flest gange af de forskellige algoritmer. library(NbClust) set.seed(24) #fordi outputtet fra NbClust har indbygget tilfældighed cluster_30_indexes &lt;- NbClust(data = penguins_scaled, distance = &quot;euclidean&quot;, min.nc = 2, max.nc = 9, method = &quot;complete&quot;) Som det ses nedenfor, er enten 2 eller 3 clusters optimalt, hvilket stemmer overens med ‘elbow’ plot-metoden. as_tibble(cluster_30_indexes$Best.nc[1,]) %&gt;% ggplot(aes(x=factor(value))) + geom_bar(stat=&quot;count&quot;,fill=&quot;blue&quot;) + xlab(&quot;Antal clusters&quot;) + ylab(&quot;Antal clustering-algoritmer der vælger dette antal&quot;) + coord_flip() + theme_minimal() 9.3.4 Visualisering af de forskellige antal clusters (augment) Vi kan også visualisere, hvordan de forskellige antal clusters tager sig ud. Her kan vi bruge vores resultater fra augment-funktionen (kclusts_augment), som indeholder tilknytningerne af observationerne til clusters for hver af de ni clusterings. Bemærk, at kclusts_augment har 2997 observationer. Dette svarer til 9 (antal clusterings) x 333 (antal observationer i penguins), fordi vi har brugt unnest til at samle alle resultaterne. kclusts_augment %&gt;% glimpse() ## Rows: 2,997 ## Columns: 13 ## $ k &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1… ## $ kclust &lt;list&gt; [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ tidied &lt;list&gt; [&lt;tbl_df[1 x 7]&gt;], [&lt;tbl_df[1 x 7]&gt;], [&lt;tbl_df[1 x … ## $ glanced &lt;list&gt; [&lt;tbl_df[1 x 4]&gt;], [&lt;tbl_df[1 x 4]&gt;], [&lt;tbl_df[1 x … ## $ species &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel… ## $ island &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse… ## $ bill_length_mm &lt;dbl&gt; 39.1, 39.5, 40.3, 36.7, 39.3, 38.9, 39.2, 41.1, 38.6… ## $ bill_depth_mm &lt;dbl&gt; 18.7, 17.4, 18.0, 19.3, 20.6, 17.8, 19.6, 17.6, 21.2… ## $ flipper_length_mm &lt;int&gt; 181, 186, 195, 193, 190, 181, 195, 182, 191, 198, 18… ## $ body_mass_g &lt;int&gt; 3750, 3800, 3250, 3450, 3650, 3625, 4675, 3200, 3800… ## $ sex &lt;fct&gt; male, female, female, female, male, female, male, fe… ## $ year &lt;fct&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007… ## $ .cluster &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1… I den følgende kode laver jeg et plot af flipper_length_mm mod bill_length_mm og anvender facet_wrap, så hver clustering får sit eget plot (så der er 333 observationer pr. plot). kclusts_augment %&gt;% ggplot(aes(x = flipper_length_mm, y = bill_length_mm, colour=.cluster)) + geom_point(aes(shape=factor(species)), alpha = 0.8) + facet_wrap(~ k) + theme_bw() Vi kan nemt inddrage kclusts_tidy() og lave “X”-mærker ved blot at tilføje en ekstra geom_point og specificere kclusts_tidy. Først anvender jeg funktionen rename, så variablen cluster fra kclusts_tidy matcher .cluster fra kclusts_augment. kclusts_tidy &lt;- kclusts_tidy %&gt;% rename(.cluster=cluster) kclusts_augment %&gt;% ggplot(aes(x = scale(flipper_length_mm), y = scale(bill_length_mm),colour=.cluster)) + #scale here geom_point(aes(shape=factor(species)), alpha = 0.8) + facet_wrap(~ k) + geom_point(data = kclusts_tidy, aes(x=flipper_length_mm,y=bill_length_mm), #already based on scaled data, so don&#39;t scale size = 10, shape = &quot;x&quot;,col=&quot;black&quot;, show.legend = FALSE) + theme_bw() Vi kan forsøge at kigge endnu dybere ind i resultaterne - her introducerer jeg sex som en ekstra variabel i plottet. Husk, at variablen sex ikke blev brugt i vores k-means clustering, men det kan være, at der er nogle aspekter ved de fire variabler, som kan fortælle os noget om kønnet på pingvinerne. For at spare plads, har jeg kun vist antallet af clusters fra 2 til 5. kclusts_augment %&gt;% filter(k %in% 2:5) %&gt;% ggplot(aes(x = scale(flipper_length_mm), y = scale(bill_length_mm),colour=.cluster)) + geom_point(aes(shape=factor(species)), alpha = 0.8) + facet_grid(sex ~ k) + geom_point(data = kclusts_tidy %&gt;% filter(k %in% 2:5), aes(x = flipper_length_mm, y = bill_length_mm), size = 10, shape = &quot;x&quot;, colour = &quot;black&quot;,show.legend = FALSE) + theme_bw() 9.3.5 Nest/map-ramme fra sidste gang Som en sidste bemærkning med k-means, kan man også lave en clustering for hver af de tre arter separat. I det følgende opretter jeg en nested dataframe, som indeholder tre datasæt (penguins opdelt efter variablen species), og jeg anvender den brugerdefinerede funktion scale_me til at udvælge de numeriske variabler og anvende scale() på hvert datasæt. scale_me &lt;- ~.x %&gt;% select(where(is.numeric)) %&gt;% scale penguins_nest &lt;- penguins %&gt;% group_by(species) %&gt;% nest() %&gt;% mutate(&quot;data_scaled&quot; = map(data, scale_me)) Dernæst laver jeg en brugerdefineret funktion til at lave en clustering på datasættet .x, og angiver at antallet af clusters skal være 3. Bemærk, at i den ovenstående sektion varierede vi antallet af clusters (indstilling centers), men her fastlægger vi antallet af clusters og varierer i stedet selve datasættet. cluster_me &lt;- ~.x %&gt;% kmeans(centers=3) Jeg anvender cluster_me på mine skalerede datasæt, og anvender derefter glance, augment og tidy på clustering-resultaterne ligesom tidligere (bemærk brugen af map til at augment de opdelte datasæt). penguins_nest &lt;- penguins_nest %&gt;% mutate(clusters = map(data_scaled,cluster_me), clusters_glance = map(clusters,glance), clusters_augment = map2(clusters,data_scaled,~.x %&gt;% augment(.y)), #I augment the scaled data so the correct scaling (based on individual datasets) appears in the next plot clusters_tidy = map(clusters,tidy)) nested_clusters_augment &lt;- penguins_nest %&gt;% unnest(clusters_augment) nested_clusters_tidy &lt;- penguins_nest %&gt;% unnest(clusters_tidy) Til sidste laver jeg en plot af resultaterne: nested_clusters_augment %&gt;% ggplot(aes(x=bill_length_mm,y=flipper_length_mm,colour=.cluster)) + #data already scaled geom_point() + facet_grid(~species) + geom_point(data=nested_clusters_tidy, shape=&quot;X&quot;,colour=&quot;black&quot;, size = 10) + theme_bw() 9.4 Metode 2: Hierarchical clustering K-means er en meget populær metode til at lave clustering, men der findes mange andre metoder, fx hierarkisk clustering. Vi skifter over til mtcars, og ligesom med kmeans skal vi først anvende scale på de numeriske kolonner i dataene. mtcars_scaled &lt;- mtcars %&gt;% select(where(is.numeric)) %&gt;% scale() I modsætning til k-means skal man først beregne afstanden mellem alle observationerne i dataene for at lave hierarkisk clustering. Det gør man med funktionen dist() (som bruger den euklidiske afstand som standard): d &lt;- dist(mtcars_scaled) For at lave en hierarkisk clustering anvender man funktionen hclust(). Metoden complete er standard, men man kan afprøve andre metoder (der er ikke en fast regel for, hvilken metode man skal bruge). mtcars_hc &lt;- hclust(d, method = &quot;complete&quot; ) # Metoder: &quot;average&quot;, &quot;single&quot;, &quot;complete&quot;, &quot;ward.D&quot; I det følgende arbejder vi lidt med mtcars_hc for at få nogle clusters frem, og for at lave et plot. 9.4.1 Vælge ønsket antal clusters Funktionen cutree anvendes til at få clusters fra resultaterne af funktionen hclust. For eksempel, hvis man gerne vil have 4 clusters, bruger man k = 4. Jeg specificerer order_clusters_as_data = FALSE for at få clusters i den rækkefølge, som passer til det plot (dendrogram) vi laver (bemærk at man skal have pakken dendextend installeret for at få det til at fungere). library(dendextend) clusters &lt;- cutree(mtcars_hc, k = 4, order_clusters_as_data = FALSE) Her laver jeg et overblik over, hvor mange observationer fra mtcars der er i hver cluster: tibble(&quot;cluster&quot;=clusters) %&gt;% group_by(cluster) %&gt;% summarise(n()) FALSE # A tibble: 4 × 2 FALSE cluster `n()` FALSE &lt;int&gt; &lt;int&gt; FALSE 1 1 7 FALSE 2 2 8 FALSE 3 3 12 FALSE 4 4 5 9.4.2 Lav et pænt plot af dendrogrammet med ggplot2 Først anvender jeg funktionen dendro_data() til at udtrække dendrogrammet fra hclust() resultaterne. library(ggdendro) dend_data &lt;- dendro_data(mtcars_hc %&gt;% as.dendrogram, type = &quot;rectangle&quot;) Vi tilføjer vores clusters, som vi beregnede ovenfor (det er derfor, vi sikrede rækkefølgen af clusters): dend_data$labels &lt;- dend_data$labels %&gt;% mutate(cluster = clusters) Vi benytter dend_data$segments og dend_data$labels til at lave et informativt plot af dataene med ggplot2. ggplot(dend_data$segments) + geom_segment(aes(x = x, y = y, xend = xend, yend = yend)) + coord_flip() + geom_text(data = dend_data$labels, aes(x, y, label = label,col=factor(cluster)), hjust=1,size=3) + ylim(-3, 10) + theme_dendro() Så kan man se, der er fire clusters i dengrammet, og biler der er tætest på hinanden ligner hinanden mest - fk. Merc 280C og Merc 280 må være meget éns, og er som forventet lige ved siden af hinanden i plottet. Man kan godt tilpasse ovenstående kode til et andet datasæt - se problemstillinger, men man må også gerne udvide plottet med de forskellige viden vi har om ggplot2. 9.4.3 Ekstra (valgfri): afprøve andre metoder på hierachical clustering Valfri ekstra hvis du vil afprøve de fire metoder i hclust - “average”, “single”, “complete” og “ward.D”. # samme ggplot kommando som ovenpå lavet til en funktion den_plot &lt;- ~ggplot(.x$segments) + geom_segment(aes(x = x, y = y, xend = xend, yend = yend)) + coord_flip() + geom_text(data = .x$labels, aes(x, y, label = label), hjust=1,size=2) + ylim(-4, 10) + theme_dendro() Vi iterate over de fire metoder og lave samme process som ovenpå med map. Derefter kan man lave et plot fk. med grid.arrange: # fire metoder: m &lt;- c( &quot;average&quot;, &quot;single&quot;, &quot;complete&quot;, &quot;ward.D&quot;) hc_results &lt;- tibble(method = m) %&gt;% mutate( kclust = map(method, ~hclust(d, method = .x)), dendrogram = map(kclust,as.dendrogram), den_dat = map(dendrogram,~dendro_data(.x,type=&quot;rectangle&quot;)), plot = map(den_dat,den_plot)) library(gridExtra) grid.arrange(grobs = hc_results %&gt;% pull(plot),ncol=2) 9.5 Problemstillinger Problem 1) Quiz - Clustering Problem 2) Funktionen kmeans. I ovenstående brugte vi mtcars i hierarchical clustering, men lad os se, hvordan det ser ud med k-means. Du er velkommen til at tilpasse min ovenstående kode, som jeg brugte til penguins datasættet: a) Benyt kmeans til at finde 2 clusters i datasættet mtcars: Husk at vælge kun de numeriske kolonner og skalér datasættet på forhånd. Gem din clustering som my_clusters. Hvor mange observationer er der i hver af de to clusters? b) Brug funktionen augment til at forbinde det oprindelige datasæt til dine clusters fra my_clusters (skriv mtcars indenfor funktionen augment). c) Brug dit “augmenterede” datasæt til at lave et scatterplot mellem to af de numeriske variabler (du vælger selv hvilke) i datasættet, og farvelæg dem efter dine beregnede klynger. Da du har knyttet det oprindelige datasæt (som ikke var skaleret) i augment()-funktionen, skal du skalere dine variabler i plottet. d) Tilføj tidy()-funktionen for at få fat i middelværdierne/centroids for hver af de 2 clusters, og tilpas min kode fra notaterne (sektion 9.2.5) for at tilføje dem til plottet som ‘x’ (husk at din “centers”/centroids er allerede baserede på scaled data så du behøver ikke at anvende scale på deres værdier). Problem 3) Hierarchical clustering øvelse Vi laver en analyse af det msleep datasæt. Jeg har lavet oprydningen og scaling for dig: data(msleep) msleep_clean &lt;- msleep %&gt;% select(name,where(is.numeric)) %&gt;% drop_na() msleep_scaled &lt;- msleep_clean %&gt;% select(-name) %&gt;% scale row.names(msleep_scaled) &lt;- msleep_clean$name Tilpas min kode fra kursusnotaterne (sektion 9.4) til at lave følgende: a) Benyt funktioner dist() og dernæst hclust() på datasættet msleep_scaled. b) Benyt cutree for at finde 5 clusters fra dine hclust-resultater, og kalde det for clusters. Husk at anvende order_clusters_as_data = FALSE så at vi har den korrekt rækkefølge for et plot (OBS man skal installere/indlæse pakken dendextend) c) Benyt dendro_data til at udtrække de dendrogram fra resultaterne og tilføj clusters til dend_data$labels (kopier kode fra 9.4.2). d) Lav et dengrogram plot: igen tilpas koden (9.4.2) for mtcars eksempel for nuværende data Problem 4) Inlæs data wholesale &lt;- read.csv(&quot;https://www.dropbox.com/s/7nb5pkruqt4fqn4/Wholesale%20customers%20data.csv?dl=1&quot;, header = TRUE) a) Foretag ændringer i datasættet i henhold til følgende instruktioner (og husk at gemme): Channel - anvend recode for at ændre til navne 1 = horeca 2 = retail Region - anvend recode for at ændre til navne 1 = Lisnon 2 = Oporto 3 = Other Anvend map_if til at transformere samtlige numeriske variabler med log (sektion 7.5.2) b) Udvælg de numeriske variabler fra dit datasæt og anvende scale() - kalde dit nye datasæt for wholescale_scale c) Tilpas min kode fra sektion 9.3.1 til at lave 10 clusterings (k=1:10) på wholesale_scale og gem dem i en dataframe, sammen med din clusterings resultater i “tidy”, “glance” og “augment” form. d) Lav et elbow plot fra dit output fra glance (sektion 9.3.2) e) Udvælg clusterings hvor k er fra 2 til 7 fra dit output fra augment og lav scatter plots af variabler Frozen VS Fresh, hvor du: Giv farve efter .cluster Adskil plots efter k Prøv dernæst at adskille dit plots yderligere efter Channel. f) Tilpas koden fra 9.3.5 til at lave en analyse for “hoerca” og “retail” (variablen Channel) hver for sig. Angiv 4 clusters i din analyse. g) Lav et plot af din clustering (adskilt efter variablen Channel) og få “x” på plotterne til at vise din cluster middelværdier for Frozen og Fresh. "],["principal-component-analysis-pca.html", "Chapter 10 Principal component analysis (PCA) 10.1 Indledning og læringsmålene 10.2 Hvad er principal component analysis (PCA)? 10.3 Fit PCA to data in R 10.4 Integrering af PCA-resultater med broom-pakken 10.5 Problemstillinger 10.6 Ekstra læsning", " Chapter 10 Principal component analysis (PCA) library(tidyverse) library(broom) 10.1 Indledning og læringsmålene 10.1.1 Læringsmålene Du skal være i stand til at Forstå koncepten bag principal component analysis (PCA) Benytte PCA i R og lave et plot af et datasæt i to dimensioner Vurdere den relative varians forklarede af de forskellige components Anvende PCA til at vurdere variablernes bidrag til de principal components 10.1.2 Introduktion til kapitlet Principal component analysis er en meget populær og ofte benyttet statistisk metode, der blandt andet kan anvendes til at visualisere data med et højt antal dimensioner i et enkelt scatterplot med to dimensioner. Det er meget nyttigt til at se den underliggende struktur i datasættet, og indenfor biologi er det meget brugt til blandt andet at visualisere, hvor de forskellige prøver eller replikater befinder sig i forhold til hinanden - for eksempel for at se, om kontrolprøverne og behandlingsprøverne fremtræder på samme steder i plottet (som indikerer, at de ligner hinanden). 10.1.3 Videoressourcer Video 1 - hvad er PCA? Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/556581604 Video 2 - hvordan man lave PCA i R og få output i tidy form Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/556581588 Video 3 - hvordan man visualisere de data (principal components, rotation matrix) Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/556787141 10.2 Hvad er principal component analysis (PCA)? I sidste lektion arbejdede vi med penguins, hvor vi så, at der faktisk var fire numeriske variabler - altså fire dimensioner - som blev brugt til at lave k-means clustering. library(palmerpenguins) penguins &lt;- penguins %&gt;% drop_na() %&gt;% mutate(year=as.factor(year)) penguins %&gt;% select(where(is.numeric)) %&gt;% head() ## # A tibble: 6 × 4 ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 39.1 18.7 181 3750 ## 2 39.5 17.4 186 3800 ## 3 40.3 18 195 3250 ## 4 36.7 19.3 193 3450 ## 5 39.3 20.6 190 3650 ## 6 38.9 17.8 181 3625 Når man laver et plot for at vise de forskellige clusters, får man et problem - hvilke to variabler skal plottes? Man kan plotte hver eneste par af variabler. For eksempel kan man prøve en pakke, der hedder GGally, som automatisk kan plotte de forskellige par af numeriske variabler og beregner korrelationen mellem variablerne. require(GGally) ## Indlæser krævet pakke: GGally ## Registered S3 method overwritten by &#39;GGally&#39;: ## method from ## +.gg ggplot2 penguins %&gt;% ggscatmat(columns = 3:6 ,color = &quot;species&quot;, corMethod = &quot;pearson&quot;) + scale_color_brewer(palette = &quot;Set2&quot;) + theme_bw() ## Warning: The dot-dot notation (`..scaled..`) was deprecated in ggplot2 3.4.0. ## ℹ Please use `after_stat(scaled)` instead. ## ℹ The deprecated feature was likely used in the GGally package. ## Please report the issue at &lt;https://github.com/ggobi/ggally/issues&gt;. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. Problemet er, at så snart antallet af dimensioner i datasættet bliver større end 4, bliver plottet alt for komplekst og pladskrævende. En løsning til problemet er at projicere datasættet ned til et mindre antal dimensioner (f.eks. kun 2 dimensioner). Disse dimensioner fanger oplysninger fra alle variablerne i datasættet, og derfor, når man laver et scatter plot, får man repræsenteret det hele datasæt i stedet for kun to udvalgte variabler. Metoden for at lave disse såkaldte ‘projektioner’ kaldes ‘principal component analysis’. 10.2.1 Simpelt eksempel med to dimensioner Man kan forsøge at forstå, hvordan PCA fungerer, ved at kigge på et simpelt eksempel med 2 dimensioner: #simulerer data med en høj korrelation a &lt;- rnorm(250,1,2) b &lt;- a + rnorm(250,0,.5) df &lt;- tibble(a,b) ggplot(df,aes(a,b)) + geom_point() + theme_minimal() Vi kan se her, at der er en meget stor korrelation mellem a og b. Selvom datasættet er plottet i 2 dimensioner, kan det næsten forklares af én linje - en såkaldt bedste rette linje, der passer bedst gennem punkterne. df &lt;- tibble(a,b) ggplot(df,aes(a,b)) + geom_point() + theme_minimal() + geom_smooth(method=&quot;lm&quot;,se=FALSE) ## `geom_smooth()` using formula = &#39;y ~ x&#39; Med andre ord kan vi næsten forklare datasættet i blot én dimension - punkternes afstand langs linjen. Når man tager alle punkterne og beskriver dem langs én linje, der bedst beskriver variansen i datasættet, kaldes denne linje for den første principal component (PC1). Man kan dernæst beskrive en anden linje, der er vinkelret på PC1, og som bedst forklarer variancen i de data, der ikke blev fanget af PC1 - dette kaldes for den anden principal component (PC2). Vi kan se her PC1 og PC2 plottet: Når vi tager PC1 og PC2 og plotter dem som henholdsvis x-aksen og y-aksen, svarer det til en drejning af akserne i plottet (vi finder PC1 og PC2 fra funktionen prcomp, som jeg forklarer i næste sektion): dat &lt;- augment(prcomp(df),df) ggplot(dat,aes(x=.fittedPC1,y=.fittedPC2)) + geom_point() + theme_minimal() + geom_smooth(method=&quot;lm&quot;) ## `geom_smooth()` using formula = &#39;y ~ x&#39; Vi kan se her, at dataene fylder pladsen på plottet bedre end før (og bemærk at akseskalaen er blevet meget mindre på den nye y-akse, da dataene spreder sig meget mindre langs PC2 i forhold til PC1.) Dette er kun et eksempel, hvor vores oprindelige data ligger i to dimensioner (to variabler), for at gøre det nemt at visualisere dem i et plot, men de fleste datasæt (fx penguins, iris osv.) har flere end to dimensioner. Vi kan godt lave den samme proces, hvor vi definerer PC1, som forklarer så meget af variansen i dataene som muligt, og dernæst PC2, som forklarer noget af variansen, der ikke blev fanget af PC1, og dernæst PC3 osv., alt efter hvor mange dimensioner dataene har. I mange praktiske situationer vælger man de første to komponenter, som er de vigtigste, da de forklarer mest af variansen i dataene i forhold til de andre komponenter. “So to sum up, the idea of PCA is simple — reduce the number of variables of a data set, while preserving as much information as possible.” https://builtin.com/data-science/step-step-explanation-principal-component-analysis 10.3 Fit PCA to data in R library(broom) Lad os skifte tilbage til nogle virkelige data for at benytte prcomp: datasættet penguins. Med prcomp fokuserer vi kun på numeriske variabler, så vi bruger select med where(is.numeric) og anvender derefter skalering ved at specificere scale = TRUE inde i funktionen prcomp. pca_fit &lt;- penguins %&gt;% select(where(is.numeric)) %&gt;% # behold kun numeriske kolonner prcomp(scale = TRUE) # udfør PCA på skaleret data summary(pca_fit) ## Importance of components: ## PC1 PC2 PC3 PC4 ## Standard deviation 1.6569 0.8821 0.60716 0.32846 ## Proportion of Variance 0.6863 0.1945 0.09216 0.02697 ## Cumulative Proportion 0.6863 0.8809 0.97303 1.00000 Proportion of Variance indikerer, hvor meget af variansen i dataene, der blev forklaret af de forskellige komponenter. Vi kan se, at PC1 forklarer omkring 69% og de første to komponenter sammen forklarer 88% af variansen i dataene. Derfor, hvis vi viser et plot af de første to komponenter, ved vi, at vi har fanget rigtig mange oplysninger om de fire variabler i datasættet. 10.4 Integrering af PCA-resultater med broom-pakken Der er flere ting, som kan være nyttige at gøre med vores PCA-resultater: Lave et plot af datasættet ud fra de første to principal components Se, hvor meget af variansen i datasættet der er forklaret af de forskellige komponenter Bruge rotationsmatricen til at se, hvordan variablerne forholder sig i forhold til hinanden For at lave vores plot af principal components kan vi benytte funktionen augment(), ligesom vi gjorde i vores sidste lektion med k-means clustering. Her får vi værdierne for hver af de fire principal components sammen med det oprindelige datasæt. pca_fit_augment &lt;- pca_fit %&gt;% augment(penguins) # tilføj det originale datasæt igen pca_fit_augment ## # A tibble: 333 × 13 ## .rownames species island bill_length_mm bill_depth_mm flipper_length_mm ## &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1 Adelie Torgersen 39.1 18.7 181 ## 2 2 Adelie Torgersen 39.5 17.4 186 ## 3 3 Adelie Torgersen 40.3 18 195 ## 4 4 Adelie Torgersen 36.7 19.3 193 ## 5 5 Adelie Torgersen 39.3 20.6 190 ## 6 6 Adelie Torgersen 38.9 17.8 181 ## 7 7 Adelie Torgersen 39.2 19.6 195 ## 8 8 Adelie Torgersen 41.1 17.6 182 ## 9 9 Adelie Torgersen 38.6 21.2 191 ## 10 10 Adelie Torgersen 34.6 21.1 198 ## # ℹ 323 more rows ## # ℹ 7 more variables: body_mass_g &lt;int&gt;, sex &lt;fct&gt;, year &lt;fct&gt;, ## # .fittedPC1 &lt;dbl&gt;, .fittedPC2 &lt;dbl&gt;, .fittedPC3 &lt;dbl&gt;, .fittedPC4 &lt;dbl&gt; Vi kan tage pca_fit_augment og lave et plot af de første to principal components: pca_fit_augment %&gt;% ggplot(aes(x=.fittedPC1, y=.fittedPC2, color = species)) + geom_point() + theme_bw() Vi kan også integrere de clusters, som vi fik fra funktionen kmeans(), i vores PCA ved at anvende funktionen augment() på resultaterne fra kmeans og vores data, som allerede har resultaterne fra pca. Da både PCA og k-means fanger oplysninger om datastrukturen baseret på de fire numeriske variabler, kan man forvente en bedre sammenligning mellem de to (i forhold til at sammenligne clusters med et plot med kun to af variablerne). penguins_scaled &lt;- penguins %&gt;% select(where(is.numeric)) %&gt;% scale kclust &lt;- kmeans(penguins_scaled,centers = 3) kclust %&gt;% augment(pca_fit_augment) %&gt;% ggplot(aes(x=.fittedPC1, y=.fittedPC2, color = .cluster)) + geom_point() + theme_bw() Output med tidy Næst vil vi se på variansen i datasættet, som er blevet fanget af hver af de forskellige komponenter. Man kan udtrække oplysningerne ved at benytte funktionen tidy() fra pakken broom og ved at angive matrix = \"eigenvalues\" inden for tidy. Det kaldes “eigenvalues”, fordi hvis man kigger på matematikken bag principal component analysis, tager man udgangspunkt i en covariance matrix. En covariance matrix beskriver sammenhængen eller korrelationen mellem de forskellige variabler. Man bruger denne covariance matrix til at beregne de såkaldte eigenvalues og deres tilsvarende eigenvectors. Det er faktisk den største eigenvalue, der fortæller os om den første principal component - det fortæller os, hvor meget af variansen i datasættet den første principal component fanger - jo større den er i forhold til de andre eigenvalues, jo mere af variansen kan man forklare med den første principal component. Og den næststørste fortæller os om den anden principal component og så videre. pca_fit_tidy &lt;- pca_fit %&gt;% tidy(matrix = &quot;eigenvalues&quot;) pca_fit_tidy ## # A tibble: 4 × 4 ## PC std.dev percent cumulative ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1.66 0.686 0.686 ## 2 2 0.882 0.195 0.881 ## 3 3 0.607 0.0922 0.973 ## 4 4 0.328 0.0270 1 Lad os visualisere disse tal som procenttal ved at specificere labels = scales::percent_format() inden for scale_y_continuous - så vi bare ændrer på de tal, der kan ses på y-aksen. pca_fit_tidy %&gt;% ggplot(aes(x = PC, y = percent)) + geom_bar(stat=&quot;identity&quot;, fill=&quot;steelblue&quot;) + scale_y_continuous( labels = scales::percent_format(), #omdann labels til procentformat ) + theme_minimal() På den ene side, hvis der er meget varians, der er forklaret af de første komponenter tilsammen, betyder det, at der er en del redundans i datasættet, fordi mange af variablerne har en tæt sammenhæng med hinanden. På den anden side, hvis der er en meget lille andel af variansen, der er forklaret af de første komponenter tilsammen, betyder det, at det er svært at beskrive datasættet i færre dimensioner (fordi der næsten ingen sammenhæng er mellem variablerne) - i dette tilfælde, hvor datasættet er mere komplekst, er PCA mindre effektiv. 10.4.1 Rotationsmatrix for at udtrække bidragene fra de forskellige variabler Eigenvalues kan anvendes til at undersøge variansen i datasættet, men deres tilsvarende eigenvectors fortæller os om, hvordan de forskellige variabler kombineres for at opnå de endelige principal component værdier, som vi fx bruger i et scatter plot. Eigenvectors bruges til at lave en matrix, der kaldes en ‘rotationsmatrix’. Jeg anvender funktionen pivot_wider for at gøre vores matrix mere overskuelig at se på. Vi kan se, at vi har variablerne her på rækkerne og de forskellige principal components i kolonnerne. pca_fit_rotate &lt;- pca_fit %&gt;% tidy(matrix = &quot;rotation&quot;) %&gt;% pivot_wider(names_from = &quot;PC&quot;, names_prefix = &quot;PC&quot;, values_from = &quot;value&quot;) pca_fit_rotate ## # A tibble: 4 × 5 ## column PC1 PC2 PC3 PC4 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 bill_length_mm 0.454 -0.600 -0.642 0.145 ## 2 bill_depth_mm -0.399 -0.796 0.426 -0.160 ## 3 flipper_length_mm 0.577 -0.00579 0.236 -0.782 ## 4 body_mass_g 0.550 -0.0765 0.592 0.585 Denne rotationsmatrix fortæller os, hvordan man beregner værdierne for de principal components for alle observationer. For eksempel tager vi vores første observation, beregner 0.45 gange bill length, og så minus 0.4 gange bill depth, og så plus 0.58 x flipper length og så plus 0.55 x body_mass. Og så har vi værdien for observationen langs den første principal component. Vi kan anvende rotationsmatrixen til at se, hvordan de forskellige variabler relaterer til hinanden. Variabler, der er tæt på hinanden i plottet, ligner hinanden. Vi kan se, at flipper_length_mm og body_mass_g ligner hinanden ret meget i vores datasæt, mens bill_depth_mm befinder sig over til venstre langs den første principal component, hvilket indikerer, at den måske indeholder nogle oplysninger om pingvinerne, der ikke kunne fanges i de andre variabler. library(ggrepel) pca_fit_rotate %&gt;% ggplot(aes(x=PC1,y=PC2,colour=column)) + geom_point(size=3) + geom_text_repel(aes(label=column)) + theme_minimal() 10.4.2 Pakken factoextra R-pakken factoextra kan anvendes til automatisk at lave et lignende plot fra rotationsmatrixen, og den arbejder oven på ggplot2, så man kan ændre temaet osv. Du kan se, hvordan det fungerer i følgende kode. Man får variansprocenten på akserne. Placeringen af pilhovederne kommer fra rotationsmatrixen. Jo mindre vinklen mellem to linjer er, og jo tættere de er på hinanden, jo større er sammenhængen mellem de to variable. Jo tættere pilhovederne er på cirklen, desto større indflydelse har den pågældende variabel på de principal components. library(factoextra) fviz_pca_var(pca_fit, col.var=&quot;steelblue&quot;,repel = TRUE)+ theme_minimal() 10.5 Problemstillinger Problem 1) Quiz på Absalon Vi arbejder med en breast cancer datasæt. _Here is the description from Kaggle https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset: Breast cancer is the most common cancer amongst women in the world. It accounts for 25% of all cancer cases, and affected over 2.1 Million people in 2015 alone. It starts when cells in the breast begin to grow out of control. These cells usually form tumors that can be seen via X-ray or felt as lumps in the breast area. The key challenges against it’s detection is how to classify tumors into malignant (cancerous) or benign(non cancerous)_ Download følgende datasæt ved at køre følgende kode chunk: cancer &lt;- read.csv(url(&quot;https://www.dropbox.com/s/4qa37itw9wtwtjg/breast-cancer.csv?dl=1&quot;)) %&gt;% as_tibble() %&gt;% select(-id) cancer %&gt;% glimpse() ## Rows: 569 ## Columns: 31 ## $ diagnosis &lt;chr&gt; &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;… ## $ radius_mean &lt;dbl&gt; 17.990, 20.570, 19.690, 11.420, 20.290, 12.450… ## $ texture_mean &lt;dbl&gt; 10.38, 17.77, 21.25, 20.38, 14.34, 15.70, 19.9… ## $ perimeter_mean &lt;dbl&gt; 122.80, 132.90, 130.00, 77.58, 135.10, 82.57, … ## $ area_mean &lt;dbl&gt; 1001.0, 1326.0, 1203.0, 386.1, 1297.0, 477.1, … ## $ smoothness_mean &lt;dbl&gt; 0.11840, 0.08474, 0.10960, 0.14250, 0.10030, 0… ## $ compactness_mean &lt;dbl&gt; 0.27760, 0.07864, 0.15990, 0.28390, 0.13280, 0… ## $ concavity_mean &lt;dbl&gt; 0.30010, 0.08690, 0.19740, 0.24140, 0.19800, 0… ## $ concave.points_mean &lt;dbl&gt; 0.14710, 0.07017, 0.12790, 0.10520, 0.10430, 0… ## $ symmetry_mean &lt;dbl&gt; 0.2419, 0.1812, 0.2069, 0.2597, 0.1809, 0.2087… ## $ fractal_dimension_mean &lt;dbl&gt; 0.07871, 0.05667, 0.05999, 0.09744, 0.05883, 0… ## $ radius_se &lt;dbl&gt; 1.0950, 0.5435, 0.7456, 0.4956, 0.7572, 0.3345… ## $ texture_se &lt;dbl&gt; 0.9053, 0.7339, 0.7869, 1.1560, 0.7813, 0.8902… ## $ perimeter_se &lt;dbl&gt; 8.589, 3.398, 4.585, 3.445, 5.438, 2.217, 3.18… ## $ area_se &lt;dbl&gt; 153.40, 74.08, 94.03, 27.23, 94.44, 27.19, 53.… ## $ smoothness_se &lt;dbl&gt; 0.006399, 0.005225, 0.006150, 0.009110, 0.0114… ## $ compactness_se &lt;dbl&gt; 0.049040, 0.013080, 0.040060, 0.074580, 0.0246… ## $ concavity_se &lt;dbl&gt; 0.05373, 0.01860, 0.03832, 0.05661, 0.05688, 0… ## $ concave.points_se &lt;dbl&gt; 0.015870, 0.013400, 0.020580, 0.018670, 0.0188… ## $ symmetry_se &lt;dbl&gt; 0.03003, 0.01389, 0.02250, 0.05963, 0.01756, 0… ## $ fractal_dimension_se &lt;dbl&gt; 0.006193, 0.003532, 0.004571, 0.009208, 0.0051… ## $ radius_worst &lt;dbl&gt; 25.38, 24.99, 23.57, 14.91, 22.54, 15.47, 22.8… ## $ texture_worst &lt;dbl&gt; 17.33, 23.41, 25.53, 26.50, 16.67, 23.75, 27.6… ## $ perimeter_worst &lt;dbl&gt; 184.60, 158.80, 152.50, 98.87, 152.20, 103.40,… ## $ area_worst &lt;dbl&gt; 2019.0, 1956.0, 1709.0, 567.7, 1575.0, 741.6, … ## $ smoothness_worst &lt;dbl&gt; 0.1622, 0.1238, 0.1444, 0.2098, 0.1374, 0.1791… ## $ compactness_worst &lt;dbl&gt; 0.6656, 0.1866, 0.4245, 0.8663, 0.2050, 0.5249… ## $ concavity_worst &lt;dbl&gt; 0.71190, 0.24160, 0.45040, 0.68690, 0.40000, 0… ## $ concave.points_worst &lt;dbl&gt; 0.26540, 0.18600, 0.24300, 0.25750, 0.16250, 0… ## $ symmetry_worst &lt;dbl&gt; 0.4601, 0.2750, 0.3613, 0.6638, 0.2364, 0.3985… ## $ fractal_dimension_worst &lt;dbl&gt; 0.11890, 0.08902, 0.08758, 0.17300, 0.07678, 0… I variablen diagnosis: M betyder ‘Malignant’ og B betyder ‘Benign’ - du kan overveje at ændre på variablen i dit indlæste datasæt for at gøre det mere klart. Problem 2) Anvend funktionen ggscatmat fra pakken GGally til at lave et plot, hvor man sammenligne fem af variablerne. Man kan lave en tilfældig sample af fem variabler med at angive columns = sample(2:31,5) som parameter indenfor funktionen ggscatmat(husk at installere og indlæse GGally-pakken). Giv farver efter factor variablen diagnosis og vælger “pearson” som parameteren corMethod. Opfatter du, at der er en del redundans i datasættet (dvs., er der stærke korrelationer mellem de forskellige variabler, der gør det muligt at forudsige den ene ud fra den anden)? Prøv at køre din kode igen, så du får forskellige samplings af fem variabler. Problem 3) Benyt funktionen prcomp() til at beregne en principal component analysis af datasættet. Husk at det skal kun være numeriske variabler og angiv scale=TRUE inde i funktionen. Lav et summary af resultaterne. Hvad er proportionen af variansen, der er forklaret af den første principal component? Hvad er proportionen af variansen, som er forklaret af de første to principal components tilsammen? Problem 4) Augment og plot Anvend augment()-funktionen til at tilføje dit rå datasæt til ovenstående resultater fra prcomp. Brug den til at lave et scatter plot af de første to principal components Giv farver efter variablen diagnosis Skriv kort om man kan skelne imellem Malignant og Benign tumours (variablen diagnosis) ud fra de første to principal components. Skriv også kort - hvilke af de to components er bedre til at skelne mellem Malignant og Benign tumours? Problem 5) Integrere kmeans clustering. Lav et clustering med kmeans på datasættet, med to clusters (husk at udvælge numeriske variabler og scale inden du anvender funktionen kmeans). Augment resultaterne af kmeans til dit datasæt, der allerede har prcomp resultater tilføjet. Lav et plot og give farver efter .cluster og former efter diagnosis. Sammenligne dine to clusters med diagnosis. Problem 6) tidy form og variansen Anvende tidy(matrix = \"eigenvalues\") på din PCA resultater til at få bidragen af de forskellige components til den overordnet varianse i datasættet. Lav et barplot som viser de components på x-aksen og percent på y-aksen. Problem 7) tidy form og rotation matrix a) Anvende tidy(matrix = \"rotation\") til at få den rotation matrix og lav følgende: Anvend funktionen pivot_wider til at få den til wide form Lav et scatter plot som viser de forskellige variabler relativ til hinanden Anvend geom_text_repel til at give labels til de variabler (kan være en god idé at anvend show.legend=F) b) Værdierne i den rotation matrix fortæller, hvordan en givet variabel bidrager til den endelige principal component beregning (dvs. værdierne som er plottet i Problem 5). Fk. variablen radius_mean har en positiv værdi i PC2, som gøre, at en højere værdi af radius_mean vil resultatere i en højere værdi på PC2 for en givet observation. Kig på placeringen af variablen compactness_mean på plottet. Bidrager den negativ eller positiv værdi til PC1? Kig igen på dit plot i Problem 5) - hvad effekt ville en forhøjet værdi af compactness_mean have på den PC1-værdien til en givet tumour? Ville det gøre det mindre eller mere sandsynligt, at den er “benign”? Problem 8) Udvidelse af Problem 5): Fra din augmented resultater med både dine principal components og clusters: Beregne middelværdierne af din første to principal components for hver af de to clusters. Tilføj dine beregnede middelværdierne til plottet som “x”. Problem 9) EKSTRA: Gå ind i Kaggle linket (https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset) og klik på “Code”. I den “Search” klik på “Filters” til højre og vælge “R” som language. Kig på analyserne, som andre har lavet på samme datasæt. 10.6 Ekstra læsning Step by step explanation: https://builtin.com/data-science/step-step-explanation-principal-component-analysis PCA tidyverse style fra claus wilke: https://clauswilke.com/blog/2020/09/07/pca-tidyverse-style/ More PCA in tidyverse framework: https://tbradley1013.github.io/2018/02/01/pca-in-a-tidy-verse-framework/ "],["emner-fra-eksperimental-design.html", "Chapter 11 Emner fra eksperimental design 11.1 Inledning og læringsmålene 11.2 Indledning og læringsmål 11.3 Grundlæggende principper i eksperimentelt design 11.4 Case studies: Simpsons paradoks 11.5 Case studies: Anscombes kvartet 11.6 Undersøgelse af “batch-effekter” 11.7 Problemstillinger 11.8 Yderligere læsning", " Chapter 11 Emner fra eksperimental design library(tidyverse) library(broom) “Amatører sidder og venter på inspiration, resten af os står bare op og går på arbejde.” - Stephen King 11.1 Inledning og læringsmålene 11.2 Indledning og læringsmål 11.2.1 Læringsmål I skal være i stand til at Beskrive randomisering, replikation og blokering Beskrive Simpsons paradoks Beskrive Anscombes kvartet Kontrollere for batch-effekter med PCA 11.2.2 Indledning til kapitlet Formålet med dette kapitel er at spørge: Hvordan kan vi anvende de værktøjer, vi har lært i kurset, til at undersøge forskellige emner inden for eksperimentelt design? Dette er ikke en grundig introduktion til eksperimentelt design, men snarere en præsentation af nogle nyttige og interessante emner, der effektivt illustrerer, hvorfor det er vigtigt at lave passende visualiseringer af dine data. Forståelsen af, hvordan batch-effekter påvirker en analyse, er særlig vigtig inden for biologifaget, hvor mange store sekventeringsprojekter involverer data indsamlet eller sekventeret over forskellige batches, sekventeringsmaskiner eller forskellige forberedelsesmetoder. 11.2.3 Video ressourcer Part 1: randomisation, replikation, blocking + confounding Ingen video: læs gerne notaterne nedenfor Part 2: Simpson’s paradox Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/556581563 Part 3: Anscombe’s quartet Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/556581540 Part 4: Batch effects and principal component analysis. OBS Man kan selvfølgelige også anvende map_if() til at log-transformere. Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/556581521 11.3 Grundlæggende principper i eksperimentelt design 11.3.1 Randomisering og replikation Man laver et eksperiment for at få svar på et bestemt spørgsmål eller en hypotese. Eksperimentet designes ud fra principper, der gør det muligt at fortolke resultaterne fra analysen af datasættet efterfølgende. For at et eksperiment skal være gyldigt, skal det kunne demonstrere hensigtsmæssig replikation og randomisering. Randomisering Målet er at udelukke, at konklusionerne simpelthen kan skyldes varians som følge af en faktor, der ikke direkte er interessant i eksperimentet. Derfor bruger man randomisering til at fordele disse faktorer over de forskellige behandlingsgrupper. Et eksempel kan være ‘double-blinding’ i kliniske eksperimenter - både lægen og patienten har ikke kendskab til, hvem der hører til de forskellige grupper, således at forskelsbehandling indenfor grupperne, som kan påvirke de endelige resultater, undgås. Replikation Dette sker, når man gentager et eksperiment flere gange - for eksempel ved at have flere patienter i hver behandlingsgruppe. Dette tillader os at beregne variabiliteten i data, som er nødvendig for at kunne konkludere om, der er en forskel mellem grupperne. Man kan altså ikke generalisere resultater, som kun er målt på én person. Figure 11.1: randomisation og replikation I ovenstående figur er der 6 replikationer i hver gruppe, der enten er “behandling” eller “kontrol”. I tilfældet “God randomisering” er objekter, som er taget tilfældigt fra populationen, godt matchet mellem de to grupper. I det andet tilfælde, “Dårlig randomisering”, kan man se, at objekternes farver er godt matchet inden for de samme grupper. Dette gør det derfor umuligt at afgøre, om en eventuel forskel mellem “behandling” og “kontrol” i virkeligheden er resultatet af farven frem for de målinger, man gerne vil sammenligne. Forvekslingsvariabler Figuren nedenfor illustrerer alder som en forvekslingsvariabel i et eksperiment, hvor man prøver at forstå sammenhængen mellem aktivitetsniveau og vægtøgning. Det kan se ud som om, at et lavt aktivitetsniveau (afhængig variabel) forklarer vægtøgning (uafhængig variabel), men man er nødt til at tage andre variable i betragtning for at sikre, at sammenhængen ikke skyldes noget andet. For eksempel kunne gruppen med det høje aktivitetsniveau bestå af personer, der er yngre end personerne i gruppen med det lave aktivitetsniveau, og deres alder kan påvirke deres vægtøgning (måske på grund af forskelle i stressniveauer, kost osv.). Blokering Man kan forsøge at kontrollere for ekstra variable, som vi ikke er interesseret i, gennem “blokering”. Blokering udføres ved først at identificere grupper af individer, der ligner hinanden så meget som muligt. Det kan for eksempel være, at tre forskellige forskere har medvirket til at udføre et stort eksperiment med mange patienter og forskellige behandlingsgrupper. Vi er interesseret i, om der er forskelle mellem behandlingsgrupperne, men ikke i, om der er en forskel i forskernes behandling af patienterne. Derfor vil vi gerne ‘blokere’ efter forsker - altså kontrollere for dem som en “batch” effekt. Man kan også blokere efter fx køn, for at sikre at forskellene i behandlingsgrupperne ikke skyldes forskelle mellem mænd og kvinder. Blokering udføres som en del af en lineær model, efter data er indsamlet, men det er nyttigt at tænke over det fra starten. 11.3.2 Eksempel med datasættet ToothGrowth Et godt eksempel på et veludført eksperimentelt design er datasættet ToothGrowth, som er baseret på marsvin - de fik forskellige kosttilskud og doser, og derefter blev længden af deres tænder målt. data(ToothGrowth) ToothGrowth &lt;- ToothGrowth %&gt;% tibble() %&gt;% mutate(dose = as.factor(dose)) summary(ToothGrowth) ## len supp dose ## Min. : 4.20 OJ:30 0.5:20 ## 1st Qu.:13.07 VC:30 1 :20 ## Median :19.25 2 :20 ## Mean :18.81 ## 3rd Qu.:25.27 ## Max. :33.90 Her kan man se, at for hver gruppe (efter supp og dose) er der 10 marsvin - vi har således replikationer over grupperne, og hver supp (supplement) har hver af de tre mulige værdier for “dose”. Hvis vi for eksempel ikke var interesseret i supp men kun i dosis, kunne vi ‘blokere’ efter supp for at afbøde forskelle i effekten af de to supplementer i supp. ToothGrowth %&gt;% dplyr::count(supp,dose) %&gt;% ggplot(aes(x=factor(dose),y=n,fill=factor(dose))) + geom_bar(stat=&quot;identity&quot;) + ylab(&quot;Antal marsvin&quot;) + xlab(&quot;Dosering&quot;) + facet_grid(~supp) + theme_bw() Man skal dog være opmærksom, fordi vi ved ikke, hvordan marsvinene blev tildelt til de forskellige grupper. For eksempel, hvis hanner og hunner ikke er tildelt tilfældigt, kan det forekomme, at supp “OJ” og dosis “0.5” kun har hanmarsvin, og supp “OJ” med dosis “1.0” kun har hunmarsvin. I sådanne tilfælde kunne vi ikke afgøre, om forskellen i dosis “0.5” versus “1.0” er resultatet af dosis eller køn. 11.4 Case studies: Simpsons paradoks (Se også videoressourcer Del 2). Simpsons paradoks er et fascinerende statistisk fænomen, der er en vigtig påmindelse om, at korrelation ikke nødvendigvis indebærer kausalitet, og at det er afgørende at forstå de underliggende data og ikke kun de aggregerede statistikker. Simpsons paradoks opstår, når man drager to modsatte konklusioner fra det samme datasæt - på den ene side, når man kigger på dataene samlet, og på den anden side, når man tager visse grupper i betragtning. Vi kan visualisere Simpsons paradoks gennem eksemplet nedenfor - her har vi to variable x og y, som vi kan bruge til at lave et scatterplot, samt nogle forskellige grupper inden for variablen group. #library(datasauRus) simpsons_paradox &lt;- read.table(&quot;https://www.dropbox.com/s/ysh3qpc7qv0ceut/simpsons_paradox_groups.txt?dl=1&quot;,header=T) simpsons_paradox &lt;- simpsons_paradox %&gt;% tibble() simpsons_paradox FALSE # A tibble: 222 × 3 FALSE x y group FALSE &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; FALSE 1 62.2 70.6 D FALSE 2 52.3 14.7 B FALSE 3 56.4 46.4 C FALSE 4 66.8 66.2 D FALSE 5 66.5 89.2 E FALSE 6 62.4 91.5 E FALSE 7 38.9 6.76 A FALSE 8 39.4 63.1 C FALSE 9 60.9 92.6 E FALSE 10 56.6 45.8 C FALSE # ℹ 212 more rows Hvis vi ignorerer group og kigger på dataene samlet, kan vi se, at der er en stærk positiv sammenhæng mellem x og y. Men når vi opdeler efter de forskellige grupper ved at skrive colour = group, opnår vi faktisk en negativ sammenhæng indenfor hver af grupperne. p1 &lt;- simpsons_paradox %&gt;% ggplot(aes(x,y)) + geom_point() + geom_smooth(method=&quot;lm&quot;,se=FALSE) + theme_classic() p2 &lt;- simpsons_paradox %&gt;% ggplot(aes(x,y,colour=group)) + geom_point() + geom_smooth(method=&quot;lm&quot;,aes(group=group),colour=&quot;black&quot;,se=FALSE) + theme_classic() library(gridExtra) grid.arrange(p1,p2,ncol=2) Simpsons paradoks forekommer oftere end man skulle tro, og derfor er det vigtigt at overveje, hvilke andre variable man også er nødt til at tage i betragtning. 11.4.1 Optagelse på Berkeley Det mest berømte eksempel på Simpsons paradoks drejer sig om optagelsen på Berkeley Universitetet i 1973. Følgende tabel fra Wikipedia (https://en.wikipedia.org/wiki/Simpson%27s_paradox) viser statistikker over antallet af ansøgere samt procentdelen, der blev optaget på universitetet generelt, opdelt efter køn. Figure 11.2: source: wikipedia Hvis vi laver et søjlediagram af tallene, kan man se, at der er en højere procentdel af mænd end kvinder, som blev optaget på universitetet (sagen medførte en retssag mod universitetet). admissions_all &lt;- tibble(&quot;sex&quot;=c(&quot;all&quot;,&quot;men&quot;,&quot;women&quot;),admitted=c(&quot;41&quot;,&quot;44&quot;,&quot;35&quot;)) admissions_all %&gt;% ggplot(aes(x=sex,y=admitted,fill=sex)) + geom_bar(stat=&quot;identity&quot;) + theme_minimal() + ylab(&quot;Procent optaget&quot;) + scale_x_discrete(limits = c(&quot;women&quot;,&quot;men&quot;,&quot;all&quot;)) + coord_flip() Da man dog kiggede lidt nærmere på de samme tal, men opdelte efter de forskellige fakulteter på universitetet, fik man et anderledes billede af situationen. I følgende tabel har vi optagelsestallene for mænd og kvinder på hver af de forskellige fakulteter (A til F). admissions_separate &lt;- tribble( ~department, ~all, ~men, ~women, #------------|-------|-------|--------# &quot;A&quot;, 64, 62, 82, &quot;B&quot;, 63, 63, 68, &quot;C&quot;, 35, 37, 34, &quot;D&quot;, 34, 33, 35, &quot;E&quot;, 25, 28, 24, &quot;F&quot;, 6, 6, 7 ) Man kan se, at for de fleste af fakulteterne er der ikke en markant forskel mellem mænd og kvinder, og i nogle tilfælde havde kvinder faktisk en større sandsynlighed for at blive optaget. admissions_separate %&gt;% pivot_longer(-department,names_to=&quot;sex&quot;,values_to=&quot;admitted&quot;) %&gt;% ggplot(aes(x=department,y=admitted,fill=sex)) + ylab(&quot;Procent optaget&quot;) + geom_bar(stat=&quot;identity&quot;,position = &quot;dodge&quot;,colour=&quot;black&quot;) + theme_minimal() Hvad skyldes denne sammenhæng? Det viste sig, at kvinder havde en tendens til at ansøge indenfor de fakulteter, som var sværest at komme ind på. For eksempel kan man se her, at fakultet E har en relativt lav optagelsesprocent. Det samme fakultet var dog et af dem, hvor betydeligt flere kvinder ansøgte end mænd. applications_E &lt;- tibble(&quot;sex&quot;=c(&quot;all&quot;,&quot;men&quot;,&quot;woman&quot;),applications=c(&quot;584&quot;,&quot;191&quot;,&quot;393&quot;)) applications_E %&gt;% ggplot(aes(x=sex,y=applications,fill=sex)) + geom_bar(stat=&quot;identity&quot;) + theme_minimal() + ylab(&quot;Number of applications to dep. E&quot;) + scale_x_discrete(limits = c(&quot;woman&quot;,&quot;men&quot;,&quot;all&quot;)) + coord_flip() Derfor, selvom kvinder ikke havde en lavere sandsynlighed for at blive optaget end mænd i deres fortrukne fag, var antallet af kvinder, der blev optaget i det hele taget på tværs af alle afdelinger, faktisk lavere end antallet af mænd. 11.5 Case studies: Anscombes kvartet (Se også videoressourcer Del 3). Anscombes kvartet (se også https://en.wikipedia.org/wiki/Anscombe%27s_quartet) er et meget nyttigt og berømt eksempel fra 1973, der fremhæver vigtigheden af at visualisere datasættet. Vi kan hente dataene fra linket nedenfor - der er x-værdier og y-værdier, som kan anvendes til at lave et scatterplot, og der er også set, der refererer til fire forskellige datasæt (derfor ‘kvartet’). anscombe &lt;- read.table(&quot;https://www.dropbox.com/s/mlt7crdik3eih9a/anscombe_long_format.txt?dl=1&quot;,header=T) anscombe &lt;- anscombe %&gt;% tibble() anscombe ## # A tibble: 44 × 3 ## set x y ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 10 8.04 ## 2 1 8 6.95 ## 3 1 13 7.58 ## 4 1 9 8.81 ## 5 1 11 8.33 ## 6 1 14 9.96 ## 7 1 6 7.24 ## 8 1 4 4.26 ## 9 1 12 10.8 ## 10 1 7 4.82 ## # ℹ 34 more rows Formålet med datasættet er, at vi gerne vil fitte en lineær regressionsmodel for at finde den forventede y-værdi afhængig af x (husk lm(y ~ x)). Da vi har fire datasæt, kan vi opdele datasættet efter set og anvende funktionerne nest og map (se Kapitel 7) til at fitte de fire lineære regressionsmodeller. Vi anvender også tidy og glance for at få resuméstatistikker fra de fire modeller: my_func &lt;- ~lm(y ~ x, data = .x) tidy_anscombe_models &lt;- anscombe %&gt;% group_nest(set) %&gt;% mutate(fit = map(data, my_func), tidy = map(fit, tidy), glance = map(fit, glance)) Vi kan anvende unnest på outputtet fra tidy og se på skæringspunktet og hældningen af de fire modeller. Man kan se, at de to parametre er næsten identiske for de fire modeller: tidy_anscombe_models %&gt;% unnest(&quot;tidy&quot;) %&gt;% pivot_wider(id_cols = &quot;set&quot;,names_from = &quot;term&quot;,values_from=&quot;estimate&quot;) ## # A tibble: 4 × 3 ## set `(Intercept)` x ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 3.00 0.500 ## 2 2 3.00 0.5 ## 3 3 3.00 0.500 ## 4 4 3.00 0.500 Hvad med de andre parametre fra modellen - lad os eksempelvis kigge på r.squared og p.value fra modellerne, som kan findes i outputtet fra glance. Her kan vi igen se, at de er næsten identiske. tidy_anscombe_models %&gt;% unnest(cols = c(glance)) %&gt;% select(set, r.squared,p.value) ## # A tibble: 4 × 3 ## set r.squared p.value ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 0.667 0.00217 ## 2 2 0.666 0.00218 ## 3 3 0.666 0.00218 ## 4 4 0.667 0.00216 Hvad med korrelation? Den er også næsten den samme: my_func &lt;- ~cor(.x$x,.x$y) anscombe %&gt;% group_nest(set) %&gt;% mutate(cor = map(data, my_func)) %&gt;% unnest(cor) %&gt;% select(-data) ## # A tibble: 4 × 2 ## set cor ## &lt;int&gt; &lt;dbl&gt; ## 1 1 0.816 ## 2 2 0.816 ## 3 3 0.816 ## 4 4 0.817 Kan vi så konkludere, at de fire datasæt, som underbygger de forskellige modeller, er identiske? Lad os lave et scatter plot af de fire datasæt (som vi faktisk burde have gjort i starten af vores analyse). anscombe %&gt;% ggplot(aes(x = x, y = y,colour=factor(set))) + geom_point() + facet_wrap(~set) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + theme_minimal() De fire datasæt er meget forskellige. Vi ved, at de alle har samme bedste tilpasning med rette linjer, men de underliggende data er slet ikke de samme. Det første datasæt ser egnet ud til en lineær regressionsanalyse, men vi kan se i datasæt nummer to, at der ikke engang er en lineær sammenhæng. Og de andre to har outlier værdier, hvilket gør, at den bedst tilpassede rette linje ikke passer særlig godt til punkterne. 11.6 Undersøgelse af “batch-effekter” (Se også videoressourcer Part 4). En “batch-effekt” er en systematisk teknisk bias, der opstår, når målinger (f.eks. genekspression) udføres i flere omgange eller “batches”. Dette kan potentielt føre til betydelige forvrængninger og fejlagtige konklusioner i dataanalyse, hvis det ikke tages højde for. Forestil dig, at du udfører et eksperiment, hvor du sammenligner genekspressionen i sundt væv med kræftvæv. Du udfører dine eksperimenter over flere dage, og det viser sig, at alle dine sunde prøver blev behandlet på mandag, og alle dine kræftprøver blev behandlet på tirsdag. Hvis der er en systematisk forskel i, hvordan dine eksperimenter blev udført på de to dage (måske et reagens var lidt anderledes, eller instrumentet blev brugt på en anden måde), vil du se en stor forskel i genekspression mellem dine sunde og kræftprøver. Men denne forskel skyldes faktisk batch-effekten, ikke forskellen mellem sundt og kræftvæv. Man kan også anvende visualiseringer til at undersøge eventuelle batch-effekter eller forvirrende variabler i datasættet. Dette er især vigtigt i store eksperimenter, hvor forskellige prøver eller dele af datasættet bliver indsamlet på forskellige tidspunkter, steder, eller af forskellige personer. Det er ofte tilfældet i sekvenseringsbaserede datasæt, at man ser batch-effekter, og det kan skyldes mange ting, bl.a.: Sekvenseringsdybde Grupper af prøver lavet på forskellige tidspunkter af forskellige individer Sekvenseringsmaskiner - prøver sekvenseret på forskellige maskiner eller ‘lanes’. Lad os tage udgangspunkt i nogle genekspressionssekvenseringsdata fra mus (vi så også dette datasæt, da vi lærte om pivot_longer kombineret med left_join). norm.cts &lt;- read.table(&quot;https://www.dropbox.com/s/3vhwnsnhzsy35nd/bottomly_count_table_normalised.txt?dl=1&quot;) coldata &lt;- read.table(&quot;https://www.dropbox.com/s/el3sm9ncvzbq6xf/bottomly_phenodata.txt?dl=1&quot;) coldata &lt;- coldata %&gt;% tibble() norm.cts &lt;- as_tibble(norm.cts,rownames=&quot;gene&quot;) Jeg begynder med at vælge kun de rækker, der har mindst 50 counts, for at undgå gener med lave ekspressionsniveauer. Det næste jeg gør er at transformere dataene til logaritmisk form (funktion map_if()) for at opnå en bedre fordeling i datasættet. #normalisere og filtrere dataene norm.cts &lt;- norm.cts %&gt;% filter(rowSums(norm.cts %&gt;% select(-gene))&gt;50) %&gt;% map_if(is.numeric,~log(.x+1)) %&gt;% as_tibble() norm.cts ## # A tibble: 10,193 × 22 ## gene SRX033480 SRX033488 SRX033481 SRX033489 SRX033482 SRX033490 SRX033483 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ENSMUS… 6.35 6.32 6.21 6.29 6.31 6.27 6.30 ## 2 ENSMUS… 3.51 3.56 3.57 3.27 2.99 3.61 3.56 ## 3 ENSMUS… 3.19 3.50 3.08 3.21 3.14 3.09 3.22 ## 4 ENSMUS… 6.69 6.48 6.38 6.35 6.39 6.34 6.50 ## 5 ENSMUS… 6.05 6.37 6.17 6.26 6.16 6.06 6.13 ## 6 ENSMUS… 2.89 2.94 3.16 3.21 3.77 3.30 3.11 ## 7 ENSMUS… 3.42 3.12 3.86 4.36 3.77 3.99 4.24 ## 8 ENSMUS… 3.42 2.94 3.52 3.41 3.57 3.60 2.99 ## 9 ENSMUS… 5.02 4.98 4.49 4.27 4.67 4.35 4.81 ## 10 ENSMUS… 5.13 4.88 4.97 4.76 4.82 4.79 4.96 ## # ℹ 10,183 more rows ## # ℹ 14 more variables: SRX033476 &lt;dbl&gt;, SRX033478 &lt;dbl&gt;, SRX033479 &lt;dbl&gt;, ## # SRX033472 &lt;dbl&gt;, SRX033473 &lt;dbl&gt;, SRX033474 &lt;dbl&gt;, SRX033475 &lt;dbl&gt;, ## # SRX033491 &lt;dbl&gt;, SRX033484 &lt;dbl&gt;, SRX033492 &lt;dbl&gt;, SRX033485 &lt;dbl&gt;, ## # SRX033493 &lt;dbl&gt;, SRX033486 &lt;dbl&gt;, SRX033494 &lt;dbl&gt; Så der er omkring 10.000 gener i rækkerne, og der er 21 forskellige prøver, der spreder sig over kolonnerne. Vi har også nogle prøveoplysninger - der er to forskellige stammer af mus og også forskellige batches, som vi gerne vil undersøge nærmere. coldata ## # A tibble: 21 × 5 ## column num.tech.reps strain batch lane.number ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 SRX033480 1 C57BL.6J 6 1 ## 2 SRX033488 1 C57BL.6J 7 1 ## 3 SRX033481 1 C57BL.6J 6 2 ## 4 SRX033489 1 C57BL.6J 7 2 ## 5 SRX033482 1 C57BL.6J 6 3 ## 6 SRX033490 1 C57BL.6J 7 3 ## 7 SRX033483 1 C57BL.6J 6 5 ## 8 SRX033476 1 C57BL.6J 4 6 ## 9 SRX033478 1 C57BL.6J 4 7 ## 10 SRX033479 1 C57BL.6J 4 8 ## # ℹ 11 more rows Vi kan se på, hvor mange prøver vi har for hver kombination af stamme og batch i datasættet: table(coldata$strain, coldata$batch) ## ## 4 6 7 ## C57BL.6J 3 4 3 ## DBA.2J 4 3 4 Så man kan se, at både stammen er repræsenteret med tre eller fire prøver i hver af de tre batches. Der er derfor replikation, og da vi har fået repræsenteret hver kombination af stamme og batch, kan vi eventuelt blokere efter batch for at fjerne dens effekt. Her har vi ikke tid til at se på metoder til at fjerne batch-effekter, men det er vigtigt, at vi er i stand til at opdage dem. 11.6.1 Principal component analyse Man kan undersøge mulige batch-effekter via principal component analyse. pca_fit &lt;- norm.cts %&gt;% select(where(is.numeric)) %&gt;% # behold kun numeriske kolonner prcomp(scale = TRUE) # udfør PCA på skalerede data Husk, at når man udfører en principal component analyse, får man rotationsmatricen, der anvendes til at se, hvor de forskellige prøver ligger i forhold til hinanden over de forskellige principal komponenter - dvs. at prøver, der ligner hinanden, vises på samme sted på plottet. Rotationsmatricen udtrækkes med funktionen tidy(): rot_matrix &lt;- pca_fit %&gt;% tidy(matrix = &quot;rotation&quot;) Vi vil gerne lave et plot af rotationsmatricen, men først vil vi gerne tilføje prøveoplysningerne med left_join, så vi kan se de forskellige batches eller stammer. Begge dataframes har en kolonne, der hedder column, som refererer til prøvenavne, så jeg forbinder efter column her. rot_matrix &lt;- rot_matrix %&gt;% left_join(coldata,by=&quot;column&quot;) Brug pivot_wider() til at få det i bred format, så vi kan plotte “PC1” og “PC2” i et scatter plot: rot_matrix_wide &lt;- rot_matrix %&gt;% pivot_wider(names_from = &quot;PC&quot;, names_prefix = &quot;PC&quot;, values_from = &quot;value&quot;) rot_matrix_wide ## # A tibble: 21 × 26 ## column num.tech.reps strain batch lane.number PC1 PC2 PC3 PC4 ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 SRX03… 1 C57BL… 6 1 -0.217 0.262 0.0200 -0.508 ## 2 SRX03… 1 C57BL… 7 1 -0.219 0.243 0.00586 0.166 ## 3 SRX03… 1 C57BL… 6 2 -0.217 0.303 0.0153 -0.237 ## 4 SRX03… 1 C57BL… 7 2 -0.219 0.246 0.00799 0.178 ## 5 SRX03… 1 C57BL… 6 3 -0.217 0.259 0.0974 -0.113 ## 6 SRX03… 1 C57BL… 7 3 -0.219 0.234 0.00385 0.209 ## 7 SRX03… 1 C57BL… 6 5 -0.218 0.237 0.0303 -0.179 ## 8 SRX03… 1 C57BL… 4 6 -0.217 0.00524 0.463 0.376 ## 9 SRX03… 1 C57BL… 4 7 -0.218 0.0901 0.305 0.0651 ## 10 SRX03… 1 C57BL… 4 8 -0.218 -0.110 0.434 -0.161 ## # ℹ 11 more rows ## # ℹ 17 more variables: PC5 &lt;dbl&gt;, PC6 &lt;dbl&gt;, PC7 &lt;dbl&gt;, PC8 &lt;dbl&gt;, PC9 &lt;dbl&gt;, ## # PC10 &lt;dbl&gt;, PC11 &lt;dbl&gt;, PC12 &lt;dbl&gt;, PC13 &lt;dbl&gt;, PC14 &lt;dbl&gt;, PC15 &lt;dbl&gt;, ## # PC16 &lt;dbl&gt;, PC17 &lt;dbl&gt;, PC18 &lt;dbl&gt;, PC19 &lt;dbl&gt;, PC20 &lt;dbl&gt;, PC21 &lt;dbl&gt; Jeg tildeler farver og former efter de tre batches. Man kan se, at jeg har fået alle prøver fra batch nummer 2 på samme sted i plottet. rot_matrix_wide %&gt;% ggplot(aes(PC1,PC2,shape=factor(batch),colour=factor(batch))) + geom_point(size=3) + theme_minimal() Jeg kan også tildele farver efter stamme, hvor man kan se, at der sandsynligvis er en forskel mellem de to stammer her. rot_matrix_wide %&gt;% ggplot(aes(PC1,PC2,shape=factor(strain),colour=factor(strain))) + geom_point(size=3) + theme_minimal() Man kan også se på dataene på en anden måde ved at lave boksdiagrammer for de to første principale komponenter, opdelt efter batch. Vi får bekræftet vores observation om, at der er en markant forskel mellem batch 7 og de andre to batches langs den første principale komponent, og det er et problem, som muligvis skal korrigeres, før man foretager yderligere analyser af dataene. p1 &lt;- rot_matrix_wide %&gt;% ggplot(aes(x=factor(batch),y=PC1,fill=factor(batch))) + geom_boxplot(show.legend = F) + geom_jitter(show.legend = F) + theme_minimal() p2 &lt;- rot_matrix_wide %&gt;% ggplot(aes(x=factor(batch),y=PC2,fill=factor(batch))) + geom_boxplot(show.legend = F) + geom_jitter(show.legend = F) + theme_minimal() library(gridExtra) grid.arrange(p1,p2,ncol=2) 11.7 Problemstillinger Problem 1) Quiz på Absalon - experimental Problem 2) Eksperimental design Jeg laver et eksperiment hvor patienter få en af tre forskellige kosttilskud (Gruppe 1, 2 og 3). Der er 5 patienter i hver gruppe og jeg vil gerne se, om patienternes energi niveau i gennemsnit er forskellige mellem de tre grupper. Alderne af patienterne i hver af de tre grupper er: Gruppe 1: 18, 23, 31, 25, 19 Gruppe 2: 24, 29, 35, 21, 30 Gruppe 3: 43, 52, 33, 39, 40 a) Hvad er problemet her med det eksperimental design? Lav boxplots for at viser fordelingen af alderne for hver af de tre grupper. b) Hvis man finder en signifikant forskel mellem de tre kosttilskud, kan man stoler på resultaterne? c) Hvad andre variabler end alder kunne skyldes en eventuelle forskel mellem de tre kosttilskud, og som måske skulle tages i betragtning? d) Hvad kan man gøre med den ovenstående eksperiment design for at løse problemet? Problem 3) Simpson’s paradoks Lung Cap data revisited Indlæse LungCapData og tilføj kategorisk variabel Age.Group: LungCapData &lt;- read.csv(&quot;https://www.dropbox.com/s/ke27fs5d37ks1hm/LungCapData.csv?dl=1&quot;) LungCapData$Age.Group &lt;- cut(LungCapData$Age,breaks=c(1,13,15,17,19),right=FALSE,include.lowest = TRUE) levels(LungCapData$Age.Group) &lt;- c(&quot;&lt;13&quot;,&quot;13-14&quot;,&quot;15-16&quot;,&quot;17+&quot;) a) Lav boxplots med smoke på x-aksen og LungCap på y-aksen. + Notere hvilke gruppe har den højeste lungkapacitet. b) Lav samme plot men adskilte efter Age.Group og beskriv, hvordan det er et eksempel på Simpson’s Paradoks. c) Lav et boxplot med Age på y-aksen og Smoke på x-aksen for at støtte hvorfor man ser Simpson’s Paradoks i datasættet. Problem 4) Anscombes analyse Gentage Anscombes analyse med dinosaurus datasæt: library(datasauRus) #installer denne pakke data_dozen &lt;- datasauRus::datasaurus_dozen data_dozen FALSE # A tibble: 1,846 × 3 FALSE dataset x y FALSE &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; FALSE 1 dino 55.4 97.2 FALSE 2 dino 51.5 96.0 FALSE 3 dino 46.2 94.5 FALSE 4 dino 42.8 91.4 FALSE 5 dino 40.8 88.3 FALSE 6 dino 38.7 84.9 FALSE 7 dino 35.6 79.9 FALSE 8 dino 33.1 77.6 FALSE 9 dino 29.0 74.5 FALSE 10 dino 26.2 71.4 FALSE # ℹ 1,836 more rows a) Fit en lineær regression model for hver af de datasæt (anvende group_by, nest og map ramme med en custom funktion), hvor man har y som afhængig variabel og x som uafhængig variabel. Anvend også tidy og glance på samtlige modeller b) Anvend resultaterne fra tidy til at kigge på den slope og intercept for de forskellige modeller - ligner de hinhanden? c) Anvende også resultaterne fra glance til at kigge på r.squared og p.value. d) Er de alle det samme datasæt? Lav et scatter plot adskilte efter de forskellige datasæt. Hvordan ser de bedste rette linjer ud på plotterne? Problem 5) Vi vil gerne undersøge eventuelle batch effects i følgende datasæt. Det er simuleret “single cell” sekvensering count data (dataframen cse50) samt dataframen batches, som angiver hvilken batch hver af de 500 cells tilhører. cse50 &lt;- read.table(&quot;https://www.dropbox.com/s/o0wzojpcsekeg6z/cell_mix_50_counts.txt?dl=1&quot;) batches &lt;- read.table(&quot;https://www.dropbox.com/s/4t382bfgro46ka5/cell_mix_50_batches.txt?dl=1&quot;) batches &lt;- tibble(&quot;batch&quot;=batches %&gt;% pull(batch)) cse50 &lt;- tibble(cse50) a) Anvend map_df til at få transformeret de data til log scale (plus 1 først og tag log bagefter). b) Lav PCA på det transformeret datasæt. c) Anvend din PCA resultater til at få den rotation matrix d) Forbinde oplysningerne fra dataframen batches til din rotation matrix (første tilføj en ny kolonne “column” til batches som er lig med names(cse50). e) Anvend pivot_wider og lav et plot af den første to principal components, hvor du angiver farve efter batch. f) Lav også boxplots for de første to prinpical components fordelt efter batch og kommenter kort på eventuelle batch effekts i de data. Problem 6 Mere Simpson’s Paradox Kør følgende kode til at indlæs og bearbejde følgende datasæt airlines. airlines &lt;- read.table(&quot;http://www.utsc.utoronto.ca/~butler/d29/airlines.txt&quot;,header=T) airlines &lt;- airlines %&gt;% pivot_longer(-airport) %&gt;% separate(name,sep=&quot;_&quot;,into = c(&quot;airline&quot;,&quot;status&quot;)) %&gt;% mutate(airline = recode(airline, aa = &quot;Alaska&quot;, aw = &quot;American&quot;)) %&gt;% pivot_wider(names_from=status,values_from=value) %&gt;% mutate(&quot;ontime&quot; = ontime + delayed) %&gt;% rename(flights = ontime) a) Opsummer antal flights og antal delayed over de forskellige airports for at få et samlet tal til hver airline. b) Beregn også proportionen af flights som er delayed i hver airline (igen samlede over alle airports). Lav et barplot til at vise proportionerne. c) Denne gange opsummer over de to airlines for at få et samlet tal til hvert airport. Beregn også proportionen af flights som er delayed og lave et plot. d) Denne gange beregne proportionen af flights som er delayed til hver kombination af både airport og airline. Igen omsæt til et plot. e) Kan du forklare? Hint: tag for eksempel en kig på de rå data og bla. airport “Phoenix”. 11.8 Yderligere læsning Simpson’s paradox og airlines: http://ritsokiguess.site/docs/2018/04/07/simpson-s-paradox-log-linear-modelling-and-the-tidyverse/ Batch effekt correction: https://en.wikipedia.org/wiki/Batch_effect#Correction "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
